% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\title{Remote Sensing in the Social Sciences}
\author{}
\date{\vspace{-2.5em}Fall 2021 \textbar{} AAEC 6984 \textbar{} Prof Benami}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Remote Sensing in the Social Sciences},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\hypertarget{introduction}{%
\section*{Introduction}\label{introduction}}
\addcontentsline{toc}{section}{Introduction}

Research involving remote sensing data acquisition and analysis has evolved significantly in the past few decades. In the earliest years of satellite-based remote sensing analysis, only a handful of governments had the capability to deploy satellites and reliably process satellite imagery, and its use was largely limited to the military and intelligence communities.

In the late 1950s, the US and Europe established the National Aeronautics and Space Administration (NASA) and the (predecessors to) the European Space Agency (ESA) so as to support a civilian space program as well as space and aeronautics research.

Even then, however, data access was unwieldy and often costly. For example, even if a researcher had identified the data they wanted to work with, they would have had to go through the time-intensive steps of downloading the data on a computer with sufficient memory and performing a series of pre-processing steps (e.g., ortho-rectification and atmospheric corrections), all before they began to assess their main questions of interest.

\textbf{Why Google Earth Engine (GEE) }

As part of Google's quest to make the world's information universally accessible and useful, Google Earth Engine emerged in 2010 to aid in organizing and simplifying geospatial data in a way that supports an end-to-end solution for analysis.

This resource simplifies many of the historical problems that remote sensing researchers have struggled with, including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  GEE now features petabytes of imagery from both public and private sources, including the most-used Landsat, MODIS, and Sentinel data.
\item
  GEE allows users to process the data and conduct sophisticated analysis on their data of choice within Google's Cloud environment (for example even allowing advanced Machine Learning using TensorFlow Processing Units).
\item
  GEE geo-rectifies the image and provides pre-built algorithms that facilitate analysis. In case you need to build your own algorithms, Google Earth Engine has built functionality within JavaScript and Python, which in turn extends the opportunities for processing data and displaying results.
\item
  Users can even import their own data and work with it within GEE while still maintaining ownership of the analysis and functions written within GEE (i.e., use it for noncommercial purposes).
\end{enumerate}

As scholars interested in using remote sensing data for public social science research questions, Google Earth Engine can open up a variety of new resources for your analysis.

\textbf{License and Attribution}

The foundation of the first series of lab exercises were generously shared with us by \href{https://research.google/people/NicholasEtienneClinton/}{Nicholas Clinton} of Google and \href{https://www.usfca.edu/faculty/david-saah}{Dr.~David Saah} of the University of San Francisco Geospatial Analysis Lab. We (\href{https://www.ebenami.com/}{Elinor Benami} and \href{https://ozzycampos.com/}{Ozzy Campos}) thank them for this great public good and take responsibility for any errors that arose from our adaptation.

This work is licensed under a Creative Commons Attribution 4.0 International License.

\hypertarget{prelab-getting-started}{%
\section*{PreLab: Getting Started}\label{prelab-getting-started}}
\addcontentsline{toc}{section}{PreLab: Getting Started}

\hypertarget{overview}{%
\subsection*{Overview}\label{overview}}
\addcontentsline{toc}{subsection}{Overview}

The purpose of this lab is to introduce some of the functionality and structure of Google Earth Engine (GEE) before we get into the practical labs. This tutorial will provide a brief introduction to the GEE Javascript interface (the Code Editor) and using GEE resources. At the completion of the lab, you will be able to access GEE imagery, upload your own assets, and explore the metadata for a given feature.

\hypertarget{learning-outcomes}{%
\paragraph*{Learning Outcomes}\label{learning-outcomes}}
\addcontentsline{toc}{paragraph}{Learning Outcomes}

\begin{itemize}
\tightlist
\item
  Navigate basic GEE Resources
\item
  Describe the major GEE data types and their associated methods
\end{itemize}

\hypertarget{setting-up-an-account}{%
\paragraph*{Setting up an Account}\label{setting-up-an-account}}
\addcontentsline{toc}{paragraph}{Setting up an Account}

To begin, ensure you sign-up for the Google Earth Engine \href{https://signup.earthengine.google.com}{here}. Registration is free and straightforward, but it takes approximately 24 hours to be approved to use the code editor. While waiting, let's get familiar with the Google Earth Engine. The video below is a quick introduction to Google Earth Engine that Ozzy assembled to to get you familiar with the available resources.

\href{https://www.youtube.com/watch?v=Ypo28T6wPbQ}{Video}

\hypertarget{importing-data}{%
\paragraph*{Importing data}\label{importing-data}}
\addcontentsline{toc}{paragraph}{Importing data}

In addition to the petabytes of satellite imagery and products that GEE has available, Google Earth Engine also allows you to work with your own raster, vector, and tabular data.
This is process is automatically linked to the Google Drive account that signed up for GEE.

If you are not familiar with Google Drive, the `\href{https://support.google.com/a/users/answer/9282958?hl=en}{Getting Started Guide}' reviews the basics of initializing and organizing your Google Drive account. Although Google Cloud Platform Storage is beyond the scope of this course, below is some additional helpful documentation on working with external data.

\begin{itemize}
\tightlist
\item
  \href{https://developers.google.com/earth-engine/guides/asset_manager}{Managing Assets}
\item
  \href{https://developers.google.com/earth-engine/guides/image_upload}{Import Raster}
\item
  \href{https://developers.google.com/earth-engine/guides/table_upload}{Import Vector / Tabular Data} ** Note that GEE only supports Shapefiles and \texttt{.csv}files ***
\item
  \href{https://developers.google.com/earth-engine/guides/exporting}{Exporting Data}
\end{itemize}

\hypertarget{gecomputation-with-gee-server-vs.-client}{%
\paragraph*{Gecomputation with GEE: Server vs.~Client}\label{gecomputation-with-gee-server-vs.-client}}
\addcontentsline{toc}{paragraph}{Gecomputation with GEE: Server vs.~Client}

Understanding the basics of how Google Earth Engine works is critical for its effective use. The Developer's \href{https://developers.google.com/earth-engine/guides/concepts_overview}{overview} provides much more detail on the intricacies of how GEE processes data on the Google Cloud Platform, but in the simplest terms, there are two sides to the process - the \texttt{client} side and \texttt{server} side.

When you open your web browser and begin to work in the code editor, that is considered the \texttt{client} side. You can write JavaScript code in the editor and the code will be processed within your browser. The code below simply creates a variables \texttt{x} and \texttt{y}, adds them together as the variable \texttt{z} and prints the result, which shows up in the console of the code editor. Even though the code is written in the GEE editor, it plays no role in the execution of this code - your browser executes it.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ x }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \KeywordTok{var}\NormalTok{ y }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ z }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+}\NormalTok{ y}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

To begin using the cloud computing resources of GEE effectively, we can then call upon the server side of the operations. Let's say we want to import an image collection. In the snippet below, you can see that there is an \texttt{ee} before the \texttt{ImageCollection} constructor. In simple terms, this signals to Earth Engine that we will be using its resources. Without that indicator, GEE will cede operations to the server.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ sentinelCollection }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{\textquotesingle{}COPERNICUS/S2\_SR\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Over time, you will gain experience understanding the role of working with JavaScript on the \texttt{client} side and the \texttt{server} side, but the main point in this section is that when programming, we will be building `packages' that draw upon GEE resources to complete their operations.

An extension of this topic is listed \href{https://developers.google.com/earth-engine/guides/client_server}{here}, along with discussions of programming specific topics (i.e., mapping instead of looping).

\hypertarget{javascript}{%
\paragraph*{JavaScript}\label{javascript}}
\addcontentsline{toc}{paragraph}{JavaScript}

The intent of this course is not to teach the intricacies of programming within JavaScript. JavaScript is the core language for web development, and you will likely find that many of the tutorials and resources you find will not be directly relevant to the type of JavaScript that you will need to work in Earth Engine (ie, working with React, JQuery, dynamic app development, etc). JavaScript was chosen because it is an extremely popular language (\textasciitilde97\% of websites use it in some fashion) and as an object-oriented language, it is well-suited to pair objects (in this case, imagery provided by Google Earth Engine) with methods (such as using the \texttt{reduce} function to summarize the analytical information from a processed image).

Several excellent resources exist that can help you in working with JavaScript. One such resource is \href{https://javascript.info}{Javascript.info}, which provides a thorough overview of working with JavaScript. In this tutorial, focus on part I, as part II and III are focused on web development.

\href{https://www.w3schools.com/js/default.asp}{W3Schools} provides good information on each individual component of working with JavaScript. For instance, if you see the word \texttt{var} and wanted more information on it, W3Schools has some helpful definitions and code snippets that will be of use.

Finally, \href{http://www.javascriptbook.com}{JavaScript \& JQuery} is an excellent, well-designed book that goes through the fundamentals of working with JavaScript and provides helpful illustrations and use cases. The second half of the book is outside the scope of this course, but if you did want to extend your skill-set, this book is a great starting point.

\hypertarget{data-and-methods}{%
\subsection{Data and Methods}\label{data-and-methods}}

\textbf{Core Components of Google Earth Engine Operations}

Most Google Earth Engine tutorials begin with an introduction to the data structures and the operations you can use to analyze your data structures. To work effectively with GEE, it is essential that you understand these core components and how to complete basic operations with each of them.

\href{https://developers.google.com/earth-engine/guides}{Intro to Data}

\begin{itemize}
\tightlist
\item
  \href{https://developers.google.com/earth-engine/guides/image_overview}{\texttt{Image}}

  \begin{itemize}
  \tightlist
  \item
    Raster Image, a fundamental data type within Earth Engine
  \end{itemize}
\item
  \href{https://developers.google.com/earth-engine/guides/ic_creating}{\texttt{ImageCollection}}

  \begin{itemize}
  \tightlist
  \item
    A ``stack'' or sequence of images with the same attributes
  \end{itemize}
\item
  \href{https://developers.google.com/earth-engine/guides/geometries}{\texttt{Geometry}}

  \begin{itemize}
  \tightlist
  \item
    Vector data either built within Earth Engine or imported
  \end{itemize}
\item
  \href{https://developers.google.com/earth-engine/guides/features}{\texttt{Feature}}

  \begin{itemize}
  \tightlist
  \item
    \texttt{Geometry} with specific attributes.
  \end{itemize}
\item
  \href{https://developers.google.com/earth-engine/guides/feature_collections}{\texttt{FeatureCollection}}

  \begin{itemize}
  \tightlist
  \item
    Set of features that share a similar theme
  \end{itemize}
\item
  \href{https://developers.google.com/earth-engine/guides/reducers_intro}{\texttt{Reducer}}

  \begin{itemize}
  \tightlist
  \item
    A method used to compute statistics or perform aggregations on the data over space, time, bands, arrays, and other data structures.
  \end{itemize}
\item
  \href{https://developers.google.com/earth-engine/guides/joins_intro}{\texttt{Join}}

  \begin{itemize}
  \tightlist
  \item
    A method to combine datasets (\texttt{Image} or \texttt{Feature} collections) based on time, location, or another specified attribute
  \end{itemize}
\item
  \href{https://developers.google.com/earth-engine/guides/arrays_intro}{\texttt{Array}}

  \begin{itemize}
  \tightlist
  \item
    A flexible (albeit sometimes inefficient) data structure that can be used for multi-dimensional analyses.
  \end{itemize}
\end{itemize}

\hypertarget{images-and-image-collections}{%
\subsection{Images and Image Collections}\label{images-and-image-collections}}

\hypertarget{images}{%
\subsubsection{Images}\label{images}}

\textbf{Images} are \textbf{Raster} objects composed of:

\begin{itemize}
\tightlist
\item
  Bands, or layers with a unique:

  \begin{itemize}
  \tightlist
  \item
    Name
  \item
    Data type
  \item
    Scale
  \item
    Mask
  \item
    Projection
  \end{itemize}
\item
  Metadata, stored as a set of properties for that band.
\end{itemize}

You can create images from constants, lists, or other objects. In the code editor `docs', you'll find numerous processes you can apply to images.

Ensure that you do not confuse an individual image with an image collection, which is a set of images grouped together, most often as a time series, and often known as a \texttt{stack}.

\hypertarget{image-collections}{%
\subsubsection{Image Collections}\label{image-collections}}

Let's analyze the code below, which is an established method of extracting one individual image from an image collection. You can copy and paste this code snippet into the code editor to follow along.

On the first line, we see that we are creating a JavaScript variable named \texttt{first}, and then using \texttt{ee} in front of \texttt{ImageCollection}, which signifies we are requesting information from GEE. The data we are importing (`COPERNICUS/S2\_SR') is the Sentinel-2 MSI: MultiSpectral Instrument, Level-2A, with more information found in the dataset \href{https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR?hl=en\#description}{documentation}.

The next four steps further refine the extraction of an image from an image collection.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{.filterBounds} filters data to the area specified, in this case a geometry Point that was created within GEE.
\item
  \texttt{.filterDate} filters between the two dates specified (filtering down to images collected in 2019)
\item
  \texttt{.sort} organizes the images in descending order based upon the perentage of cloudy pixels (this is an attribute of the image, which can be found in the `Image Properties' tab in the dataset documentation)
\item
  \texttt{.first} is a JavaScript method of choosing the first image in the list of sorted images
\end{enumerate}

As a result, we can now use the JavaScript variable `first' to visualize the image.

\texttt{Map.centerObject()} centers the map on the image, and the number is the amount of zoom. The higher that value is, the more zoomed in the image is - you'll likely have to adjust via trial-and-error to find the best fit.

\texttt{Map.addLayer()} adds the visualization layer to the map. Image/image collections will each have a unique naming convention of their bands, so you will have to reference the documentation. GEE uses Red-Green-Blue ordering (as opposed to the popular Computer Vision framework, OpenCV, which uses a Blue-Green-Red convention). \texttt{min} and \texttt{max} are the values that normalize the value of each pixel to the conventional 0-255 color scale. In this case, although the maximum value of a pixel in all three of those bands is 2000, for visualization purposes GEE will normalize that to 255, the max value in a standard 8-bit image.

There is a comprehensive \href{https://developers.google.com/earth-engine/guides/image_visualization}{guide} to working on visualization with different types of imagery that goes quite in-depth on working with different types of imagery. It is a worthwhile read, and covers some interesting topics such as false-color composites, mosaicking and single-band visualization. Work with some of the code-snippets to understand how to build visualizations for different sets of imagery.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ first }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{\textquotesingle{}COPERNICUS/S2\_SR\textquotesingle{}}\NormalTok{)}
                \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{(}\OperatorTok{{-}}\FloatTok{70.48}\OperatorTok{,} \FloatTok{43.3631}\NormalTok{))}
                \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2019{-}01{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2019{-}12{-}31\textquotesingle{}}\NormalTok{)}
                \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUDY\_PIXEL\_PERCENTAGE\textquotesingle{}}\NormalTok{)}
                \OperatorTok{.}\FunctionTok{first}\NormalTok{()}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{centerObject}\NormalTok{(first}\OperatorTok{,} \DecValTok{11}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(first}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{2000}\NormalTok{\}}\OperatorTok{,} \StringTok{\textquotesingle{}first\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\hypertarget{sensed-versus-derived-imagery}{%
\subsubsection{Sensed versus Derived Imagery}\label{sensed-versus-derived-imagery}}

One additional note: GEE provides a rich suite of datasets, and while many of them are traditional sensed imagery, others are derived datasets. For instance, the \emph{Global Map of Oil Palm Plantations} \href{https://developers.google.com/earth-engine/datasets/catalog/BIOPAMA_GlobalOilPalm_v1}{dataset} provides is derived from analysis on the Sentinel composite imagery. If you look at the `Bands', there are only three values, which refer to categories of palm plantations. Datasets such as these will have different methods for visualizing the data or working as a mosaic.

\hypertarget{geometries}{%
\subsection{Geometries}\label{geometries}}

Google Earth Engine handles vector data with the Geometry type. Traditionally, this means

\begin{itemize}
\tightlist
\item
  Point
\item
  Line
\item
  Polygon
\end{itemize}

However, GEE has several different nuances.

\begin{itemize}
\tightlist
\item
  \texttt{Point}
\item
  \texttt{LineString}

  \begin{itemize}
  \tightlist
  \item
    List of Points that do not start and end at the same location
  \end{itemize}
\item
  \texttt{LinearRing}

  \begin{itemize}
  \tightlist
  \item
    LineString which does start and end at the same location
  \end{itemize}
\item
  \texttt{Polygon}

  \begin{itemize}
  \tightlist
  \item
    List of LinearRing's - first item of the list is the outer shell and other components of the list are interior shells
  \end{itemize}
\end{itemize}

GEE also recognizes \texttt{MultiPoint}, \texttt{MultiLineString} and \texttt{MultiPolygon}, which are simply collections of more than one element. Additionally, you can combine any of these together to form a \texttt{MultiGeometry}. Here is a quick \href{https://www.youtube.com/watch?v=OdBhndxgN48}{video} of working with the Geometry tools within GEE.

Once you have a set of geometries, there are geospatial operations you can use for analysis, such as building buffer zones, area analysis, rasterization, etc. The \href{https://developers.google.com/earth-engine/guides/geometric_operations}{documentation} contains some basic examples to show you how to get started, although there are many more functions listed under the `Docs' tab in the Code Editor.

\begin{figure}
\includegraphics[width=0.8\linewidth]{./im/im_01_01} \caption{A view of the google earth engine code editor}\label{fig:code-editor}
\end{figure}

\hypertarget{features-and-feature-collections}{%
\subsection{Features and Feature Collections}\label{features-and-feature-collections}}

\hypertarget{features}{%
\subsubsection{Features}\label{features}}

At the most basic definition, a Feature in GEE is an object which stores a \texttt{geometry} property (\texttt{Point}, \texttt{Line}, \texttt{Polygon}) along with it's associated properties. GEE uses the GeoJSON format to store and transmit these features. In the previous video, we saw how to build geometries within Google Earth Engine, a feature adds meaningful information to it. This would be a good section to review working with dictionaries with JavaScript.

Let's say we created an individual point, which we want to associate with data that we collected. The first line establishes the variable \texttt{point}, which is then used as the \texttt{geometry} to create a \texttt{feature}. The curly braces represent a JavaScript dictionary, which creates Key:Value pairs, which in our case is the type of tree and a measurement of the size. this new variable, \texttt{treeFeature}, now contains geographic information along with attribute data about that point.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// geometry created from within GEE}
\KeywordTok{var}\NormalTok{ point }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{([}\OperatorTok{{-}}\FloatTok{79.68}\OperatorTok{,} \FloatTok{42.06}\NormalTok{])}\OperatorTok{;}
\CommentTok{// Create a Feature from the geometry}
\KeywordTok{var}\NormalTok{ treeFeature }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(point}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{type}\OperatorTok{:} \StringTok{\textquotesingle{}Pine\textquotesingle{}}\OperatorTok{,} \DataTypeTok{size}\OperatorTok{:} \DecValTok{15}\NormalTok{\})}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Obviously this is just one point, but JavaScript and GEE engine provide functionality for bringing different data sources together and automatically associating geometries with attribute data. This can be done within GEE or outside, depending on your preferences.

\hypertarget{feature-collections}{%
\subsubsection{Feature Collections}\label{feature-collections}}

Just like the relationship between images and image collections, Feature Collections are Features that can be grouped together for ease of use and analysis. They can be different types and combinations of geometry, as well as associated tabular data. The code segment from the documentation consolidates the operations discussed earlier. Each line has an interior layer which creates the geometry (\texttt{ee.Geometry.-\/-\/-()} ), which is then associated with attribute data (information within the \{\} ) and then converted to a Feature. This variable is a JavaScript\texttt{list}, which contains three separate features. This is then converted to a Feature Collection with the command \texttt{ee.FeatureCollection(features)}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Make a list of Features.}
\KeywordTok{var}\NormalTok{ features }\OperatorTok{=}\NormalTok{ [}
\NormalTok{  ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Rectangle}\NormalTok{(}\FloatTok{30.01}\OperatorTok{,} \FloatTok{59.80}\OperatorTok{,} \FloatTok{30.59}\OperatorTok{,} \FloatTok{60.15}\NormalTok{)}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{name}\OperatorTok{:} \StringTok{\textquotesingle{}Voronoi\textquotesingle{}}\NormalTok{\})}\OperatorTok{,}
\NormalTok{  ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{(}\OperatorTok{{-}}\FloatTok{73.96}\OperatorTok{,} \FloatTok{40.781}\NormalTok{)}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{name}\OperatorTok{:} \StringTok{\textquotesingle{}Thiessen\textquotesingle{}}\NormalTok{\})}\OperatorTok{,}
\NormalTok{  ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{(}\FloatTok{6.4806}\OperatorTok{,} \FloatTok{50.8012}\NormalTok{)}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{name}\OperatorTok{:} \StringTok{\textquotesingle{}Dirichlet\textquotesingle{}}\NormalTok{\})}
\NormalTok{]}\OperatorTok{;}

\CommentTok{// Create a FeatureCollection from the list and print it.}
\KeywordTok{var}\NormalTok{ fromList }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{FeatureCollection}\NormalTok{(features)}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(fromList)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

If you take this code block and run it in Google Earth Engine, you can see the information that is contained within the FeatureCollection, which has three elements (Features) and two columns (the \texttt{index} and the \texttt{properties}). By clicking on the dropdown next to each one, you can see that the first feature is a Polygon that has the name of `Voronoi'.

\begin{center}\includegraphics[width=0.5\linewidth]{./im/im_01_02} \end{center}

Once you have information in a Feature Collection, you can filter it to find specific information, such as the name of an object or based on the size of a polygon, or provide aggregated analysis. The \href{https://developers.google.com/earth-engine/guides/features}{documentation} on working with Feature Collections is comprehensive, and provides many ideas on how to use them efficiently in in your analysis.

\hypertarget{methods-reducers}{%
\subsection{Methods: Reducers}\label{methods-reducers}}

Up until now, we have focused on objects: Images, Features, and Geometries. Reducers are a method of aggregating data for analysis. For instance, we could take an Image Collection and use \texttt{reducer} to find the average value at each pixel, resulting in a single layer. Or we could reduce an image to a set of regions, grouping similar data together to create a simplifed map. The applications of Reducer are endless, and can be applied to both Images and Features. There are different functions for different object types, and Reducer can be both combined and sequenced to create a chain of analysis. From the documentation, the code chunk below creates the variable \texttt{collection} which is a collection that is filtered to the year 2016 and defined to a specific point. The variable \texttt{extrema} then reduces the dataset to identify the minimum and maximum value at that specific point for every band.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Load and filter the Sentinel{-}2 image collection.}
\KeywordTok{var}\NormalTok{ collection }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{\textquotesingle{}COPERNICUS/S2\textquotesingle{}}\NormalTok{)}
    \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2016{-}01{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2016{-}12{-}31\textquotesingle{}}\NormalTok{)}
    \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{([}\OperatorTok{{-}}\FloatTok{81.31}\OperatorTok{,} \FloatTok{29.90}\NormalTok{]))}\OperatorTok{;}
\CommentTok{// Reduce the collection.}
\KeywordTok{var}\NormalTok{ extrema }\OperatorTok{=}\NormalTok{ collection}\OperatorTok{.}\FunctionTok{reduce}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{minMax}\NormalTok{())}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

If you print \texttt{extrema} in the console, you can see that the result is 32 separate `bands', which represents the minimum and maximum value for all 16 bands in the Sentinel data. In the screenshot below, you can expand the first `band', which identifies the attributes of the minimum value of Band 1.

\begin{center}\includegraphics[width=0.5\linewidth]{./im/im_01_03} \end{center}

There are hundreds of different operations for using \texttt{Reducer}, with the functions listed on the left hand table under `Docs'. Certain functions will only work with specific object types, but follow along with the Reducer \href{https://developers.google.com/earth-engine/guides/reducers_intro}{documentation} to get a better understanding of how to aggregate data and extract meaningful results. Getting familiar with Reducer is an essential component to working with Google Earth Engine.

\begin{center}\includegraphics[width=0.5\linewidth]{./im/im_01_04} \end{center}

\hypertarget{joins-and-arrays}{%
\subsection{Joins and Arrays}\label{joins-and-arrays}}

\hypertarget{join}{%
\subsubsection{Join}\label{join}}

If you have programmed in the past, joining data togetgher is likely a familiar concept. This process assicates information from one set of data with relevant data from another set on a specific attribute. Let's say you have an Image Collection of Landsat data that is filtered to the first six months of the year 2016 and a bounding box of your area of study. You also have a table of Redwood tree locations that is filtered to the same area of study, although it contains information over the past decade. You can use a Join to associate information about the trees from the Feature Collection and include it in the Image Collection, keeping only the relevant data. You now have a dataset with useful information from both the Image Collection and Feature Collection in one location. Although there are different types of joins, the process brings information together, keeping only relevant information. The \href{https://developers.google.com/earth-engine/guides/joins_save_all}{documentation} on Joins goes over specific examples and concepts, but a crucial component is understanding the type of join you need the three most prominent within GEE are:

\begin{itemize}
\tightlist
\item
  Left Join

  \begin{itemize}
  \tightlist
  \item
    Keeps all the information from the primary dataset, and only information that joins from the secondary datset
  \end{itemize}
\item
  Inner Join

  \begin{itemize}
  \tightlist
  \item
    Keeps only the information where the primary and secondary data match
  \end{itemize}
\item
  Spatial Join

  \begin{itemize}
  \tightlist
  \item
    A join based on spatial location (ie, keep only the geometry points that fall within a specified buffer)
  \end{itemize}
\end{itemize}

GEE provides some unique types of joins, including `Save-All', `Save-Best' and `Save-First', which are useful if you want to look at a specific area.

\hypertarget{arrays}{%
\subsubsection{Arrays}\label{arrays}}

Arrays are a collection of data where information is stored contiguously - matrices are a multi-dimensional array. For instance, an image might have 1024 rows and 1024 columns. Each row is an array, each column is an array, and taken together, you have a 2-dimensional array, also known as a matrix. If the image has three separate color channels, then that is a 3-dimensional array. Some of the terminology changes depending on discipline (ie, physics vs.~computer science), but if you are familiar with working with matrices and arrays in programming languages such as Matlab or OpenCV, it is important to understand the role of arrays within GEE.

In fact, Google Earth Engine states that working with arrays outside of the established functions that they have built is not recommended, as GEE is not specifically designed for array-based math, and will lead to unoptimized performance.

There is a very informative \href{https://developers.google.com/earth-engine/guides/arrays_intro}{video} that delves into the engineering behind Google Earth Engine, but in this course we will only be doing a limited amount with array transformations and Eigen Analysis. In many cases, you will probably be better off aggregating the specific data and then conducting array mathematics with programming frameworks geared to that context.

\hypertarget{additional-resources}{%
\subsection{Additional Resources}\label{additional-resources}}

\begin{itemize}
\tightlist
\item
  Google Earth Engine \href{https://earthengine.google.com}{link}
\item
  Code Editor \href{https://developers.google.com/earth-engine/guides/playground?hl=en}{Map} -- what all the features on the code editor mean
\item
  \href{https://developers.google.com/earth-engine/datasets/}{Datasets}
\item
  \href{https://earthengine.google.com/case_studies/}{Case Studies}
\item
  Google Earth Engine \href{https://medium.com/google-earth}{Blog}
\item
  \href{https://developers.google.com/earth-engine/tutorials/tutorials}{Video} tutorials on using GEE (from the Earth Engine Users' Summit)
\end{itemize}

\hypertarget{lab1}{%
\section{Remote Sensing Background}\label{lab1}}

\hypertarget{overview-1}{%
\subsection*{Overview}\label{overview-1}}
\addcontentsline{toc}{subsection}{Overview}

The purpose of this lab is to introduce digital images, datum, and projections, as well as demonstrate concepts of spatial, spectral, temporal and radiometric resolution. You will be introduced to image data from several sensors aboard various platforms. At the completion of the lab, you will be able to understand the difference between remotely sensed datasets based on sensor characteristics and how to choose an appropriate dataset based on these concepts.

\hypertarget{learning-outcomes-1}{%
\paragraph*{Learning Outcomes}\label{learning-outcomes-1}}
\addcontentsline{toc}{paragraph}{Learning Outcomes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Describe the following terms:

  \begin{itemize}
  \tightlist
  \item
    Digital image
  \item
    Datum
  \item
    Projection
  \item
    Resolution (spatial, spectral, temporal, radiometric)
  \end{itemize}
\item
  Navigate the Google Earth Engine console to gather information about a digital image
\item
  Evaluate the projection and attributes of a digital image
\item
  Apply image visualization code in GEE to visualize a digital image
\end{enumerate}

\hypertarget{what-is-a-digital-image}{%
\subsection{What is a digital image?}\label{what-is-a-digital-image}}

A digital image is a matrix of same-sized pixels that are each defined by two main attributes: (1) the position, as defined by rows and columns and (2) the a value associated with that position.

A digital image 8 pixels wide by 8 pixels tall could thus look like the image below. Note though you can reference the position from a given axis, typically, image processing uses the top-left of an image as the reference point, as in the below image.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{./im/im_02_01} 

}

\caption{Digital Image Example}\label{fig:digimage}
\end{figure}

A ``traditional'' optical photograph typically represents three layers (often the brightness values represented in the Red, Blue, and Green portions of the electromagnetic spectrum). Together, these three layers create a full-color photograph that is represented by a three dimensional matrix where pixel position is characterized by the (1) row (2) column (3) \emph{and} layer.

Digital images are also often called \href{https://en.wikipedia.org/wiki/Raster_graphics}{rasters}, and ESRI has a great overview of rasters used in geospatial analysis featured \href{https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/what-is-raster-data.htm}{here}.

\hypertarget{from-digital-image-to-geospatial-image}{%
\subsubsection{From digital image to geospatial image}\label{from-digital-image-to-geospatial-image}}

A digital image is a flat, square surface. However, the earth is round (spherical).

Thus to make use of the synoptic properties of remote sensing data, we need to align the pixels in our image to a real-world location. There's quite a bit of mathematics involved in this process, but we will focus on two main components - establishing a Geographic Coordinate System (GCS) and a Projected Coordinate System (PCS).

The GCS defines the spherical location of the image whereas the PCS defines how the grid around that location is constructed. Because the earth is not a perfect sphere, there are different GCS for different regions, such as `North American Datum: 83' which is used to accurately define North America, and `World Geodetic System of 1984', which is used globally.

The PCS then constructs a flat grid around the GCS in which you can create a relationship between each pixel of a 2-dimensional image to the corresponding area on the world. Some of the common PCS formats include EPSG, Albers Conic, Lambert, Eckert, Equidistant, etc. Different types of PCS's are designed for different formats, as the needs of a petroleum engineer working over a few square miles will differ from than a climate change researcher at the scope of the planet, for example.

ESRI (the makers of ArcGIS) has an \href{https://www.esri.com/arcgis-blog/products/arcgis-pro/mapping/gcs_vs_pcs/}{article} discussing the difference between GCS and PCS that provides further context. While you should be aware of the differences between GCS and PCS's -- especially when you intend to run analyses on the data you download from GEE in another system such as R, Python, or Arc -- GEE takes care of much of the complexity of these differences behind the scenes. Further documentation on the GEE methodology can be found \href{https://developers.google.com/earth-engine/guides/projections}{here}. In our first exercise, we will show you how to identify the PCS so you can understand the underlying structure.

Furthermore, remote sensing data often consists of more than the three Red-Green-Bluye layers we're used to seeing visualized in traditional photography. For instance, the Landsat 8 sensor has eleven bands capturing information from eleven different portions of the electromagentic spectrum, including near infrared (NIR) and thermal bands that are invisible to the human eye. Many Machine Learning projects also involve normalizing or transforming the information contained within each of these layers, which we will return to in subsequent labs.

In sum, understanding the bands available in your datasets, identifying which bands are necessary (and appropriate) for your analysis, and ensuring that these data represent consistent spatial locations is essential. While GEE simplifies many complex calculations behind the scenes, this lab will help us unpack the products available to us and their essential characteristics.

\hypertarget{summary}{%
\paragraph*{Summary}\label{summary}}
\addcontentsline{toc}{paragraph}{Summary}

Each pixel has a position, measured with respect to the axes of some coordinate reference system (CRS), such as a \href{https://en.wikipedia.org/wiki/Geographic_coordinate_system}{geographic coordinate system}. A CRS in Earth Engine is often referred to as a projection, since it combines a shape of the Earth with a \href{https://en.wikipedia.org/wiki/Geodetic_datum}{datum} and a transformation from that spherical shape to a flat map, called a \href{https://en.wikipedia.org/wiki/Map_projection}{projection}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{./im/im_02_02} 

}

\caption{A pixel, raster, and a CRS}\label{fig:pixel}
\end{figure}

\hypertarget{visualize-a-digital-image}{%
\subsubsection{Visualize a Digital Image}\label{visualize-a-digital-image}}

Let's view a digital image in GEE to better understand this concept:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In the map window of GEE, click on the Point geometry tool using the \href{https://developers.google.com/earth-engine/playground\#geometry-tools}{geometry drawing tools} to define your area of interest (for the purposes of consistency in this exercise, place a point on the Virginia Tech Drillfield, which will bring you roughly to
  \texttt{{[}-80.42,37.23{]}}). As a reminder, you can find more information on geometry drawing tools in GEE's Guides. Name the import \texttt{point}.
\item
  Import NAIP imagery by searching for `naip' and choosing the \emph{`NAIP: National Agriculture Imagery Program'} raster dataset. Name the import \texttt{naip}.
\item
  Get a single, recent NAIP image over your study area and inspect it:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//  Get a single NAIP image over the area of interest.  }
\KeywordTok{var}\NormalTok{  image }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(naip  }
                      \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(point)}
                      \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}system:time\_start\textquotesingle{}}\OperatorTok{,} \KeywordTok{false}\NormalTok{)}
                      \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}      
\CommentTok{//  Print the image to the console.  }
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Inspect the image object:\textquotesingle{}}\OperatorTok{,}\NormalTok{ image)}\OperatorTok{;}     
\CommentTok{//  Display the image with the default visualization.  }
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{centerObject}\NormalTok{(point}\OperatorTok{,} \DecValTok{18}\NormalTok{)}\OperatorTok{;}  
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}Original image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Expand the image object that is printed to the console by clicking on the dropdown triangles. Expand the property called \texttt{bands} and expand one of the bands (0, for example). Note that the CRS transform is stored in the \texttt{crs\_transform} property underneath the band dropdown and the CRS is stored in the \texttt{crs} property, which references an EPSG code.

  \begin{quote}
  \textbf{EPSG Codes} are 4-5 digit numbers that represent CRS definitions. The acronym EPGS, comes from the (now defunct) European Petroleum Survey Group. The CRS of this image is \href{https://spatialreference.org/ref/epsg/nad83-utm-zone-17n/}{EPSG:26917}. You can often learn more about those \href{http://www.epsg-registry.org/}{EPSG codes} from \href{http://spatialreference.org/}{thespatialreference.org} or from the \href{https://epsg.org/home.html}{ESPG homepage}.
  \end{quote}

  \begin{quote}
  The CRS transform is a list \texttt{{[}m00,\ m01,\ m02,\ m10,\ m11,\ m12{]}} in the notation of \href{http://docs.oracle.com/javase/7/docs/api/java/awt/geom/AffineTransform.html}{this reference}. The CRS transform defines how to map pixel coordinates to their associated spherical coordinate through an affine transformation. While affine transformations are beyond the scope of this class, more information can be found at \href{https://rasterio.readthedocs.io/en/latest/topics/georeferencing.html}{Rasterio}, which provides detailed documentation for the popular Python library designed for working with geospatial data.
  \end{quote}
\item
  In addition to using the dropdowns, you can also access these data programmatically with the \texttt{.projection()} method:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Display the projection of band 0}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Inspect the projection of band 0:\textquotesingle{}}\OperatorTok{,}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\DecValTok{0}\NormalTok{)}\OperatorTok{.}\FunctionTok{projection}\NormalTok{())}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Note that the projection can differ by band, which is why it's good practice to inspect the projection of individual image bands.
\item
  (If you call \texttt{.projection()} on an image for which the projection differs by band, you'll get an error.) Exchange the NAIP imagery with the Planet SkySat MultiSpectral image collection, and note that the error occurs because the `P' band has a different pixel size than the others.
\item
  Explore the \texttt{ee.Projection} docs to learn about useful methods offered by the \texttt{Projection} object. To play with projections offline, try \href{http://www.giss.nasa.gov/tools/gprojector/}{this tool}.
\end{enumerate}

\hypertarget{digital-image-visualization-and-stretching}{%
\subsubsection{Digital Image Visualization and Stretching}\label{digital-image-visualization-and-stretching}}

You've learned about how an image stores pixel data in each band as digital numbers (DNs) and how the pixels are organized spatially. When you add an image to the map, Earth Engine handles the spatial display for you by recognizing the projection and putting all the pixels in the right place. However, you must specify how to stretch the DNs to make an 8-bit display image (e.g., the \texttt{min} and \texttt{max} visualization parameters). Specifying \texttt{min} and \texttt{max} applies (where DN' is the displayed value):

\[ DN' =   \frac{ 255 (DN - min)}{(max - min)} \]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  To apply a \href{https://en.wikipedia.org/wiki/Gamma_correction}{gamma correction} (DN' = DN\(_\gamma\)), use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Display gamma stretches of the input image.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{.}\FunctionTok{visualize}\NormalTok{(\{}\DataTypeTok{gamma}\OperatorTok{:} \FloatTok{0.5}\NormalTok{\})}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}gamma = 0.5\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{.}\FunctionTok{visualize}\NormalTok{(\{}\DataTypeTok{gamma}\OperatorTok{:} \FloatTok{1.5}\NormalTok{\})}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}gamma = 1.5\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

  Note that gamma is supplied as an argument to \href{https://developers.google.com/earth-engine/apidocs/ee-image-visualize}{image.visualize()} so that you can click on the map to see the difference in pixel values (try it!). It's possible to specify \texttt{gamma}, \texttt{min}, and \texttt{max} to achieve other unique visualizations.
\item
  To apply a \href{https://en.wikipedia.org/wiki/Histogram_equalization}{histogram equalization} stretch, use the \href{https://devsite.googleplex.com/earth-engine/image_visualization\#styled-layer-descriptors}{\texttt{sldStyle()}} method

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Define a RasterSymbolizer element with \textquotesingle{}\_enhance\_\textquotesingle{} for a placeholder.}
  \KeywordTok{var}\NormalTok{ histogram\_sld }\OperatorTok{=}
    \StringTok{\textquotesingle{}\textless{}RasterSymbolizer\textgreater{}\textquotesingle{}} \OperatorTok{+}
      \StringTok{\textquotesingle{}\textless{}ContrastEnhancement\textgreater{}\textless{}Histogram/\textgreater{}\textless{}/ContrastEnhancement\textgreater{}\textquotesingle{}} \OperatorTok{+}
      \StringTok{\textquotesingle{}\textless{}ChannelSelection\textgreater{}\textquotesingle{}} \OperatorTok{+}
        \StringTok{\textquotesingle{}\textless{}RedChannel\textgreater{}\textquotesingle{}} \OperatorTok{+}
          \StringTok{\textquotesingle{}\textless{}SourceChannelName\textgreater{}R\textless{}/SourceChannelName\textgreater{}\textquotesingle{}} \OperatorTok{+}
        \StringTok{\textquotesingle{}\textless{}/RedChannel\textgreater{}\textquotesingle{}} \OperatorTok{+}
        \StringTok{\textquotesingle{}\textless{}GreenChannel\textgreater{}\textquotesingle{}} \OperatorTok{+}
          \StringTok{\textquotesingle{}\textless{}SourceChannelName\textgreater{}G\textless{}/SourceChannelName\textgreater{}\textquotesingle{}} \OperatorTok{+}
        \StringTok{\textquotesingle{}\textless{}/GreenChannel\textgreater{}\textquotesingle{}} \OperatorTok{+}
        \StringTok{\textquotesingle{}\textless{}BlueChannel\textgreater{}\textquotesingle{}} \OperatorTok{+}
          \StringTok{\textquotesingle{}\textless{}SourceChannelName\textgreater{}B\textless{}/SourceChannelName\textgreater{}\textquotesingle{}} \OperatorTok{+}
        \StringTok{\textquotesingle{}\textless{}/BlueChannel\textgreater{}\textquotesingle{}} \OperatorTok{+}
      \StringTok{\textquotesingle{}\textless{}/ChannelSelection\textgreater{}\textquotesingle{}} \OperatorTok{+}
    \StringTok{\textquotesingle{}\textless{}/RasterSymbolizer\textgreater{}\textquotesingle{}}\OperatorTok{;}

  \CommentTok{// Display the image with a histogram equalization stretch.}
  \BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{.}\FunctionTok{sldStyle}\NormalTok{(histogram\_sld)}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}Equalized\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

  The \href{https://devsite.googleplex.com/earth-engine/image_visualization\#styled-layer-descriptors}{\texttt{sldStyle()}} method requires image statistics to be computed in a region (to determine the histogram).
\end{enumerate}

\hypertarget{spatial-resolution}{%
\subsection{Spatial Resolution}\label{spatial-resolution}}

In the present context, spatial resolution often means pixel size. In practice, spatial resolution depends on the projection of the sensor's instantaneous field of view (IFOV) on the ground and how a set of radiometric measurements are resampled into a regular grid. To see the difference in spatial resolution resulting from different sensors, let's visualize data at different scales from different sensors.

\hypertarget{modis}{%
\subsubsection{MODIS}\label{modis}}

There are two Moderate Resolution Imaging Spectro-Radiometers (\href{http://modis.gsfc.nasa.gov/}{MODIS}) aboard the \href{http://terra.nasa.gov/}{Terra} and \href{http://aqua.nasa.gov/}{Aqua} satellites. Different MODIS \href{http://modis.gsfc.nasa.gov/about/specifications.php}{bands} produce data at different spatial resolutions. For the visible bands, the lowest common resolution is 500 meters (red and NIR are 250 meters). Data from the MODIS platforms are used to produce a large number of data sets having daily, weekly, 16-day, monthly, and annual data sets. Outside this lab, you can find a list of MODIS land products \href{https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table}{here}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Search for `\href{https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/myd09ga_v006}{MYD09GA}' and import `\emph{MYD09GA.006 Aqua Surface Reflectance Daily Global 1km and 500m}'. Name the import \texttt{myd09}.
\item
  Zoom the map to San Francisco (SFO) airport:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Define a region of interest as a point at SFO airport.}
\KeywordTok{var}\NormalTok{ sfoPoint }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{(}\OperatorTok{{-}}\FloatTok{122.3774}\OperatorTok{,} \FloatTok{37.6194}\NormalTok{)}\OperatorTok{;}

\CommentTok{// Center the map at that point.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{centerObject}\NormalTok{(sfoPoint}\OperatorTok{,} \DecValTok{16}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  To display a false-color MODIS image, select an image acquired by the Aqua MODIS sensor and display it for SFO:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get a surface reflectance image from the MODIS MYD09GA collection.}
\KeywordTok{var}\NormalTok{ modisImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(myd09}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2017{-}07{-}01\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}

\CommentTok{// Use these MODIS bands for red, green, blue, respectively.}
\KeywordTok{var}\NormalTok{ modisBands }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}sur\_refl\_b01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}sur\_refl\_b04\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}sur\_refl\_b03\textquotesingle{}}\NormalTok{]}\OperatorTok{;}

\CommentTok{// Define visualization parameters for MODIS.}
\KeywordTok{var}\NormalTok{ modisVis }\OperatorTok{=}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ modisBands}\OperatorTok{,} \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{3000}\NormalTok{\}}\OperatorTok{;}

\CommentTok{// Add the MODIS image to the map}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(modisImage}\OperatorTok{,}\NormalTok{ modisVis}\OperatorTok{,} \StringTok{\textquotesingle{}MODIS\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Note the size of pixels with respect to objects on the ground. (It may help to turn on the satellite basemap to see high-resolution data for comparison.) Print the size of the pixels (in meters) with:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get the scale of the data from the first band\textquotesingle{}s projection:}
\KeywordTok{var}\NormalTok{ modisScale }\OperatorTok{=}\NormalTok{ modisImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}sur\_refl\_b01\textquotesingle{}}\NormalTok{)}
\OperatorTok{.}\FunctionTok{projection}\NormalTok{()}\OperatorTok{.}\FunctionTok{nominalScale}\NormalTok{()}\OperatorTok{;}

\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}MODIS scale:\textquotesingle{}}\OperatorTok{,}\NormalTok{ modisScale)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Note these \texttt{MYD09} data are surface reflectance scaled by 10000 (not TOA reflectance), meaning that clever NASA scientists have done a fancy atmospheric correction for you!
\end{enumerate}

\hypertarget{multispectral-scanners}{%
\subsubsection{Multispectral Scanners}\label{multispectral-scanners}}

Multi-spectral scanners were flown aboard Landsats 1-5. (\href{https://landsat.gsfc.nasa.gov/multispectral-scanner-system}{MSS}) data have a spatial resolution of 60 meters.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Search for `landsat 5 mss' and import the result called \emph{`USGS Landsat 5 MSS Collection 1 Tier 2 Raw Scenes'}. Name the import \texttt{mss}.
\item
  To visualize MSS data over SFO (for a relatively cloud-free) image, use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Filter MSS imagery by location, date and cloudiness.   }
\KeywordTok{var}\NormalTok{ mssImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(mss     }
                        \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(}\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{getCenter}\NormalTok{())     }
                        \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2011{-}05{-}01\textquotesingle{}}\OperatorTok{,}  \StringTok{\textquotesingle{}2011{-}10{-}01\textquotesingle{}}\NormalTok{)     }
                        \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUD\_COVER\textquotesingle{}}\NormalTok{)     }
                        \CommentTok{//  Get the least cloudy image.     }
                        \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}  

\CommentTok{// Display the MSS image as a color{-}IR composite.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(mssImage}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B1\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{200}\NormalTok{\}}\OperatorTok{,} \StringTok{\textquotesingle{}MSS\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Check the scale (in meters) as before:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get the scale of the MSS data from its projection:}
\KeywordTok{var}\NormalTok{ mssScale }\OperatorTok{=}\NormalTok{ mssImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B1\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{projection}\NormalTok{()}\OperatorTok{.}\FunctionTok{nominalScale}\NormalTok{()}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}MSS scale:\textquotesingle{}}\OperatorTok{,}\NormalTok{ mssScale)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\hypertarget{thematic-mapper-tm}{%
\subsubsection{Thematic Mapper (TM)}\label{thematic-mapper-tm}}

The Thematic Mapper (\href{https://landsat.gsfc.nasa.gov/landsat-4-5/tm}{TM}) was flown aboard Landsats 4-5. (It was succeeded by the Enhanced Thematic Mapper (\href{https://landsat.gsfc.nasa.gov/about/enhanced-thematic-mapper}{ETM+}) aboard Landsat 7 and the Operational Land Imager (\href{https://landsat.gsfc.nasa.gov/landsat-8/operational-land-imager}{OLI}) / Thermal Infrared Sensor (\href{https://landsat.gsfc.nasa.gov/landsat-8/thermal-infrared-sensor-tirs}{TIRS}) sensors aboard Landsat 8.) TM data have a spatial resolution of 30 meters.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Search for `landsat 5 toa' and import the first result (which should be `\emph{USGS Landsat 5 TM Collection 1 Tier 1 TOA Reflectance}'. Name the import \texttt{tm}.
\item
  To visualize TM data over SFO, for approximately the same time as the MODIS image, use:

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{// Filter TM imagery by location, date and cloudiness.}
\KeywordTok{var}\NormalTok{ tmImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(tm}
            \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(}\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{getCenter}\NormalTok{())}
            \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2011{-}05{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2011{-}10{-}01\textquotesingle{}}\NormalTok{)}
            \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUD\_COVER\textquotesingle{}}\NormalTok{)}
            \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}

\CommentTok{// Display the TM image as a color{-}IR composite.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(tmImage}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.4}\NormalTok{\}}\OperatorTok{,} \StringTok{\textquotesingle{}TM\textquotesingle{}}\NormalTok{)}\OperatorTok{;} 
\end{Highlighting}
\end{Shaded}
\item
  For some hints about why the TM data is not the same date as the MSS data, see \href{https://www.usgs.gov/core-science-systems/nli/landsat/landsat-5?qt-science_support_page_related_con=0\#qt-science_support_page_related_con}{this page}.
\item
  Check the scale (in meters) as previously:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get the scale of the TM data from its projection:}
\KeywordTok{var}\NormalTok{ tmScale }\OperatorTok{=}\NormalTok{ tmImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B1\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{projection}\NormalTok{()}\OperatorTok{.}\FunctionTok{nominalScale}\NormalTok{()}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}TM scale:\textquotesingle{}}\OperatorTok{,}\NormalTok{ tmScale)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Question 1: By assigning the NIR, red, and green bands in RGB (4-3-2), what features appear bright red in a Landsat 5 image and why?}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{national-agriculture-imagery-program-naip}{%
\subsubsection{National Agriculture Imagery Program (NAIP)}\label{national-agriculture-imagery-program-naip}}

The National Agriculture Imagery Program (\href{http://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/}{NAIP}) is an effort to acquire imagery over the continental US on a 3-year rotation using airborne sensors. The imagery has a spatial resolution of 1-2 meters.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Search for `naip' and import the data set for \emph{`NAIP: National Agriculture Imagery Program'}. Name the import naip. Since NAIP imagery is distributed as quarters of Digital Ortho Quads at irregular cadence, load everything from the closest year to the examples in its acquisition cycle (2012) over the study area and \href{https://developers.google.com/earth-engine/guides/ic_composite_mosaic}{mosaic()} it:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get NAIP images for the study period and region of interest.}

\KeywordTok{var}\NormalTok{ naipImages }\OperatorTok{=}\NormalTok{ naip}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2012{-}01{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2012{-}12{-}31\textquotesingle{}}\NormalTok{)}
\OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(}\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{getCenter}\NormalTok{())}\OperatorTok{;}

\CommentTok{// Mosaic adjacent images into a single image.}
\KeywordTok{var}\NormalTok{ naipImage }\OperatorTok{=}\NormalTok{ naipImages}\OperatorTok{.}\FunctionTok{mosaic}\NormalTok{()}\OperatorTok{;}

\CommentTok{// Display the NAIP mosaic as a color{-}IR composite.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(naipImage}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}N\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}R\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{]\}}\OperatorTok{,} \StringTok{\textquotesingle{}NAIP\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Check the scale by getting the first image from the mosaic (a mosaic doesn't know what its projection is, since the mosaicked images might all have different projections), getting its projection, and getting its scale (meters):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get the NAIP resolution from the first image in the mosaic.}
\KeywordTok{var}\NormalTok{ naipScale }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(naipImages}\OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{.}
              \FunctionTok{projection}\NormalTok{()}\OperatorTok{.}\FunctionTok{nominalScale}\NormalTok{()}\OperatorTok{;}

\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}NAIP scale:\textquotesingle{}}\OperatorTok{,}\NormalTok{ naipScale)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Question 2: What is the scale of the most recent round of NAIP imagery for the sample area (2018), and how did you determine the scale?}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{spectral-resolution}{%
\subsection{Spectral Resolution}\label{spectral-resolution}}

Spectral resolution refers to the number and width of spectral bands in which the sensor takes measurements. You can think of the width of spectral bands as the wavelength intervals for each band. A sensor that measures radiance in multiple bands is called a \emph{multispectral} sensor (generally 3-10 bands), while a sensor with many bands (possibly hundreds) is called a \emph{hyperspectral} sensor (these are not hard and fast definitions). For example, compare the \href{http://landsat.gsfc.nasa.gov/?p=5779}{multi-spectral OLI} aboard Landsat 8 to \href{https://eo1.usgs.gov/sensors/hyperioncoverage}{Hyperion}, a hyperspectral sensor aboard the \href{https://eo1.usgs.gov/}{EO-1 satellite}.

A figure representing common optical sensors and their spectral resolution can be viewed below \href{https://www.researchgate.net/figure/Spectral-resolution-of-currently-available-optical-satellite-sensors-grouped-by-different_fig1_348695518}{(image source)}:

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{./im/im_02_03} 

}

\caption{Common Optical Sensors and their Spectral Resolution}\label{fig:spectralres}
\end{figure}

There is an easy way to check the number of bands in Earth Engine, but no way to get an understanding of the relative \emph{spectral response} of the bands, where spectral response is a function measured in the laboratory to characterize the detector.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  To see the number of bands in an image, use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get the MODIS band names as a List}
\KeywordTok{var}\NormalTok{ modisBands }\OperatorTok{=}\NormalTok{ modisImage}\OperatorTok{.}\FunctionTok{bandNames}\NormalTok{()}\OperatorTok{;}

\CommentTok{// Print the list.}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}MODIS bands:\textquotesingle{}}\OperatorTok{,}\NormalTok{ modisBands)}\OperatorTok{;}

\CommentTok{// Print the length of the list.}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Length of the bands list:\textquotesingle{}}\OperatorTok{,}\NormalTok{ modisBands}\OperatorTok{.}\FunctionTok{length}\NormalTok{())}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Note that only some of those bands contain radiometric data. Lots of them have other information, like quality control data. So the band listing isn't necessarily an indicator of spectral resolution, but can inform your investigation of the spectral resolution of the dataset. Try printing the bands from some of the other sensors to get a sense of spectral resolution.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Question 3.1: What is the spectral resolution of the MODIS instrument, and how did you determine it?}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Question 3.2: Investigate the bands available for the USDA NASS Cropland Data Layers (CDL). What does the band information for the CDL represent? Which band(s) would you select if you were interested in evaluating the extent of pasture areas in the US? }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{temporal-resolution}{%
\subsection{Temporal Resolution}\label{temporal-resolution}}

Temporal resolution refers to the \emph{revisit time}, or temporal \emph{cadence} of a particular sensor's image stream. Think of this as the frequency of pixels in a time series at a given location.

\hypertarget{modis-1}{%
\subsubsection{MODIS}\label{modis-1}}

MODIS (either Terra or Aqua) produces imagery at approximately a daily cadence. To see the time series of images at a location, you can \texttt{print()} the \texttt{ImageCollection}, filtered to your area and date range of interest. For example, to see the MODIS images in 2011:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Filter the MODIS mosaics to one year.   }
\KeywordTok{var}\NormalTok{ modisSeries }\OperatorTok{=}\NormalTok{ myd09}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2011{-}01{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2011{-}12{-}31\textquotesingle{}}\NormalTok{)}\OperatorTok{;}      

\CommentTok{// Print the filtered  MODIS ImageCollection.   }
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}MODIS series:\textquotesingle{}}\OperatorTok{,}\NormalTok{ modisSeries)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Expand the \texttt{features} property of the printed \texttt{ImageCollection} to see a \texttt{List} of all the images in the collection. Observe that the date of each image is part of the filename. Note the daily cadence. Observe that each MODIS image is a global mosaic, so there's no need to filter by location.

\hypertarget{landsat}{%
\subsubsection{Landsat}\label{landsat}}

Landsats (5 and later) produce imagery at 16-day cadence. TM and MSS are on the same satellite (Landsat 5), so it suffices to print the TM series to see the temporal resolution. Unlike MODIS, data from these sensors is produced on a scene basis, so to see a time series, it's necessary to filter by location in addition to time:

\begin{Shaded}
\begin{Highlighting}[]

   \CommentTok{// Filter to get a year\textquotesingle{}s worth of TM scenes.}
  \KeywordTok{var}\NormalTok{ tmSeries }\OperatorTok{=}\NormalTok{ tm}
  \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(}\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{getCenter}\NormalTok{())}
  \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2011{-}01{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2011{-}12{-}31\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
  
  \CommentTok{// Print the filtered TM ImageCollection. }
  \FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}TM series:\textquotesingle{}}\OperatorTok{,}\NormalTok{ tmSeries)}\OperatorTok{;}
  
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Again expand the \texttt{features} property of the printed \texttt{ImageCollection}. Note that a \href{http://landsat.usgs.gov/naming_conventions_scene_identifiers.php}{careful parsing of the TM image IDs} indicates the day of year (DOY) on which the image was collected. A slightly more cumbersome method involves expanding each Image in the list, expanding its properties and looking for the `DATE\_ACQUIRED' property.
\item
  To make this into a nicer list of dates, \href{https://en.wikipedia.org/wiki/Map_(higher-order_function)}{map()} a function over the ImageCollection. First define a function to get a Date from the metadata of each image, using the system properties:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ getDate }\OperatorTok{=} \KeywordTok{function}\NormalTok{(image) \{}
\CommentTok{// Note that you need to cast the argument}
\KeywordTok{var}\NormalTok{ time }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(image)}\OperatorTok{.}\FunctionTok{get}\NormalTok{(}\StringTok{\textquotesingle{}system:time\_start\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\CommentTok{// Return the time (in milliseconds since Jan 1, 1970) as a Date}
\ControlFlowTok{return}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Date}\NormalTok{(time)}\OperatorTok{;}
\NormalTok{\}}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Turn the \texttt{ImageCollection} into a \texttt{List} and\href{https://developers.google.com/earth-engine/getstarted\#mapping-what-to-do-instead-of-a-for-loop}{map() the function} over it:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ dates }\OperatorTok{=}\NormalTok{ tmSeries}\OperatorTok{.}\FunctionTok{toList}\NormalTok{(}\DecValTok{100}\NormalTok{)}\OperatorTok{.}\FunctionTok{map}\NormalTok{(getDate)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Print the result:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(dates)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Question 4 What is the temporal resolution of the Sentinel-2 satellites? How can you determine this from within GEE? }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{radiometric-resolution}{%
\subsection{Radiometric Resolution}\label{radiometric-resolution}}

Radiometric resolution refers to the ability of an imaging system to record many levels of brightness: \emph{coarse} radiometric resolution would record a scene with only a few brightness levels, whereas \emph{fine} radiometric resolution would record the same scene using many levels of brightness. Some also consider radiometric resolution to refer to the \emph{precision} of the sensing, or the level of \emph{quantization}.

Radiometric resolution is determined from the minimum radiance to which the detector is sensitive (Lmin), the maximum radiance at which the sensor saturates (Lmax), and the number of bits used to store the DNs (Q):

\[  \text{Radiometric resolution} = \frac{(L_{max} - L_{min})}{2^Q} \]

It might be possible to dig around in the metadata to find values for Lmin and Lmax, but computing radiometric resolution is generally not necessary unless you're studying phenomena that are distinguished by very subtle changes in radiance.

\hypertarget{resampling-and-reprojection}{%
\subsection{Resampling and ReProjection}\label{resampling-and-reprojection}}

Earth Engine makes every effort to handle projection and scale so that you don't have to. However, there are occasions where an understanding of projections is important to get the output you need. As an example, it's time to demystify the \href{https://developers.google.com/earth-engine/apidocs/ee-image-reproject}{reproject()} calls in the previous examples. Earth Engine requests inputs to your computations in the projection and scale of the output. The map attached to the playground has a \href{http://epsg.io/3857}{Maps Mercator projection}.

The scale is determined from the map's zoom level. When you add something to this map, Earth Engine secretly reprojects the input data to Mercator, resampling (with nearest neighbor) to screen resolution pixels based on the map's zoom level, then does all the computations with the reprojected, resampled imagery. In the previous examples, the reproject() calls force the computations to be done at the resolution of the input pixels: 1 meter.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Re-run the edge detection code with and without the reprojection (Comment out all previous \texttt{Map.addLayer()} calls except for the original one)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Zoom all the way in.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{centerObject}\NormalTok{(point}\OperatorTok{,} \DecValTok{21}\NormalTok{)}\OperatorTok{;}
\CommentTok{// Display edges computed on a reprojected image.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{.}\FunctionTok{convolve}\NormalTok{(laplacianKernel)}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{255}\NormalTok{\}}\OperatorTok{,} 
       \StringTok{\textquotesingle{}Edges with little screen pixels\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\CommentTok{// Display edges computed on the image at native resolution.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(edges}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{255}\NormalTok{\}}\OperatorTok{,} 
       \StringTok{\textquotesingle{}Edges with 1 meter pixels\textquotesingle{}}\NormalTok{)}\OperatorTok{;} 
\end{Highlighting}
\end{Shaded}

  What's happening here is that the projection specified in \texttt{reproject()} propagates backwards to the input, forcing all the computations to be performed in that projection. If you don't specify, the computations are performed in the projection and scale of the map (Mercator) at screen resolution.
\item
  You can control how Earth Engine resamples the input with \href{https://developers.google.com/earth-engine/guides/resample}{\texttt{resample()}}. By default, all resampling is done with the nearest neighbor. To change that, call \texttt{resample()} on the \emph{inputs}. Compare the input image, resampled to screen resolution with a bilinear and bicubic resampling:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Resample the image with bilinear instead of the nearest neighbor.}
\KeywordTok{var}\NormalTok{ bilinearResampled }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{resample}\NormalTok{(}\StringTok{\textquotesingle{}bilinear\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(bilinearResampled}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}input image, bilinear resampling\textquotesingle{}}\NormalTok{)}\OperatorTok{;}

\CommentTok{// Resample the image with bicubic instead of the nearest neighbor.}
\KeywordTok{var}\NormalTok{ bicubicResampled }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{resample}\NormalTok{(}\StringTok{\textquotesingle{}bicubic\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(bicubicResampled}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}input image, bicubic resampling\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  Try zooming in and out, comparing to the input image resampled with the nearest with nearest neighbor (i.e.~without \texttt{resample()} called on it).

  \textbf{You should rarely, if ever, have to use \texttt{reproject()} and \texttt{resample()}.} Do not use \texttt{reproject()} or \texttt{resample()} unless necessary. They are only used here for demonstration purposes.
\end{enumerate}

\hypertarget{additional-exercises}{%
\subsection{Additional Exercises}\label{additional-exercises}}

Now that we have some familiarity with higher quality images, lets look at a few from the (broken) Landsat 7 satellite. Using your downloading skills, now select an image that contains the Blacksburg area with minimal cloud cover from Landsat 7 (for now, using the Collection 1 Tier 1 calibrated top-of-atmosphere (TOA) reflectance data product). Look at the image.

\textbf{Question 5: What is the obvious (hint: post-2003) problem with the Landsat 7 image? What is the nature of that problem and what have some researchers done to try to correct it?} (please research online in addition to using what you have learned in class/from the book)
---

\textbf{Question 6: Name three major changes you can view in the Blacksburg Area in the last decade using any of the above imagery (and state the source).}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Conduct a search to compare the technical characteristics of the following sensors:

\begin{enumerate}
\def\labelenumi{(\roman{enumi})}
\tightlist
\item
  MODIS (NASA) versus Sentinel (ESA), and
\item
  AVHRR (NASA) versus IRS-P6 (or choose another Indian Remote Sensing satellite)
\end{enumerate}

\textbf{Question 7: Based on the characteristics you describe, for which applications is one sensor likely to be more suitable than the other ones? }

Note: when using the internet to answer this question, be sure to cite your sources and ensure that you are obtaining information from an official, reputable source!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{where-to-submit}{%
\subsection*{Where to submit}\label{where-to-submit}}
\addcontentsline{toc}{subsection}{Where to submit}

Submit your responses to these questions on \href{https://www.gradescope.com/courses/293173/assignments/1446622/submissions}{Gradescope} by 10am on Wednesday, September 8. All students who have been attending class have already been enrolled in Gradescope, although if for some reason you need to sign up again, the access code for our course is \texttt{6PEW3W}.

\hypertarget{lab2}{%
\section{Digital Imagery \& Image Processing}\label{lab2}}

\hypertarget{overview-2}{%
\subsection*{Overview}\label{overview-2}}
\addcontentsline{toc}{subsection}{Overview}

The purpose of this lab is to enable you to search, find and visualize imagery in Google Earth Engine. At completion, you should be able to understand the difference between radiance and reflectance, load imagery with the units of interest (radiance or reflectance, for example), make true color and false color composites and visually identify land cover types based on spectral characteristics.

\hypertarget{learning-outcomes-2}{%
\paragraph*{Learning Outcomes}\label{learning-outcomes-2}}
\addcontentsline{toc}{paragraph}{Learning Outcomes}

\begin{itemize}
\tightlist
\item
  Search and import imagery in GEE
\item
  Extract single scenes from collections of images
\item
  Create and visualize different composites according to desired parameters
\item
  Use the Inspector tab to assess pixel values
\item
  Understand the difference between radiance and reflectance through visualization
\end{itemize}

\hypertarget{searching-for-imagery-exercise-1}{%
\subsection{Searching for Imagery (Exercise 1)}\label{searching-for-imagery-exercise-1}}

The Landsat program is a joint NASA/USGS program that has launched a sequence of Earth observation satellites, named Landsat 1, 2,\ldots{} etc. The Landsat program has resulted in the \href{https://www.youtube.com/embed/ZZx1xmNGcXI?list=PLD240BBC85537B9BE}{longest continuous observation of the Earth's surface}. In this exercise, you will load a Landsat scene over your area of interest, inspect the units and make a plot of radiance. Specifically, use imagery from the Landsat 8, the most recent of the \href{https://www.usgs.gov/core-science-systems/nli/landsat/landsat-8}{sequence of Landsat satellites}. To inspect a Landsat 8 image (also called a \emph{scene}) in your region of interest (ROI), define your ROI as a point, filter the image collection to get a scene with few clouds, and display some information about the image in the console.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Search for `San Francisco' in the playground search bar and click the result under ``Places'' to pan and zoom the map to San Francisco.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./im/im_03_01} 

}

\caption{Playground Search for San Francisco in the GEE Console}\label{fig:sfgeeexample}
\end{figure}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\item
  Use the \href{https://developers.google.com/earth-engine/playground\#geometry-tools}{geometry tools} to make a point in San Francisco (Exit the drawing tool when you're finished). Name the resultant \href{https://developers.google.com/earth-engine/playground\#imports}{import} `point' by clicking on the import name (`geometry' by default).
\item
  Search for `landsat 8 raw' and import the `USGS Landsat 8 Collection 1 Tier 1 Raw Scenes' ImageCollection. Name the import \texttt{landsat}.
\item
  Filter the \texttt{ImageCollection} by date and location, sort by a metadata property called \texttt{CLOUD\_COVER} and get the first image out of this sorted collection:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//  Note that we need to cast the result of first() to Image.   }
\KeywordTok{var}\NormalTok{ image }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(landsat        }
                     \CommentTok{//  Filter to get only images in the specified range.  }
                     \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2014{-}01{-}01\textquotesingle{}}\OperatorTok{,}  \StringTok{\textquotesingle{}2014{-}12{-}31\textquotesingle{}}\NormalTok{)        }
                     \CommentTok{//  Filter to get only images at the location of the point.     }
                     \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(point)        }
                     \CommentTok{//  Sort the collection by a metadata property.     }
                     \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUD\_COVER\textquotesingle{}}\NormalTok{)        }
                     \CommentTok{//  Get the first image out of this collection.     }
                     \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}
\item
  The variable \texttt{image} now stores a reference to an object of type \texttt{ee.Image}. Display a human-readable representation of the image by printing it to the console.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{//  Print the information to the console }
  \FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}A Landsat scene:\textquotesingle{}}\OperatorTok{,}\NormalTok{ image)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}
\item
  Activate the \href{https://developers.google.com/earth-engine/playground\#console-tab}{\textbf{Console}} and observe that after the descriptive text, an object is displayed. Expand and explore the object by clicking the little triangle next to the image name to see more information stored in that object. Specifically, expand \texttt{properties} and inspect the long list of metadata items stored as properties of the image. This is where that \texttt{CLOUD\_COVER} property you just used is stored.
\item
  Note that there are band specific coefficients (\texttt{RADIANCE\_ADD\_*}, \texttt{RADIANCE\_MULT\_*} where * is a band name) in the metadata for converting from the digital number (DN) stored by the image into physical units of radiance. These coefficients will be useful in later exercises.
\end{enumerate}

\hypertarget{visualizing-landsat-imagery}{%
\subsection{Visualizing Landsat Imagery}\label{visualizing-landsat-imagery}}

Recall that \href{https://svs.gsfc.nasa.gov/cgi-bin/details.cgi?aid=11491}{Landsat 8 measures radiance in multiple spectral bands}. A common way to visualize images is to set the red band to display in red, the green band to display in green and the blue band to display in blue. This means trying to match the \href{http://landsat.gsfc.nasa.gov/?p=5779}{spectral response of the instrument} to the spectral response of the photoreceptors in the human eye. It's not a perfect match. Despite that, a visualization done in this manner is called a \emph{true-color} image. When the display bands don't match human visual perception, the resultant visualization is called a \emph{false-color composite}. In this exercise, you will make several different visualizations of the scene you found in exercise 1.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Add the image found in exercise 1 to the map display with the following code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//  Define visualization parameters in a JavaScript dictionary.   }
\KeywordTok{var}\NormalTok{ trueColor }\OperatorTok{=}\NormalTok{ \{    }
  \DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,}    
  \DataTypeTok{min}\OperatorTok{:} \DecValTok{4000}\OperatorTok{,}    
  \DataTypeTok{max}\OperatorTok{:} \DecValTok{12000}\NormalTok{\}}\OperatorTok{;}  
\CommentTok{// Add the image to the  map, using the visualization parameters.   }
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{,}\NormalTok{ trueColor}\OperatorTok{,} \StringTok{\textquotesingle{}true{-}color image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}
\item
  Observe that this Image is displayed according to the visualization instructions in the trueColor dictionary object. Specifically, bands is a list of three bands to display as red, green and blue, respectively (first band is red, second is green, third is blue). To understand where these band names come from, inspect the bands property of the image in the \textbf{Console}. To understand how to match bands to colors, see \href{http://landsat.usgs.gov/band_designations_landsat_satellites.php}{this helpful page} and \href{http://landsat.usgs.gov/L8_band_combos.php}{this one}.
\item
  There is more than one way to discover the appropriate min and max values to display. Try going to the \href{https://developers.google.com/earth-engine/playground\#inspector-tab}{\textbf{Inspector} tab} and clicking somewhere on the map. Note that value in each band, in the pixel where you clicked, is displayed as a list in the \textbf{Inspector}. Try clicking on dark and bright objects to get a sense of the range of pixel values. Also note that the \href{https://developers.google.com/earth-engine/playground\#layer-manager}{layer manager} in the upper right of the map display lets you automatically compute a linear stretch based on the pixels in the map display.
\item
  Define a new set of visualization parameters and use them to add the image to the map as a false-color composite. This particular set of bands results in a \emph{color-IR composite} because the near infra-red (NIR) band is set to red:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//  Define false{-}color visualization parameters.   }
\KeywordTok{var}\NormalTok{ falseColor }\OperatorTok{=}\NormalTok{ \{    }\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\NormalTok{]}\OperatorTok{,}    \DataTypeTok{min}\OperatorTok{:} \DecValTok{4000}\OperatorTok{,}    \DataTypeTok{max}\OperatorTok{:} \DecValTok{13000}\NormalTok{   \}}\OperatorTok{;}  
\CommentTok{// Add the image to the  map, using the visualization parameters.   }
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{,}\NormalTok{ falseColor}\OperatorTok{,} \StringTok{\textquotesingle{}false{-}color composite\textquotesingle{}}\NormalTok{)}\OperatorTok{;} 
\end{Highlighting}
\end{Shaded}
\item
  Try playing with band combinations, min and max DNs to achieve different visualizations. Note that you can compare the displays by toggling layers on and off with the layer manager.
\end{enumerate}

\hypertarget{plot-at-sensor-radiance}{%
\subsection{Plot at-Sensor Radiance}\label{plot-at-sensor-radiance}}

The image data you have used so far is stored as DNs. To convert DN values into at-sensor \href{https://en.wikipedia.org/wiki/Radiance}{radiance} units in Watts/m2/sr/𝝁m, use a linear equation of the form

\[ L_𝝀 = a_{\lambda} * DN_{\lambda} + b_{\lambda}  \qquad (1) \]

Note that every term is indexed by lamda (\(\lambda\), the symbol for wavelength) because the coefficients are different in each band. See \href{http://www.sciencedirect.com/science/article/pii/S0034425709000169}{Chander et al.~(2009)} for details on this linear transformation between DN and radiance. In this exercise, you will generate a radiance image and examine the differences in radiance from different targets.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Perform the transformation in equation 1 using the Earth Engine function for converting Landsat imagery to radiance in Watts/m2/sr/𝝁m. It will automatically look up the right metadata values for each band and apply the equation for you

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//  Use these bands.    }
\KeywordTok{var}\NormalTok{ bands }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}B1\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B6\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B7\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B10\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B11\textquotesingle{}}\NormalTok{]}\OperatorTok{;}  
\CommentTok{// Get an image that  contains only the bands of interest.   }
\KeywordTok{var}\NormalTok{ dnImage }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(bands)}\OperatorTok{;}  
\CommentTok{// Apply the  transformation.   }
\KeywordTok{var}\NormalTok{ radiance }\OperatorTok{=}\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Algorithms}\OperatorTok{.}\AttributeTok{Landsat}\OperatorTok{.}\FunctionTok{calibratedRadiance}\NormalTok{(dnImage)}\OperatorTok{;}  
\CommentTok{// Display the result.   }
\KeywordTok{var}\NormalTok{ radParams }\OperatorTok{=}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{100}\NormalTok{\}}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(radiance}\OperatorTok{,}\NormalTok{ radParams}\OperatorTok{,} \StringTok{\textquotesingle{}radiance\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

  Note that this code applies the transformation to a subset of bands (specified by a list of band names) obtained from the image using select(). That is to facilitate interpretation of the radiance spectrum by removing the panchromatic band (`B8'), an atmospheric absorption band (`B9') and the QA band (`BQA'). Also note that the visualization parameters are different to account for the radiance units.
\item
  Inspect the radiance image by activating the \textbf{Inspector} and clicking locations on the map. (It may be easier if you turn off the other images you're displaying by commenting `Map.addLayer() lines from previous exercises. Comment a line with the Ctrl-/ shortcut or two forward slashes at the start of the line). Click on different land cover types and in the \textbf{Inspector}, and click the chart icon (\includegraphics{./im/im_03_03.png}) to get a chart of the pixel values. If the shape of the chart resembles Figure 1, that's because the radiance (in bands 1-7) is mostly reflected solar irradiance. The radiance detected in bands 10-11 is thermal, and is \emph{emitted} (not reflected) from the surface.
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./im/im_03_02} 

}

\caption{Solar irradiance vs wavelenth. Data sources: 6000K blackbody spectrum from http://astrogeology.usgs.gov/tools/thermal-radiance-calculator, adjusted according to the solid angle subtended by the solar disk. TOA and sea level irradiance from http://rredc.nrel.gov/solar/spectra/am1.5/.}\label{fig:irradiancewavelength}
\end{figure}

\hypertarget{plot-top-of-atmosphere-toa-reflectance}{%
\subsection{Plot Top-of-Atmosphere (TOA) Reflectance}\label{plot-top-of-atmosphere-toa-reflectance}}

The Landsat sensor is in orbit approximately 700 kilometers above Earth. The ratio of upward (reflected from the target at Earth's surface) radiance measured by the sensor to downward radiance from the sun is a unitless ratio called \href{https://en.wikipedia.org/wiki/Reflectance}{reflectance}. (In fact it's more complicated than that because radiance is a directional quantity, but this definition captures the basic idea). Because this ratio is computed using whatever radiance the sensor measures (which may contain all sorts of atmospheric effects), it's called \emph{at-sensor} or \emph{top-of-atmosphere} (TOA) reflectance. In this exercise, you will load TOA reflectance data and examine spectra at representative locations.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  To get TOA data for landsat, a transformation of digital numbers is performed as described in \href{http://www.sciencedirect.com/science/article/pii/S0034425709000169}{Chander et al.~(2009)}. This transformation is automatically done by Earth Engine. Search for `landsat 8 toa' and import the `USGS Landsat 8 Collection 1 Tier 1 TOA Reflectance' ImageCollection. Name the import `toa'. This collection stores TOA images which can be filtered as in exercise 1, substituting `toa' for `landsat' as the collection variable. A shortcut is to find the image ID from the printout of image (defined in exercise 1), then copy this ID directly into the Image constructor, appending \_TOA to the collection name (the difference is shown in bold):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ toaImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(}\StringTok{\textquotesingle{}LANDSAT/LC08/C01/T1\_TOA/LC08\_044034\_20141012\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}
\item
  Since reflectance is a unitless ratio in {[}0, 1{]}, change the visualization parameters to correctly display the TOA data:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(toaImage}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.3}\NormalTok{\}}\OperatorTok{,}  \StringTok{\textquotesingle{}toa\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}
\item
  Using the \textbf{Inspector}, click several locations on the map and examine the resultant spectra. It should be apparent, especially if you chart the spectra, that the scale of pixel values in different bands is drastically different. Specifically, bands 10-11 are not in {[}0, 1{]}. The reason is that these are thermal bands, and are converted to brightness temperature, in \href{https://en.wikipedia.org/wiki/Kelvin}{Kelvin}, as part of the TOA conversion. Very little radiance is reflected in this wavelength range; most is emitted from the Earth's surface. That emitted radiance can be used to estimate \href{https://en.wikipedia.org/wiki/Brightness_temperature}{brightness temperature}, using the inverted \href{https://en.wikipedia.org/wiki/Planck's_law}{Planck equation}. Examine the temperature of various locations. Now add this command to the TOA image before adding it to the map to get only bands 1-9 \texttt{.select(\textquotesingle{}B({[}0-9{]})\textquotesingle{})}
\item
  To make plots of reflectance, select the reflective bands from the TOA image and use the Earth Engine \href{https://developers.google.com/earth-engine/charts}{charting API}. To see a customized chart of reflectance at a point in Golden Gate Park, use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//  Hardcode a point in Golden Gate Park.   }
\KeywordTok{var}\NormalTok{ ggPark }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{([}\OperatorTok{{-}}\FloatTok{122.4860}\OperatorTok{,} \FloatTok{37.7692}\NormalTok{])}\OperatorTok{;}      
\CommentTok{// Define reflective  bands as bands B1{-}B7. See the docs for slice().   }
\KeywordTok{var}\NormalTok{ reflectiveBands }\OperatorTok{=}\NormalTok{ bands}\OperatorTok{.}\FunctionTok{slice}\NormalTok{(}\DecValTok{0}\OperatorTok{,} \DecValTok{7}\NormalTok{)}\OperatorTok{;}      
\CommentTok{// See  http://landsat.usgs.gov/band\_designations\_landsat\_satellites.php   }
\KeywordTok{var}\NormalTok{ wavelengths }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.44}\OperatorTok{,} \FloatTok{0.48}\OperatorTok{,} \FloatTok{0.56}\OperatorTok{,} \FloatTok{0.65}\OperatorTok{,} \FloatTok{0.86}\OperatorTok{,} \FloatTok{1.61}\OperatorTok{,} \FloatTok{2.2}\NormalTok{]}\OperatorTok{;}      
\CommentTok{// Select only the  reflectance bands of interest.   }
\KeywordTok{var}\NormalTok{ reflectanceImage }\OperatorTok{=}\NormalTok{  toaImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(reflectiveBands)}\OperatorTok{;}      
\CommentTok{// Define an object of  customization parameters for the chart.   }
\KeywordTok{var}\NormalTok{ options }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{title}\OperatorTok{:} \StringTok{\textquotesingle{}Landsat  8 TOA spectrum in Golden Gate Park\textquotesingle{}}\OperatorTok{,}    
               \DataTypeTok{hAxis}\OperatorTok{:}\NormalTok{ \{}\DataTypeTok{title}\OperatorTok{:} \StringTok{\textquotesingle{}Wavelength  (micrometers)\textquotesingle{}}\NormalTok{\}}\OperatorTok{,}
               \DataTypeTok{vAxis}\OperatorTok{:}\NormalTok{ \{}\DataTypeTok{title}\OperatorTok{:} \StringTok{\textquotesingle{}Reflectance\textquotesingle{}}\NormalTok{\}}\OperatorTok{,}
               \DataTypeTok{lineWidth}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}
               \DataTypeTok{pointSize}\OperatorTok{:} \DecValTok{4}\NormalTok{\}}\OperatorTok{;}      
\CommentTok{// Make the chart, using  a 30 meter pixel.   }
\KeywordTok{var}\NormalTok{ chart }\OperatorTok{=}\NormalTok{ ui}\OperatorTok{.}\AttributeTok{Chart}\OperatorTok{.}\AttributeTok{image}\OperatorTok{.}\FunctionTok{regions}\NormalTok{(}
\NormalTok{  reflectanceImage}\OperatorTok{,} 
\NormalTok{  ggPark}\OperatorTok{,} \KeywordTok{null}\OperatorTok{,} \DecValTok{30}\OperatorTok{,} \KeywordTok{null}\OperatorTok{,}\NormalTok{ wavelengths)}
        \OperatorTok{.}\FunctionTok{setOptions}\NormalTok{(options)}\OperatorTok{;}      
\CommentTok{// Display the chart.   }
\FunctionTok{print}\NormalTok{(chart)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{1. Upload the TOA reflectance plot you generated and briefly describe its salient features }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

There are several new methods in this code. The Point constructor takes a list of coordinates as input, as an alternative to a ``hand-made'' point from the geometry drawing tools that is imported to the script. The \texttt{slice()} method gets entries in a list based on starting and ending indices. Search the docs (on the \textbf{Docs} tab) for `slice' to find other places this method can be used. Construction of the chart is handled by an object of customization parameters (\href{https://developers.google.com/earth-engine/charts_image_histogram}{learn more about customizing charts}) passed to \href{https://developers.google.com/earth-engine/charts_image_regions}{Chart.image.regions()}.

\hypertarget{plot-surface-reflectance}{%
\subsection{Plot Surface Reflectance}\label{plot-surface-reflectance}}

The ratio of upward radiance \emph{at the Earth's surface} to downward radiance \emph{at the Earth's surface} is called surface reflectance. Unlike TOA reflectance, in which those radiances are at the sensor, the radiances at the Earth's surface have been affected by the atmosphere. The radiance incident on the target is affected by its downward path through the atmosphere. The radiance reflected by the target is affected by its upward path through the atmosphere to the sensor. Unravelling those effects is called atmospheric correction (``compensation'' is probably a more accurate term) and is beyond our scope. However, helpful scientists at the USGS have already performed this correction for us.

To explore Landsat surface reflectance data, search `Landsat 8 surface reflectance' and import the `USGS Landsat 8 Surface Reflectance Tier 1' \texttt{ImageCollection}. Name the import \texttt{sr}. Filter to the same date, location and cloudiness as with the raw and TOA collections and get the first image.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{2. Upload the surface reflectance plot you just generated and briefly describe its salient features. What differs or remains the same between the TOA plot and the surface reflectance plot? }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{3. When you add \texttt{sr} to the map, you will need to scale the imagery or change the visualization parameters. Why? Read the dataset description to find out. Hint: What is the scale factor for bands 1-9? }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{additional-exercises-1}{%
\subsection{Additional Exercises}\label{additional-exercises-1}}

\textbf{4. In your code, set the value of a variable called \texttt{azimuth} to the solar azimuth of the image from 1d. Do not hardcode the number. Use \texttt{get()}. Print the result and show you set the value of \texttt{azimuth}.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{5. Add a layer to the map in which the image from 1d is displayed with band 7 set to red, band 5 set to green and band 3 set to blue. Upload a visual of the layer and show how you would display the layer name as \texttt{falsecolor}. }

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{0.06}}@{}}
\toprule
\endhead
\textbf{6. What is the brightness temperature of the golden gate park point? Also show how you make a variable in your code called temperature and set it to the band 10 brightness temperature.} Hint: \\
\texttt{javascript\ var\ \ temperature\ =\ toaImage.reduceRegion(\ \{\ \textless{}YOUR\ SOLUTION\ HERE\textgreater{}\ \ \ \})\ .get(\ \ \textless{}YOUR\ SOLUTION\ \ HERE\textgreater{});} \\
Use \href{https://developers.google.com/earth-engine/reducers_reduce_region}{this guide} for help. \\
\bottomrule
\end{longtable}

\textbf{7. What is the surface reflectance (in {[}0,1{]}, meaning you will need to apply the scale factor) in band 5 (NIR) at the golden gate park point? Also show how you make a variable in your code called \texttt{reflectance} that stores this value.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{where-to-submit-1}{%
\subsection*{Where to submit}\label{where-to-submit-1}}
\addcontentsline{toc}{subsection}{Where to submit}

Submit your responses to these questions on \href{https://www.gradescope.com/courses/293173/assignments/1446622/submissions}{Gradescope} by 10am on Wednesday, September 15. If needed, the access code for our course is \texttt{6PEW3W}.

\hypertarget{spectral-indices-transformations}{%
\section{Spectral Indices \& Transformations}\label{spectral-indices-transformations}}

\hypertarget{overview-3}{%
\subsection*{Overview}\label{overview-3}}
\addcontentsline{toc}{subsection}{Overview}

The purpose of this lab is to enable you to extract, visualize, combine, and transform spectral data in GEE so as to highlight and indicate the relative abundance of particular features of interest from an image. At completion, you should be able to understand the difference between wavelengths, load visualizations displaying relevant indices, compare the relevant applications for varying spectral transformations, and compute and examine image texture.

\hypertarget{spectral-indices}{%
\subsection{Spectral Indices}\label{spectral-indices}}

Spectral indices are based on the fact that reflectance spectra of different land cover types have unique characteristics. We can build custom indices designed to exploit these differences to accentuate particular land cover types. Consider the following chart of reflectance spectra for various targets.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./im/im_04_01} 

}

\caption{Sample Spectral Reflectance Curves}\label{fig:specindices}
\end{figure}

Observe that the land covers are separable at one or more wavelengths. Note, in particular, that vegetation curves (green) have relatively high reflectance in the NIR range, where radiant energy is scattered by cell walls (\href{http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19850022138.pdf}{Bowker et al.~1985}). Also note that vegetation has low reflectance in the red range, where radiant energy is \href{https://en.wikipedia.org/wiki/Chlorophyll\#/media/File:Chlorophyll_ab_spectra-en.svg}{absorbed by chlorophyll}. These observations motivate the formulation of vegetation indices, some of which are described in the following sections.

\hypertarget{important-indices}{%
\subsubsection{Important Indices}\label{important-indices}}

\hypertarget{normalized-difference-vegetation-index-ndvi}{%
\paragraph{Normalized Difference Vegetation Index (NDVI)}\label{normalized-difference-vegetation-index-ndvi}}

The Normalized Difference Vegetation Index (NDVI) has a \href{https://en.wikipedia.org/wiki/Normalized_Difference_Vegetation_Index}{long history} in remote sensing. The typical formulation is

\[ \text{NDVI} = (\text{NIR} - \text{red}) / (\text{NIR} + \text{red}) \]

Where \emph{NIR} and \emph{red} refer to reflectance, radiance or DN at the respective wavelength. Implement indices of this form in Earth Engine with the normalizedDifference() method. First, get an image of interest by drawing a Point named \texttt{point} over SFO airport, importing the \texttt{Landsat\ 8\ Collection\ 1\ Tier\ 1\ TOA\ Reflectance} as landsat8 and sorting the collection by cloud cover metadata:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{  image }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(landsat8     }
                      \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(point)     }
                      \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2015{-}06{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2015{-}09{-}01\textquotesingle{}}\NormalTok{)}
                      \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUD\_COVER\textquotesingle{}}\NormalTok{)}
                      \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ trueColor }\OperatorTok{=}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,} 
                 \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.3}\NormalTok{\}}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{,}\NormalTok{ trueColor}\OperatorTok{,} \StringTok{\textquotesingle{}image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

The NDVI computation is one line:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{  ndvi }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{normalizedDifference}\NormalTok{([}\StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\NormalTok{])}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Display the NDVI image with a color palette (feel free to make a better one):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{  vegPalette }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}white\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}green\textquotesingle{}}\NormalTok{]}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(ndvi}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}  
                    \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ vegPalette\}}\OperatorTok{,} \StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Use the \textbf{Inspector} to check pixel values in areas of vegetation and non-vegetation.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{1. What are some of the sample pixel values of the NDVI in areas of vegetation vs.~urban features vs.~bare earth vs.~water? Indicate which parts of the images you used and how you determined what each of their values were.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{enhanced-vegetation-index-evi}{%
\paragraph{Enhanced Vegetation Index (EVI)}\label{enhanced-vegetation-index-evi}}

The Enhanced Vegetation Index (EVI) is designed to minimize saturation and background effects in NDVI (\href{http://www.sciencedirect.com/science/article/pii/S0034425702000962}{Huete et al.~2002}). Since it is not a normalized difference index, compute it with \href{https://developers.google.com/earth-engine/image_math\#expressions}{an expression}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ exp }\OperatorTok{=} \StringTok{\textquotesingle{}2.5  * ((NIR {-} RED) / (NIR + 6 * RED {-} 7.5 * BLUE + 1))\textquotesingle{}}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ evi }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{expression}\NormalTok{( exp}\OperatorTok{,} 
\NormalTok{                            \{}\StringTok{\textquotesingle{}NIR\textquotesingle{}}\OperatorTok{:}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B5\textquotesingle{}}\NormalTok{)}\OperatorTok{,}
                             \StringTok{\textquotesingle{}RED\textquotesingle{}}\OperatorTok{:}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B4\textquotesingle{}}\NormalTok{)}\OperatorTok{,}
                             \StringTok{\textquotesingle{}BLUE\textquotesingle{}}\OperatorTok{:}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{)}
\NormalTok{                            \})}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Observe that bands are referenced with the help of \href{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Grammar_and_Types\#Object_literals}{an object} that is passed as the second argument to image.expression(). Display EVI:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(evi}\OperatorTok{,}  
\NormalTok{             \{}\DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}  \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ vegPalette\}}\OperatorTok{,} 
             \StringTok{\textquotesingle{}EVI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{2a. Compare EVI to NDVI across those same land use categories as in the previous question. What do you observe -- how are the images and values similar or different across the two indices?}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{normalized-difference-water-index-ndwi}{%
\paragraph{Normalized Difference Water Index (NDWI)}\label{normalized-difference-water-index-ndwi}}

The Normalized Difference Water Index (NDWI) was developed by \href{http://www.sciencedirect.com/science/article/pii/S0034425796000673}{Gao (1996)} as an index of vegetation water content:

\[\text{NDWI} = (\text{NIR} - \text{SWIR})) / (\text{NIR} + \text{SWIR})\]

Compute NDWI in Earth Engine with:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ ndwi }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{normalizedDifference}\NormalTok{([}\StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B6\textquotesingle{}}\NormalTok{])}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

And display:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ waterPalette }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}white\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{]}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(ndwi}\OperatorTok{,} 
\NormalTok{             \{}\DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\FloatTok{0.5}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}  
              \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ waterPalette\}}\OperatorTok{,} 
             \StringTok{\textquotesingle{}NDWI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Note that this is not an exact implementation of NDWI, according to the \href{http://landsat.gsfc.nasa.gov/?p=5779}{OLI spectral response}, since OLI does not have a band in the right position (1.26 𝛍m).

\hypertarget{normalized-difference-water-body-index-ndwbi}{%
\paragraph{\texorpdfstring{Normalized Difference Water \emph{Body} Index (NDWBI)}{Normalized Difference Water Body Index (NDWBI)}}\label{normalized-difference-water-body-index-ndwbi}}

It's unfortunate that two \emph{different} NDWI indices were independently invented in 1996. To distinguish, define the Normalized Difference Water \emph{Body} Index (NDWBI) as the index described in \href{http://www.tandfonline.com/doi/abs/10.1080/01431169608948714\#.VkThFHyrTlM}{McFeeters (1996)}:

\[\text{NDWBI} = (\text{green} - \text{NIR}) / (\text{green} + \text{NIR})\]

As previously, implement NDWBI with \texttt{normalizedDifference()} and display the result:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ ndwbi }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{normalizedDifference}\NormalTok{([}\StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B5\textquotesingle{}}\NormalTok{])}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(ndwbi}\OperatorTok{,} 
\NormalTok{             \{}\DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,} 
              \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.5}\OperatorTok{,}  
              \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ waterPalette\}}\OperatorTok{,} 
             \StringTok{\textquotesingle{}NDWBI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}   
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{2b. Compare NDWI and NDWBI. What do you observe?}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{normalized-difference-bare-index-ndbi}{%
\paragraph{Normalized Difference Bare Index (NDBI)}\label{normalized-difference-bare-index-ndbi}}

The Normalized Difference Bare Index (NDBI) was developed by \href{http://www.tandfonline.com/doi/abs/10.1080/01431160304987}{Zha et al.~(2003)} to aid in the differentiation of urban areas:

\[ \text{NDBI} = (\text{SWIR} - \text{NIR}) / (\text{SWIR} + \text{NIR}) \]

Note that NDBI is the negative of NDWI. Compute NDBI and display with a suitable palette:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ ndbi }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{normalizedDifference}\NormalTok{([}\StringTok{\textquotesingle{}B6\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B5\textquotesingle{}}\NormalTok{])}\OperatorTok{;}   
\KeywordTok{var}\NormalTok{ barePalette }\OperatorTok{=}\NormalTok{  waterPalette}\OperatorTok{.}\FunctionTok{slice}\NormalTok{()}\OperatorTok{.}\FunctionTok{reverse}\NormalTok{()}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(ndbi}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.5}\OperatorTok{,}  \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ barePalette\}}\OperatorTok{,} \StringTok{\textquotesingle{}NDBI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

(Check \href{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array}{this reference} to demystify the palette reversal).

\hypertarget{burned-area-index-bai}{%
\paragraph{Burned Area Index (BAI)}\label{burned-area-index-bai}}

The Burned Area Index (BAI) was developed by \href{http://www.tandfonline.com/doi/abs/10.1080/01431160210153129}{Chuvieco et al.~(2002)} to assist in the delineation of burn scars and assessment of burn severity. It is based on the spectral distance to charcoal reflectance. To examine burn indices, load an image from 2013 showing the \href{https://en.wikipedia.org/wiki/Rim_Fire}{Rim fire} in the Sierra Nevadas:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ burnImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(landsat8                         }
                         \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{(}\OperatorTok{{-}}\FloatTok{120.083}\OperatorTok{,} \FloatTok{37.850}\NormalTok{))                                        }
                         \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2013{-}08{-}17\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2013{-}09{-}27\textquotesingle{}}\NormalTok{)                         }
                         \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUD\_COVER\textquotesingle{}}\NormalTok{)                         }
                         \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(burnImage}\OperatorTok{,}\NormalTok{ trueColor}\OperatorTok{,} \StringTok{\textquotesingle{}burn image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Closely examine the true color display of this image. Can you spot the fire? If not, the BAI may help. As with EVI, use an expression to compute BAI in Earth Engine:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ exp }\OperatorTok{=} \StringTok{\textquotesingle{}1.0  / ((0.1 {-} RED)**2 + (0.06 {-} NIR)**2)\textquotesingle{}}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ bai }\OperatorTok{=}\NormalTok{ burnImage}\OperatorTok{.}\FunctionTok{expression}\NormalTok{(  exp}\OperatorTok{,}   
\NormalTok{                               \{}\StringTok{\textquotesingle{}NIR\textquotesingle{}}\OperatorTok{:}\NormalTok{ burnImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B5\textquotesingle{}}\NormalTok{)}\OperatorTok{,}   
                                \StringTok{\textquotesingle{}RED\textquotesingle{}}\OperatorTok{:}\NormalTok{ burnImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B4\textquotesingle{}}\NormalTok{) }
\NormalTok{                               \}}
\NormalTok{                              )}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Display the result.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ burnPalette }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}green\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}blue\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}yellow\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{]}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(bai}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{400}\OperatorTok{,}  \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ burnPalette\}}\OperatorTok{,} \StringTok{\textquotesingle{}BAI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{0.06}}@{}}
\toprule
\endhead
\textbf{2c. Compare NDBI and the BAI displayed results -- what do you observe?} \\
\bottomrule
\end{longtable}

\hypertarget{normalized-burn-ratio-thermal-nbrt}{%
\paragraph{Normalized Burn Ratio Thermal (NBRT)}\label{normalized-burn-ratio-thermal-nbrt}}

The Normalized Burn Ratio Thermal (NBRT) was developed based on the idea that burned land has low NIR reflectance (less vegetation), high SWIR reflectance (think ash), and high brightness temperature (\href{http://www.tandfonline.com/doi/abs/10.1080/01431160500239008}{Holden et al.~2005}). Unlike the other indices, a lower NBRT means more burning. Implement the NBRT with an expression

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ exp }\OperatorTok{=} \StringTok{\textquotesingle{}(NIR {-} 0.0001 * SWIR *  Temp) / (NIR + 0.0001 * SWIR * Temp)\textquotesingle{}}
\KeywordTok{var}\NormalTok{ nbrt }\OperatorTok{=}\NormalTok{ burnImage}\OperatorTok{.}\FunctionTok{expression}\NormalTok{(exp}\OperatorTok{,}   
\NormalTok{                                \{}\StringTok{\textquotesingle{}NIR\textquotesingle{}}\OperatorTok{:}\NormalTok{ burnImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B5\textquotesingle{}}\NormalTok{)}\OperatorTok{,}   
                                 \StringTok{\textquotesingle{}SWIR\textquotesingle{}}\OperatorTok{:}\NormalTok{ burnImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B7\textquotesingle{}}\NormalTok{)}\OperatorTok{,}   
                                 \StringTok{\textquotesingle{}Temp\textquotesingle{}}\OperatorTok{:}\NormalTok{ burnImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B11\textquotesingle{}}\NormalTok{)  }
\NormalTok{                                \})}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

To display this result, reverse the scale:

\begin{Shaded}
\begin{Highlighting}[]
  \BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(nbrt}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \DecValTok{1}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.9}\OperatorTok{,}  \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ burnPalette\}}\OperatorTok{,} \StringTok{\textquotesingle{}NBRT\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

The difference in this index, before - after the fire, can be used as a diagnostic of burn severity (see \href{http://www.sciencedirect.com/science/article/pii/S003442570400152X}{van Wagtendonk et al.~2004}).

\hypertarget{normalized-difference-snow-index-ndsi}{%
\paragraph{Normalized Difference Snow Index (NDSI)}\label{normalized-difference-snow-index-ndsi}}

The Normalized Difference Snow Index (NDSI) was designed to estimate the amount of a pixel covered in snow (\href{http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=399618\&tag=1}{Riggs et al.~1994})

\[\text{NDSI} = (\text{green} - \text{SWIR}) /(\text{green} + \text{SWIR})\]

First, find a snow covered scene to test the index:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ snowImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(landsat8 }
                         \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{(}\OperatorTok{{-}}\FloatTok{120.0421}\OperatorTok{,} \FloatTok{39.1002}\NormalTok{))  }
                         \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2013{-}11{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2014{-}05{-}01\textquotesingle{}}\NormalTok{)                         }
                         \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUD\_COVER\textquotesingle{}}\NormalTok{)                         }
                         \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(snowImage}\OperatorTok{,}\NormalTok{ trueColor}\OperatorTok{,} \StringTok{\textquotesingle{}snow image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Compute and display NDSI in Earth Engine:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ ndsi }\OperatorTok{=}\NormalTok{ snowImage}\OperatorTok{.}\FunctionTok{normalizedDifference}\NormalTok{([}\StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B6\textquotesingle{}}\NormalTok{])}\OperatorTok{;}      
\KeywordTok{var}\NormalTok{ snowPalette }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}red\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}green\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}blue\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{]}\OperatorTok{;}   
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(ndsi}\OperatorTok{,}              
\NormalTok{             \{}\DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\FloatTok{0.5}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.5}\OperatorTok{,}  \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ snowPalette\}}\OperatorTok{,}              
             \StringTok{\textquotesingle{}NDSI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

\hypertarget{linear-transformations}{%
\subsubsection{Linear Transformations}\label{linear-transformations}}

Linear transforms are linear combinations of input pixel values. These can result from a variety of different strategies, but a common theme is that pixels are treated as arrays of band values.

\hypertarget{tasseled-cap-tc}{%
\paragraph{Tasseled cap (TC)}\label{tasseled-cap-tc}}

Based on observations of agricultural land covers in the NIR-red spectral space, \href{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.461.6381\&rep=rep1\&type=pdf}{Kauth and Thomas (1976)} devised a \href{https://en.wikipedia.org/wiki/Change_of_basis}{rotational transform} of the form

\[p_1 = R^T p_0 \]

where \textbf{p\_0} is the original \emph{p}x1 pixel vector (a stack of the \emph{p} band values as an \href{https://developers.google.com/earth-engine/arrays_intro}{Array}), \textbf{p\_1} is the rotated pixel and \textbf{R} is an \href{https://en.wikipedia.org/wiki/Orthonormal_basis}{orthonormal basis} of the new space (therefore \textbf{R\^{}T} is its inverse). Kauth and Thomas found \textbf{R} by defining the first axis of their transformed space to be parallel to the soil line in the following chart, then used the \href{https://en.wikipedia.org/wiki/Gram–Schmidt_process}{Gram-Schmidt process} to find the other basis vectors.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./im/im_04_02} 

}

\caption{Tassel Cap Illustration}\label{fig:tasselcap}
\end{figure}

Assuming that \textbf{R} is available, one way to implement this rotation in Earth Engine is with arrays. Specifically, make an array of TC coefficients:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ coefficients }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Array}\NormalTok{([    }
\NormalTok{  [}\FloatTok{0.3037}\OperatorTok{,} \FloatTok{0.2793}\OperatorTok{,} \FloatTok{0.4743}\OperatorTok{,} \FloatTok{0.5585}\OperatorTok{,} \FloatTok{0.5082}\OperatorTok{,} \FloatTok{0.1863}\NormalTok{]}\OperatorTok{,}    
\NormalTok{  [}\OperatorTok{{-}}\FloatTok{0.2848}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.2435}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.5436}\OperatorTok{,} \FloatTok{0.7243}\OperatorTok{,} \FloatTok{0.0840}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.1800}\NormalTok{]}\OperatorTok{,}
\NormalTok{  [}\FloatTok{0.1509}\OperatorTok{,} \FloatTok{0.1973}\OperatorTok{,} \FloatTok{0.3279}\OperatorTok{,} \FloatTok{0.3406}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.7112}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.4572}\NormalTok{]}\OperatorTok{,}
\NormalTok{  [}\OperatorTok{{-}}\FloatTok{0.8242}\OperatorTok{,} \FloatTok{0.0849}\OperatorTok{,} \FloatTok{0.4392}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.0580}\OperatorTok{,} \FloatTok{0.2012}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.2768}\NormalTok{]}\OperatorTok{,}
\NormalTok{  [}\OperatorTok{{-}}\FloatTok{0.3280}\OperatorTok{,} \FloatTok{0.0549}\OperatorTok{,} \FloatTok{0.1075}\OperatorTok{,} \FloatTok{0.1855}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.4357}\OperatorTok{,} \FloatTok{0.8085}\NormalTok{]}\OperatorTok{,}
\NormalTok{  [}\FloatTok{0.1084}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.9022}\OperatorTok{,} \FloatTok{0.4120}\OperatorTok{,} \FloatTok{0.0573}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{0.0251}\OperatorTok{,} \FloatTok{0.0238}\NormalTok{]}
\NormalTok{])}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Since these coefficients are for the TM sensor, get a less cloudy Landsat 5 scene. First, search for landsat 5 toa', then import `USGS Landsat 5 TOA Reflectance (Orthorectified)'. Name the import \texttt{landsat5}, then filter and sort the collection as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ tcImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(landsat5}
                       \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(point)}
                       \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2008{-}06{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2008{-}09{-}01\textquotesingle{}}\NormalTok{)}
                       \OperatorTok{.}\FunctionTok{sort}\NormalTok{(}\StringTok{\textquotesingle{}CLOUD\_COVER\textquotesingle{}}\NormalTok{)}
                       \OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

To do the matrix multiplication, first convert the input image from a multi-band image to an array image in which each pixel stores an array:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ bands }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}B1\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B7\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
\CommentTok{// Make an Array Image,  with a 1{-}D Array per pixel.}
\KeywordTok{var}\NormalTok{ arrayImage1D }\OperatorTok{=}\NormalTok{  tcImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(bands)}\OperatorTok{.}\FunctionTok{toArray}\NormalTok{()}\OperatorTok{;}
\CommentTok{// Make an Array Image  with a 2{-}D Array per pixel, 6x1.}
\KeywordTok{var}\NormalTok{ arrayImage2D }\OperatorTok{=}\NormalTok{ arrayImage1D}\OperatorTok{.}\FunctionTok{toArray}\NormalTok{(}\DecValTok{1}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Do the matrix multiplication, then convert back to a multi-band image:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ componentsImage }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(coefficients)}
                \OperatorTok{.}\FunctionTok{matrixMultiply}\NormalTok{(arrayImage2D)}
\CommentTok{// Get rid of the extra  dimensions.}
                \OperatorTok{.}\FunctionTok{arrayProject}\NormalTok{([}\DecValTok{0}\NormalTok{])  }
\CommentTok{// Get a multi{-}band image  with TC{-}named bands.  }
                \OperatorTok{.}\FunctionTok{arrayFlatten}\NormalTok{(}
\NormalTok{          [[}\StringTok{\textquotesingle{}brightness\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}greenness\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}wetness\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}fourth\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}fifth\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}sixth\textquotesingle{}}\NormalTok{]]}
\NormalTok{        )}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Finally, display the result:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ vizParams }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}brightness\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}greenness\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}wetness\textquotesingle{}}\NormalTok{]}\OperatorTok{,}
  \DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\FloatTok{0.1}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:}\NormalTok{ [}\FloatTok{0.5}\OperatorTok{,}  \FloatTok{0.1}\OperatorTok{,} \FloatTok{0.1}\NormalTok{]}
\NormalTok{\}}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(componentsImage}\OperatorTok{,}\NormalTok{ vizParams}\OperatorTok{,} \StringTok{\textquotesingle{}TC components\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{3a. Upload the resulting \texttt{componentsImage} and interpret your output.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{principal-component-analysis-pca}{%
\paragraph{Principal Component Analysis (PCA)}\label{principal-component-analysis-pca}}

Like the TC transform, the \href{https://en.wikipedia.org/wiki/Principal_component_analysis}{PCA transform} is a rotational transform in which the new basis is orthonormal, but the axes are determined from statistics of the input image, rather than empirical data. Specifically, the new basis is the \href{https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors}{eigenvectors} of the image's \href{https://en.wikipedia.org/wiki/Covariance_matrix}{variance-covariance matrix}. As a result, the PCs are uncorrelated. To demonstrate, use the Landsat 8 image, converted to an array image:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ bands }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}B2\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B6\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B7\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B10\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B11\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ arrayImage }\OperatorTok{=}\NormalTok{  image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(bands)}\OperatorTok{.}\FunctionTok{toArray}\NormalTok{()}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

In the next step, use the \href{https://developers.google.com/earth-engine/reducers_reduce_region}{reduceRegion() method} to compute statistics (band covariances) for the image. (Here the region is just the image footprint):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ covar }\OperatorTok{=}\NormalTok{ arrayImage}\OperatorTok{.}\FunctionTok{reduceRegion}\NormalTok{(\{}
  \DataTypeTok{reducer}\OperatorTok{:}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{covariance}\NormalTok{()}\OperatorTok{,}
  \DataTypeTok{maxPixels}\OperatorTok{:} \FloatTok{1e9}
\NormalTok{\})}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ covarArray }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Array}\NormalTok{(covar}\OperatorTok{.}\FunctionTok{get}\NormalTok{(}\StringTok{\textquotesingle{}array\textquotesingle{}}\NormalTok{))}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

A \href{https://developers.google.com/earth-engine/reducers_intro}{\emph{reducer}} is an object that tells Earth Engine what statistic to compute. Note that the result of the reduction is an object with one property, array, that stores the covariance matrix. The next step is to compute the eigenvectors and eigenvalues of that covariance matrix:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ eigens }\OperatorTok{=}\NormalTok{ covarArray}\OperatorTok{.}\FunctionTok{eigen}\NormalTok{()}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Since the eigenvalues are appended to the eigenvectors, slice the two apart and discard the eigenvectors

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ eigenVectors }\OperatorTok{=}\NormalTok{ eigens}\OperatorTok{.}\FunctionTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{1}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Perform the matrix multiplication, as with the TC components:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ principalComponents }\OperatorTok{=}\NormalTok{  ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(eigenVectors)}\OperatorTok{.}\FunctionTok{matrixMultiply}\NormalTok{(arrayImage}\OperatorTok{.}\FunctionTok{toArray}\NormalTok{(}\DecValTok{1}\NormalTok{))}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Finally, convert back to a multi-band image and display the first PC:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ pcImage }\OperatorTok{=}\NormalTok{ principalComponents    }
\CommentTok{// Throw out an an  unneeded dimension, [[]] {-}\textgreater{} [].    }
                \OperatorTok{.}\FunctionTok{arrayProject}\NormalTok{([}\DecValTok{0}\NormalTok{])    }
\CommentTok{// Make the one band  array image a multi{-}band image, [] {-}\textgreater{} image.    }
                \OperatorTok{.}\FunctionTok{arrayFlatten}\NormalTok{(}
\NormalTok{          [[}\StringTok{\textquotesingle{}pc1\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}pc2\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}pc3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}pc4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}pc5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}pc6\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}pc7\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}pc8\textquotesingle{}}\NormalTok{]]}
\NormalTok{        )}\OperatorTok{;}      
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(pcImage}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}pc1\textquotesingle{}}\NormalTok{)}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}PC\textquotesingle{}}\NormalTok{)}\OperatorTok{;}   
\end{Highlighting}
\end{Shaded}

Use the \href{https://developers.google.com/earth-engine/playground\#layer-manager}{layer manager} to stretch the result. What do you observe? Try displaying some of the other principal components.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{3b. How much did you need to stretch the results to display outputs for principal component 1? Display and upload images of each the other principal components, stretching each band as needed for visual interpretation and indicating how you selected each stretch. How do you interpret each PC band? On what basis do you make that interpretation? }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{spectral-unmixing}{%
\paragraph{Spectral Unmixing}\label{spectral-unmixing}}

The \href{http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=974727\&tag=1}{linear spectral mixing model} is based on the assumption that each pixel is a mixture of ``pure'' spectra. The pure spectra, called \emph{endmembers}, are from land cover classes such as water, bare land, vegetation. The goal is to solve the following equation for \textbf{f}, the \emph{P}x1 vector of endmember fractions in the pixel:

\[ Sf = p \]

where \textbf{S} is a \emph{B}x\emph{P} matrix in which the columns are \emph{P} pure endmember spectra (known) and \textbf{p} is the \emph{B}x1 pixel vector when there are \emph{B} bands (known). In this example, \(B= 6\):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ unmixImage }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{([}\StringTok{\textquotesingle{}B2\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B6\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B7\textquotesingle{}}\NormalTok{])}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

The first step is to get the endmember spectra. Do that by computing the mean spectra in polygons delineated around regions of pure land cover. Zoom the map to a location with homogeneous areas of bare land, vegetation and water (hint: SFO). Visualize the input as a false color composite.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(image}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.4}\NormalTok{\}}\OperatorTok{,} \StringTok{\textquotesingle{}false color\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Using the \href{https://developers.google.com/earth-engine/playground\#geometry-tools}{geometry drawing tools}, make three new layers (\emph{P}=3) by clicking \textbf{+ new layer}. In the first layer, digitize a polygon around pure bare land; in the second layer make a polygon of pure vegetation; in the third layer, make a water polygon. Name the imports bare, veg, and water, respectively. Check the polygons you made by charting mean spectra in them using \href{https://developers.google.com/earth-engine/charts_image_regions}{Chart.image.regions()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(Chart}\OperatorTok{.}\AttributeTok{image}\OperatorTok{.}\FunctionTok{regions}\NormalTok{(unmixImage}\OperatorTok{,}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{FeatureCollection}\NormalTok{([}
\NormalTok{    ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(bare}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{label}\OperatorTok{:} \StringTok{\textquotesingle{}bare\textquotesingle{}}\NormalTok{\})}\OperatorTok{,} 
\NormalTok{    ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(water}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{label}\OperatorTok{:} \StringTok{\textquotesingle{}water\textquotesingle{}}\NormalTok{\})}\OperatorTok{,}
\NormalTok{    ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(veg}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{label}\OperatorTok{:} \StringTok{\textquotesingle{}vegetation\textquotesingle{}}\NormalTok{\})])}\OperatorTok{,} 
\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{mean}\NormalTok{()}\OperatorTok{,} \DecValTok{30}\OperatorTok{,} \StringTok{\textquotesingle{}label\textquotesingle{}}\OperatorTok{,}\NormalTok{ [}\FloatTok{0.48}\OperatorTok{,} \FloatTok{0.56}\OperatorTok{,} \FloatTok{0.65}\OperatorTok{,} \FloatTok{0.86}\OperatorTok{,} \FloatTok{1.61}\OperatorTok{,} \FloatTok{2.2}\NormalTok{]))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Your chart should look something like:

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{./im/im_04_03} 

}

\caption{Spectral Chart}\label{fig:spectralchartlab3}
\end{figure}

Use the \href{https://developers.google.com/earth-engine/reducers_reduce_region}{reduceRegion() method} to compute mean spectra in the polygons you made. Note that the return value of reduceRegion() is a Dictionary, with reducer output keyed by band name. Get the means as a List by calling values():

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ bareMean }\OperatorTok{=}\NormalTok{ unmixImage}\OperatorTok{.}\FunctionTok{reduceRegion}\NormalTok{(}
\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{mean}\NormalTok{()}\OperatorTok{,}\NormalTok{ bare}\OperatorTok{,} \DecValTok{30}\NormalTok{)}\OperatorTok{.}\FunctionTok{values}\NormalTok{()}\OperatorTok{;}   
\KeywordTok{var}\NormalTok{ waterMean }\OperatorTok{=}\NormalTok{ unmixImage}\OperatorTok{.}\FunctionTok{reduceRegion}\NormalTok{(}
\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{mean}\NormalTok{()}\OperatorTok{,}\NormalTok{ water}\OperatorTok{,} \DecValTok{30}\NormalTok{)}\OperatorTok{.}\FunctionTok{values}\NormalTok{()}\OperatorTok{;}   
\KeywordTok{var}\NormalTok{ vegMean }\OperatorTok{=}\NormalTok{ unmixImage}\OperatorTok{.}\FunctionTok{reduceRegion}\NormalTok{(}
\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{mean}\NormalTok{()}\OperatorTok{,}\NormalTok{ veg}\OperatorTok{,} \DecValTok{30}\NormalTok{)}\OperatorTok{.}\FunctionTok{values}\NormalTok{()}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Each of these three lists represents a mean spectrum vector. Stack the vectors into a 6x3 Array of endmembers by concatenating them along the 1-axis (or columns direction):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ endmembers }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Array}\OperatorTok{.}\FunctionTok{cat}\NormalTok{([bareMean}\OperatorTok{,}\NormalTok{  vegMean}\OperatorTok{,}\NormalTok{ waterMean]}\OperatorTok{,} \DecValTok{1}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Turn the 6-band input image into an image in which each pixel is a 1D vector (\texttt{toArray()}), then into an image in which each pixel is a 6x1 matrix (\texttt{toArray(1)}):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ arrayImage }\OperatorTok{=}\NormalTok{ unmixImage}\OperatorTok{.}\FunctionTok{toArray}\NormalTok{()}\OperatorTok{.}\FunctionTok{toArray}\NormalTok{(}\DecValTok{1}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Now that the dimensions match, in each pixel, solve the equation for \textbf{f}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ unmixed }\OperatorTok{=}\NormalTok{  ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(endmembers)}\OperatorTok{.}\FunctionTok{matrixSolve}\NormalTok{(arrayImage)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Finally, convert the result from a 2D array image into a 1D array image (\texttt{arrayProject()}), then to a multi-band image (\texttt{arrayFlatten()}). The three bands correspond to the estimates of bare, vegetation and water fractions in \textbf{f}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ unmixedImage }\OperatorTok{=}\NormalTok{ unmixed}\OperatorTok{.}\FunctionTok{arrayProject}\NormalTok{([}\DecValTok{0}\NormalTok{])}
                \OperatorTok{.}\FunctionTok{arrayFlatten}\NormalTok{(}
\NormalTok{          [[}\StringTok{\textquotesingle{}bare\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}veg\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}water\textquotesingle{}}\NormalTok{]]}
\NormalTok{        )}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Display the result where bare is red, vegetation is green, and water is blue (the \texttt{addLayer()} call expects bands in order, RGB)

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(unmixedImage}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}Unmixed\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{3c. Upload the mean spectra chart you generated for bare, water, and land. Then upload the resulting map and interpret the output of the \texttt{unmixedImage}}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{hue-saturation-value-transform}{%
\paragraph{Hue-Saturation-Value Transform}\label{hue-saturation-value-transform}}

The Hue-Saturation-Value (HSV) model \href{https://en.wikipedia.org/wiki/HSL_and_HSV}{is a color transform of the RGB color space}. Among many other things, it is useful for \href{https://en.wikipedia.org/wiki/Pansharpened_image}{pan-sharpening}. This involves converting an RGB to HSV, swapping the panchromatic band for the value (V), then converting back to RGB. For example, using the Landsat 8 scene:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//  Convert Landsat RGB bands to HSV   }
\KeywordTok{var}\NormalTok{ hsv }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{([}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{])}\OperatorTok{.}\FunctionTok{rgbToHsv}\NormalTok{()}\OperatorTok{;}
\CommentTok{// Convert back to RGB,  swapping the image panchromatic band for the value.}
\KeywordTok{var}\NormalTok{ rgb }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Image}\OperatorTok{.}\FunctionTok{cat}\NormalTok{([}
\NormalTok{  hsv}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}hue\textquotesingle{}}\NormalTok{)}\OperatorTok{,}
\NormalTok{  hsv}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}saturation\textquotesingle{}}\NormalTok{)}\OperatorTok{,}
\NormalTok{  image}\OperatorTok{.}\FunctionTok{select}\NormalTok{([}\StringTok{\textquotesingle{}B8\textquotesingle{}}\NormalTok{])])}\OperatorTok{.}\FunctionTok{hsvToRgb}\NormalTok{()}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(rgb}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{max}\OperatorTok{:} \FloatTok{0.4}\NormalTok{\}}\OperatorTok{,} \StringTok{\textquotesingle{}Pan{-}sharpened\textquotesingle{}}\NormalTok{)}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{3d. Compare the pan-sharpened image with the original image. What do you notice that's different? The same? }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{spectral-transformation}{%
\subsection{Spectral Transformation}\label{spectral-transformation}}

\hypertarget{linear-filtering}{%
\subsubsection{Linear Filtering}\label{linear-filtering}}

In the present context, linear \emph{filtering} (or \href{http://www.dspguide.com/ch24/1.htm}{convolution}) refers to a linear combination of pixel values in a neighborhood. The neighborhood is specified by a \href{https://en.wikipedia.org/wiki/Kernel_(image_processing)}{kernel}, where the weights of the kernel determine the coefficients in the linear combination. (For this lab, the terms \emph{kernel} and \emph{filter} are interchangeable.) Filtering an image can be useful for extracting image information at different \href{http://www.dspguide.com/ch24/5.htm}{spatial frequencies}. For this reason, smoothing filters are called \emph{low-pass} filters (they let \emph{low}-frequency data \emph{pass} through) and edge detection filters are called \emph{high-pass} filters. To implement filtering in Earth Engine use \href{https://developers.google.com/earth-engine/guides/image_convolutions}{image.convolve()} with an ee.Kernel for the argument.

\hypertarget{smoothing}{%
\paragraph{Smoothing}\label{smoothing}}

Smoothing means to convolve an image with a smoothing kernel.

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\item
  A simple smoothing filter is a square kernel with uniform weights that sum to one. Convolving with this kernel sets each pixel to the mean of its neighborhood. Print a square kernel with uniform weights (this is sometimes called a ``pillbox'' or ``boxcar'' filter):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Print a uniform kernel to see its weights.}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}A uniform kernel:\textquotesingle{}}\OperatorTok{,}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Kernel}\OperatorTok{.}\FunctionTok{square}\NormalTok{(}\DecValTok{2}\NormalTok{))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

  Expand the kernel object in the console to see the weights. This kernel is defined by how many pixels it covers (i.e.~\texttt{radius} is in units of `pixels'). A kernel with radius defined in `meters' adjusts its size in pixels, so you can't visualize its weights, but it's more flexible in terms of adapting to inputs of different scale. In the following, use kernels with radius defined in meters except to visualize the weights.
\item
  Define a kernel with 2-meter radius (Which corresponds to how many pixels in the NAIP image? Hint: try \href{https://developers.google.com/earth-engine/guides/projections}{projection.nominalScale()}), convolve the image with the kernel and compare the input image with the smoothed image:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Define a square, uniform kernel.}
\KeywordTok{var}\NormalTok{ uniformKernel }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Kernel}\OperatorTok{.}\FunctionTok{square}\NormalTok{(\{}
 \DataTypeTok{radius}\OperatorTok{:} \DecValTok{2}\OperatorTok{,}
 \DataTypeTok{units}\OperatorTok{:} \StringTok{\textquotesingle{}meters\textquotesingle{}}\OperatorTok{,}
\NormalTok{\})}\OperatorTok{;}
\CommentTok{// Filter the image by convolving with the smoothing filter.}
\KeywordTok{var}\NormalTok{ smoothed }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{convolve}\NormalTok{(uniformKernel)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(smoothed}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.35}\NormalTok{\}}\OperatorTok{,} \StringTok{\textquotesingle{}smoothed image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\item
  To make the image even smoother, try increasing the size of the neighborhood by increasing the pixel radius.
\item
  A Gaussian kernel can also be used for smoothing. Think of filtering with a Gaussian kernel as computing the weighted average in each pixel's neighborhood. For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Print a Gaussian kernel to see its weights.}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}A Gaussian kernel:\textquotesingle{}}\OperatorTok{,}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Kernel}\OperatorTok{.}\FunctionTok{gaussian}\NormalTok{(}\DecValTok{2}\NormalTok{))}\OperatorTok{;}
\CommentTok{// Define a square Gaussian kernel:}
\KeywordTok{var}\NormalTok{ gaussianKernel }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Kernel}\OperatorTok{.}\FunctionTok{gaussian}\NormalTok{(\{}
 \DataTypeTok{radius}\OperatorTok{:} \DecValTok{2}\OperatorTok{,}
 \DataTypeTok{units}\OperatorTok{:} \StringTok{\textquotesingle{}meters\textquotesingle{}}\OperatorTok{,}
\NormalTok{\})}\OperatorTok{;}
\CommentTok{// Filter the image by convolving with the Gaussian filter.}
\KeywordTok{var}\NormalTok{ gaussian }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{convolve}\NormalTok{(gaussianKernel)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(gaussian}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.25}\NormalTok{\}}\OperatorTok{,} \StringTok{\textquotesingle{}Gaussian smoothed image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{4a. What happens as you increase the pixel radius for each smoothing? What differences can you discern between the weights and the visualizations of the two smoothing kernels?}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{edge-detection}{%
\paragraph{Edge Detection}\label{edge-detection}}

Convolving with an edge-detection kernel is used to find rapid changes in DNs that usually signify edges of objects represented in the image data.

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\item
  A classic edge detection kernel is the \href{https://en.wikipedia.org/wiki/Discrete_Laplace_operator}{Laplacian} kernel. Investigate the kernel weights and the image that results from convolving with the Laplacian:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Define a Laplacian, or edge{-}detection kernel.}
\KeywordTok{var}\NormalTok{ laplacian }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Kernel}\OperatorTok{.}\FunctionTok{laplacian8}\NormalTok{(\{ }\DataTypeTok{normalize}\OperatorTok{:} \KeywordTok{false}\NormalTok{ \})}\OperatorTok{;}

\CommentTok{// Apply the edge{-}detection kernel.}
\KeywordTok{var}\NormalTok{ edgy }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{convolve}\NormalTok{(laplacian)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(edgy}\OperatorTok{,}
\NormalTok{             \{}\DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{0.5}\OperatorTok{,} \DataTypeTok{format}\OperatorTok{:} \StringTok{\textquotesingle{}png\textquotesingle{}}\NormalTok{\}}\OperatorTok{,}
             \StringTok{\textquotesingle{}edges\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{4b. Upload the image of \texttt{edgy} and describe the output }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Other edge detection kernels include the \href{https://en.wikipedia.org/wiki/Sobel_operator}{Sobel}, \href{https://en.wikipedia.org/wiki/Prewitt_operator}{Prewitt} and \href{https://en.wikipedia.org/wiki/Roberts_cross}{Roberts} kernels. \href{https://developers.google.com/earth-engine/image_edges}{Learn more about additional edge detection methods in Earth Engine}.
\end{enumerate}

\hypertarget{gradients}{%
\paragraph{Gradients}\label{gradients}}

An image gradient refers to the change in pixel values over space (analogous to computing slope from a DEM).

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  Use \href{https://developers.google.com/earth-engine/guides/image_gradients}{image.gradient()} to compute the gradient in an image band.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
   \CommentTok{// Load a Landsat 8 image and select the panchromatic band.}
  \KeywordTok{var}\NormalTok{ Landsat8B8 }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(}\StringTok{\textquotesingle{}LANDSAT/LC08/C01/T1/LC08\_044034\_20140318\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B8\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
  
  \KeywordTok{var}\NormalTok{ xyGrad }\OperatorTok{=}\NormalTok{ Landsat8B8}\OperatorTok{.}\FunctionTok{gradient}\NormalTok{()}\OperatorTok{;}
  
  \CommentTok{// Compute the magnitude of the gradient.}
  \KeywordTok{var}\NormalTok{ gradient }\OperatorTok{=}\NormalTok{ xyGrad}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{pow}\NormalTok{(}\DecValTok{2}\NormalTok{)}
            \OperatorTok{.}\FunctionTok{add}\NormalTok{(xyGrad}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{pow}\NormalTok{(}\DecValTok{2}\NormalTok{))}\OperatorTok{.}\FunctionTok{sqrt}\NormalTok{()}\OperatorTok{;}
  
  \CommentTok{// Compute the direction of the gradient.}
  \KeywordTok{var}\NormalTok{ direction }\OperatorTok{=}\NormalTok{ xyGrad}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{atan2}\NormalTok{(xyGrad}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Gradients in the NIR band indicate transitions in vegetation. For an in-depth study of gradients in multi-spectral imagery, see \href{http://www.sciencedirect.com/science/article/pii/0734189X86902239}{Di Zenzo (1986)}.
\end{enumerate}

--\textgreater{}

\hypertarget{additional-exercises-2}{%
\subsection{Additional Exercises}\label{additional-exercises-2}}

\textbf{5a. Look in google scholar to identify 2-3 publications that have used NDVI and two-three that used EVI. For what purposes were these indices used and what was the justification provided for that index? }

\textbf{5b. Discuss a spectral index that we did not cover in this lab relates to your area of research/interest. What is the the name of the spectral index, the formula used to calculate it, and what is it used to detect? Provide a citation of an academic article that has fruitfully used that index. }

\textbf{5c. Find 1-2 articles that use any of the linear transformation methods we practiced in this lab in the service of addressing an important social issue (e.g., one related to agriculture, environment, or development). Provide the citations and discussed how the transformation is used and how it's justified in the article. }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{where-to-submit-2}{%
\subsection*{Where to submit}\label{where-to-submit-2}}
\addcontentsline{toc}{subsection}{Where to submit}

Submit your responses to these questions on \href{https://www.gradescope.com/courses/293173/assignments/1446622/submissions}{Gradescope} by 10am on Wednesday, September 22. If needed, the access code for our course is \texttt{6PEW3W}.

\hypertarget{classification}{%
\section{Classification}\label{classification}}

\hypertarget{overview-4}{%
\subsection*{Overview}\label{overview-4}}
\addcontentsline{toc}{subsection}{Overview}

While it is possible for a human to look at a satellite image and identify objects or land cover types based on their visual characteristics, the sheer magnitude and volume of imagery makes it very difficult to do this manually. To compensate, machine learning allows computers to process this information much quicker than a human and find meaningful insights about what we see in the imagery. Image classification is an essential component in today's remote sensing, and there are many opportunities in this growing field. By training ML models to efficiently process the data and return labeled information, we can focus on the insights and higher-level insights.

Google Earth Engine offers many options in to work with classification which we will get familiar with. Most broadly, we can separate classification into two parts - supervised and unsupervised classification. We will introduce both components and work our way through several examples.

\hypertarget{introduction-to-classification}{%
\subsection{Introduction to Classification}\label{introduction-to-classification}}

For present purposes, define prediction as guessing the value of some geographic variable of interest \texttt{g}, using a function \texttt{G} that takes as input a pixel vector \textbf{\texttt{p}}:

\[
G_{t}(p_{i}) = g_{i}
\]
The \emph{i} in this equation refers to a particular instance from a set of pixels. Think of \emph{G} as a guessing function and \(g_{i}\) as the guess for pixel \emph{i}. The \textbf{T} in the subscript of \emph{G} refers to a \emph{training set} (a set of known values for \textbf{p} and the correct \emph{g}), used to infer the structure of \emph{G}. You have to choose a suitable \emph{G} to train with \textbf{T}.

When \texttt{g} is nominal, or a fixed category (ex., \{`water', `vegetation', `bare'\}), we call this classification.

When \texttt{g} is numeric (ex., \{0, 1, 2, 3\}), we call this regression.

This is an incredibly simplistic description of a problem addressed in a broad range of fields including mathematics, statistics, data mining, machine learning. For our purposes, we will go through some examples using these concepts in Google Earth Engine and then provide more resources for further reading at the end.

\hypertarget{unsupervised-classification}{%
\subsection{Unsupervised Classification}\label{unsupervised-classification}}

Unsupervised classification finds unique groupings in the dataset without manually developed training data. The computer will cycle through the pixels, look at the characteristics of the different bands, and pixel-by-pixel begin to group information together. Perhaps pixels with a blue hue and a low NIR value are grouped together, while green-dominant pixels are also grouped together. The outcome of unsupervised classification is that each pixel is categorized within the context of the image, and there will be the number of categories specified. One important note, is that the number of clusters is set by the user, and this plays a major role in how the algorithm operates. Too many clusters creates unnecessary noise, while too few clusters does not have enough granularity.

Google Earth Engine provides \href{https://developers.google.com/earth-engine/guides/clustering}{documentation} on working with unsupervised classification within their ecosystem, and we will be focusing on the \texttt{ee.Clusterer} package, which provides a flexible unsupervised classification (or clustering) in an easy-to-use way.

Clusterers are used in the same manner as classifiers in Earth Engine. The general workflow for clustering is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Assemble features with numeric properties to find clusters
\item
  Instantiate a clusterer - set its parameters if necessary
\item
  Train the clusterer using the training data
\item
  Apply the clusterer to an image or feature collection
\item
  Label the clusters
\end{enumerate}

Begin by creating a study region - in this case we will be working the Amazon Rainforest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Lab: Unsupervised Classification (Clustering)}
\CommentTok{// Create region}
\KeywordTok{var}\NormalTok{ region }\OperatorTok{=}\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Polygon}\NormalTok{([[}
\NormalTok{  [}\OperatorTok{{-}}\FloatTok{54.07419968695418}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{3.558053010380929}\NormalTok{]}\OperatorTok{,}
\NormalTok{  [}\OperatorTok{{-}}\FloatTok{54.07419968695418}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{3.8321399733300234}\NormalTok{]}\OperatorTok{,}
\NormalTok{  [}\OperatorTok{{-}}\FloatTok{53.14310837836043}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{3.8321399733300234}\NormalTok{]}\OperatorTok{,}
\NormalTok{  [}\OperatorTok{{-}}\FloatTok{53.14310837836043}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{3.558053010380929}\NormalTok{]]]}\OperatorTok{,} \KeywordTok{null}\OperatorTok{,} \KeywordTok{false}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(region}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{"Region"}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{centerObject}\NormalTok{(region}\OperatorTok{,} \DecValTok{10}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Function to mask clouds based on the pixel\_qa band of Landsat 8 SR data.}
\KeywordTok{function} \FunctionTok{maskL8sr}\NormalTok{(image) \{}
\CommentTok{// Bits 3 and 5 are cloud shadow and cloud, respectively.}
        \KeywordTok{var}\NormalTok{ cloudShadowBitMask }\OperatorTok{=}\NormalTok{ (}\DecValTok{1} \OperatorTok{\textless{}\textless{}} \DecValTok{3}\NormalTok{)}\OperatorTok{;}
        \KeywordTok{var}\NormalTok{ cloudsBitMask }\OperatorTok{=}\NormalTok{ (}\DecValTok{1} \OperatorTok{\textless{}\textless{}} \DecValTok{5}\NormalTok{)}\OperatorTok{;}
        \CommentTok{// Get the pixel QA band.}
        \KeywordTok{var}\NormalTok{ qa }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}pixel\_qa\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
        \CommentTok{// Both flags should be set to zero, indicating clear conditions.}
        \KeywordTok{var}\NormalTok{ mask }\OperatorTok{=}\NormalTok{ qa}\OperatorTok{.}\FunctionTok{bitwiseAnd}\NormalTok{(cloudShadowBitMask)}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\DecValTok{0}\NormalTok{)}
                \OperatorTok{.}\FunctionTok{and}\NormalTok{(qa}\OperatorTok{.}\FunctionTok{bitwiseAnd}\NormalTok{(cloudsBitMask)}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\DecValTok{0}\NormalTok{))}\OperatorTok{;}
           \ControlFlowTok{return}\NormalTok{ image}\OperatorTok{.}\FunctionTok{updateMask}\NormalTok{(mask)}\OperatorTok{;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We will be working with Landsat data, which you can read in below. We will filter the data to the date range, map cloud pixels and work within the study region.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Load Landsat 8 annual composites.}
\KeywordTok{var}\NormalTok{ landsat }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{\textquotesingle{}LANDSAT/LC08/C01/T1\_SR\textquotesingle{}}\NormalTok{)}
      \OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}\StringTok{\textquotesingle{}2019{-}01{-}01\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}2019{-}12{-}31\textquotesingle{}}\NormalTok{)}
      \OperatorTok{.}\FunctionTok{map}\NormalTok{(maskL8sr)}
      \OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(region)}
      \OperatorTok{.}\FunctionTok{median}\NormalTok{()}\OperatorTok{;}
\CommentTok{//Display Landsat data}
\KeywordTok{var}\NormalTok{ visParams }\OperatorTok{=}\NormalTok{ \{}
       \DataTypeTok{bands}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B2\textquotesingle{}}\NormalTok{]}\OperatorTok{,}
       \DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,}
       \DataTypeTok{max}\OperatorTok{:} \DecValTok{3000}\OperatorTok{,}
       \DataTypeTok{gamma}\OperatorTok{:} \FloatTok{1.4}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{centerObject}\NormalTok{(region}\OperatorTok{,} \DecValTok{9}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(landsat}\OperatorTok{,}\NormalTok{ visParams}\OperatorTok{,} \StringTok{"Landsat 8 (2016)"}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

In this case, we will randomly select a sample of 5000 pixels in the region to build a clustering model - we will use this `training' data to find clustering groups and then apply it to the rest of the data We will also set the variable \texttt{clusterNum} to idenfity how many categories to use. Start with 15, and modify based on the output and needs of your experiment. Note that we are using \texttt{ee.Clusterer.wekaKMeans},

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Create a training dataset.}
\KeywordTok{var}\NormalTok{ training }\OperatorTok{=}\NormalTok{ landsat}\OperatorTok{.}\FunctionTok{sample}\NormalTok{(\{}
     \DataTypeTok{region}\OperatorTok{:}\NormalTok{ region}\OperatorTok{,}
     \DataTypeTok{scale}\OperatorTok{:} \DecValTok{30}\OperatorTok{,}
     \DataTypeTok{numPixels}\OperatorTok{:} \DecValTok{5000}
\NormalTok{\})}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ clusterNum }\OperatorTok{=} \DecValTok{15}  
\CommentTok{// Instantiate the clusterer and train it.}
\KeywordTok{var}\NormalTok{ clusterer }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Clusterer}\OperatorTok{.}\FunctionTok{wekaKMeans}\NormalTok{(clusterNum)}\OperatorTok{.}\FunctionTok{train}\NormalTok{(training)}\OperatorTok{;}
\CommentTok{// Cluster the input using the trained clusterer.}
\KeywordTok{var}\NormalTok{ result }\OperatorTok{=}\NormalTok{ landsat}\OperatorTok{.}\FunctionTok{cluster}\NormalTok{(clusterer)}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(}\StringTok{"result"}\OperatorTok{,}\NormalTok{ result}\OperatorTok{.}\FunctionTok{getInfo}\NormalTok{())}\OperatorTok{;}
\CommentTok{// Display the clusters with random colors.}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(result}\OperatorTok{.}\FunctionTok{randomVisualizer}\NormalTok{()}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}Unsupervised Classification\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

As you can see from the output, the result is quite vivid. On the `layers' toggle on the top-right of the map section, increase the transparency of the layer to compare it to the satellite imagery.

Change the variable \texttt{clusterNum} and run through some different options to find better results. Note that the output of an unsupervised clustering model is not specifying that each pixel should be a certain type of label (ex, the pixel is `water'), but rather that these pixels have similar characteristics.

\textbf{Question}: If you were going to use a clustering model to identify water in the image, is 15 an appropriate cluster number?

\hypertarget{supervised-classification}{%
\subsection{Supervised Classification}\label{supervised-classification}}

Just like in unsupervised classification, GEE has \href{https://developers.google.com/earth-engine/classification}{documentation} that works through several examples. Supervised classification is an iterative process of obtaining training data, creating an initial model, reviewing the results and tuning the parameters. Many projects using supervised classification may take several months of years of fine-tuning, requiring constant refinement and maintenance. Below is a list of the steps of Supervised learning according to GEE.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Collect the training data
\item
  Instantiate the classifier
\item
  Train the classifier
\item
  Classify the image
\item
  Tune the model.
\end{enumerate}

We will begin by creating training data manually within GEE. Using the geometry tools and the Landsat composite as a background, we can digitize training polygons. We'll need to do two things: identify where polygons occur on the ground, and label them with the proper class number.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a polygon around an area of bare earth (dirt, no vegetation), then \href{https://developers.google.com/earth-engine/playground\#geometry-tools}{configure the import}. Import as FeatureCollection, then click \textbf{\texttt{+\ New\ property}}. Name the new property `class' and give it a value of 0. The dialog should show \textbf{class}: 0. Name the import `bare'.
\item
  \textbf{\texttt{+\ New\ property}} \textgreater{} Draw a polygon around vegetation \textgreater{} import as FeatureCollection \textgreater{} add a property \textgreater{} name it `class' and give it a value of 1. Name the import `vegetation'.
\item
  \textbf{\texttt{+\ New\ property}} \textgreater{} Draw a polygon around water \textgreater{} import as FeatureCollection \textgreater{} add a property \textgreater{} name it `class' and give it a value of 2. Name the import `water'.
\item
  You should have three FeatureCollection imports named `bare', `vegetation' and `water'. Merge them into one FeatureCollection:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ trainingFeatures }\OperatorTok{=}\NormalTok{ bare}\OperatorTok{.}\FunctionTok{merge}\NormalTok{(vegetation)}\OperatorTok{.}\FunctionTok{merge}\NormalTok{(water)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

In the merged FeatureCollection, each Feature should have a property called `class' where the classes are consecutive integers, one for each class, starting at 0. Verify that this is true.

For Landsat, we will use the following bands for their predictive values - we could just keep the visual bands, but using a larger number of predictive values in many cases improves the model's ability to find relationships and patterns in the data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ predictionBands }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}B2\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B3\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B6\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B7\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B10\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B11\textquotesingle{}}\NormalTok{]}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Create a training set \textbf{T} for the classifier by sampling the Landsat composite with the merged features.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ classifierTraining }\OperatorTok{=}\NormalTok{ landsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(predictionBands)}
  \OperatorTok{.}\FunctionTok{sampleRegions}\NormalTok{(\{}
   \DataTypeTok{collection}\OperatorTok{:}\NormalTok{ trainingFeatures}\OperatorTok{,} 
   \DataTypeTok{properties}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{]}\OperatorTok{,} 
   \DataTypeTok{scale}\OperatorTok{:} \DecValTok{30}
\NormalTok{  \})}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

The choice of classifier is not always obvious, but a CART (a \href{https://en.wikipedia.org/wiki/Decision_tree_learning}{decision tree} when running in classification mode) is an excellent starting point. Instantiate a CART and train it.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ classifier }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Classifier}\OperatorTok{.}\FunctionTok{smileCart}\NormalTok{()}\OperatorTok{.}\FunctionTok{train}\NormalTok{(\{}
 \DataTypeTok{features}\OperatorTok{:}\NormalTok{ classifierTraining}\OperatorTok{,} 
 \DataTypeTok{classProperty}\OperatorTok{:} \StringTok{\textquotesingle{}class\textquotesingle{}}\OperatorTok{,} 
 \DataTypeTok{inputProperties}\OperatorTok{:}\NormalTok{ predictionBands}
\NormalTok{\})}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Classify the image and visualize the image.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ classified }\OperatorTok{=}\NormalTok{ landsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(predictionBands)}
                \OperatorTok{.}\FunctionTok{classify}\NormalTok{(classifier)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(classified}\OperatorTok{,} 
\NormalTok{             \{}\DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{2}\OperatorTok{,} 
              \DataTypeTok{palette}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}red\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}green\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{]\}}\OperatorTok{,} 
             \StringTok{\textquotesingle{}classified\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Inspect the result. Some things to test if the result is unsatisfactory:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Other classifiers

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Try some of the other classifiers in Earth Engine to see if the result is better or different. You can find different classifiers under \texttt{Docs} on the left panel of the console.
  \end{enumerate}
\item
  Different (or more) training data.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Try adjusting the shape and/or size of your training polygons to have a more representative sample of your classes. It is very common to either underfit or overfit your model when beginning the process.
  \end{enumerate}
\item
  Add more predictors.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Try adding spectral indices to the input variables.
  \end{enumerate}
\end{enumerate}

\hypertarget{accuracy-assessment}{%
\subsection{Accuracy Assessment}\label{accuracy-assessment}}

The previous section asked the question whether the result is satisfactory or not. In remote sensing, the quantification of the answer is called accuracy assessment. In the regression context, a standard measure of accuracy is the \href{https://en.wikipedia.org/wiki/Root-mean-square_deviation}{Root Mean Square Error} (RMSE) or the \href{https://en.wikipedia.org/wiki/Correlation_and_dependence}{correlation} between known and predicted values. (Although the RMSE is returned by the linear regression reducer, beware: this is computed from the training data and is not a fair estimate of expected prediction error when guessing a pixel not in the training set). It is testing how accurate the model is based on the existing training data, but proper methodology uses separate ground-truth values for testing. In the classification context, accuracy measurements are often derived from a \href{https://en.wikipedia.org/wiki/Confusion_matrix}{confusion matrix}.

The first step is to partition the set of known values into training and testing sets. Reusing the classification training set, add a column of random numbers used to partition the known data where about 60\% of the data will be used for training and 40\% for testing:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ trainingTesting }\OperatorTok{=}\NormalTok{ classifierTraining}\OperatorTok{.}\FunctionTok{randomColumn}\NormalTok{()}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ trainingSet }\OperatorTok{=}\NormalTok{ trainingTesting}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{lessThan}\NormalTok{(}\StringTok{\textquotesingle{}random\textquotesingle{}}\OperatorTok{,}  \FloatTok{0.6}\NormalTok{))}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ testingSet }\OperatorTok{=}\NormalTok{ trainingTesting}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{greaterThanOrEquals}\NormalTok{(}\StringTok{\textquotesingle{}random\textquotesingle{}}\OperatorTok{,} \FloatTok{0.6}\NormalTok{))}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Train the classifier with the trainingSet:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ trained }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Classifier}\OperatorTok{.}\FunctionTok{smileCart}\NormalTok{()}\OperatorTok{.}\FunctionTok{train}\NormalTok{(\{}
  \DataTypeTok{features}\OperatorTok{:}\NormalTok{ trainingSet}\OperatorTok{,}
  \DataTypeTok{classProperty}\OperatorTok{:} \StringTok{\textquotesingle{}class\textquotesingle{}}\OperatorTok{,}
  \DataTypeTok{inputProperties}\OperatorTok{:}\NormalTok{ predictionBands}
\NormalTok{\})}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Classify the testingSet and get a confusion matrix. Note that the classifier automatically adds a property called `classification', which is compared to the `class' property added when you imported your polygons:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ confusionMatrix }\OperatorTok{=}\NormalTok{  ee}\OperatorTok{.}\FunctionTok{ConfusionMatrix}\NormalTok{(testingSet}\OperatorTok{.}\FunctionTok{classify}\NormalTok{(trained)}
                                          \OperatorTok{.}\FunctionTok{errorMatrix}\NormalTok{(\{}\DataTypeTok{actual}\OperatorTok{:} \StringTok{\textquotesingle{}class\textquotesingle{}}\OperatorTok{,}
                                                        \DataTypeTok{predicted}\OperatorTok{:} \StringTok{\textquotesingle{}classification\textquotesingle{}}\NormalTok{\}))}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Print the confusion matrix and expand the object to inspect the matrix. The entries represent the number of pixels. Items on the diagonal represent correct classification. Items off the diagonal are misclassifications, where the class in row \emph{i} is classified as column \emph{j}. It's also possible to get basic descriptive statistics from the confusion matrix. For example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Confusion matrix:\textquotesingle{}}\OperatorTok{,}\NormalTok{ confusionMatrix)}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Overall Accuracy:\textquotesingle{}}\OperatorTok{,}\NormalTok{ confusionMatrix}\OperatorTok{.}\FunctionTok{accuracy}\NormalTok{())}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Producers Accuracy:\textquotesingle{}}\OperatorTok{,}\NormalTok{ confusionMatrix}\OperatorTok{.}\FunctionTok{producersAccuracy}\NormalTok{())}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Consumers Accuracy:\textquotesingle{}}\OperatorTok{,}\NormalTok{ confusionMatrix}\OperatorTok{.}\FunctionTok{consumersAccuracy}\NormalTok{())}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

Note that you can test different classifiers by replacing CART with some other classifier of interest. Also note that as a result of the randomness in the partition, you may get different results from different runs.

\hypertarget{hyperparameter-tuning}{%
\subsection{Hyperparameter Tuning}\label{hyperparameter-tuning}}

Another fancy classifier is called a random forest (\href{https://link.springer.com/article/10.1023/A:1010933404324}{Breiman 2001}). A random forest is a collection of random trees in that the predictions of which are used to compute an average (regression) or vote on a label (classification). Their adaptability makes them one of the most effective classification models, and is an excellent starting point. Because random forests are so good, we need to make things a little harder for it to be interesting. Do that by adding noise to the training data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ sample }\OperatorTok{=}\NormalTok{ landsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(predictionBands)}\OperatorTok{.}\FunctionTok{sampleRegions}\NormalTok{(}
\NormalTok{  \{}\DataTypeTok{collection}\OperatorTok{:}\NormalTok{ trainingFeatures}
   \OperatorTok{.}\FunctionTok{map}\NormalTok{(}\KeywordTok{function}\NormalTok{(f) \{}
    \ControlFlowTok{return}\NormalTok{  f}\OperatorTok{.}\FunctionTok{buffer}\NormalTok{(}\DecValTok{300}\NormalTok{)}
\NormalTok{   \}}
\NormalTok{       )}\OperatorTok{,} \DataTypeTok{properties}\OperatorTok{:}\NormalTok{ [}\StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{]}\OperatorTok{,} \DataTypeTok{scale}\OperatorTok{:} \DecValTok{30}\NormalTok{\})}\OperatorTok{;}  
\KeywordTok{var}\NormalTok{ classifier }\OperatorTok{=}\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Classifier}\OperatorTok{.}\FunctionTok{smileRandomForest}\NormalTok{(}\DecValTok{10}\NormalTok{)}
                \OperatorTok{.}\FunctionTok{train}\NormalTok{(\{}\DataTypeTok{features}\OperatorTok{:}\NormalTok{ sample}\OperatorTok{,}
                \DataTypeTok{classProperty}\OperatorTok{:} \StringTok{\textquotesingle{}class\textquotesingle{}}\OperatorTok{,}
                \DataTypeTok{inputProperties}\OperatorTok{:}\NormalTok{ predictionBands}
\NormalTok{               \})}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ classified }\OperatorTok{=}\NormalTok{  landsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(predictionBands)}\OperatorTok{.}\FunctionTok{classify}\NormalTok{(classifier)}\OperatorTok{;}   \BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(classified}\OperatorTok{,}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \DecValTok{0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \DecValTok{2}\OperatorTok{,}  \DataTypeTok{palette}\OperatorTok{:} 
\NormalTok{             [}\StringTok{\textquotesingle{}red\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}green\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{]\}}\OperatorTok{,} \StringTok{\textquotesingle{}classified\textquotesingle{}}\NormalTok{)                                                                     }
\end{Highlighting}
\end{Shaded}

Note that the only parameter to the classifier is the number of trees (10). How many trees should you use? Making that choice is best done by hyperparameter tuning. For example,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ sample  }\OperatorTok{=}\NormalTok{ sample}\OperatorTok{.}\FunctionTok{randomColumn}\NormalTok{()}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ train }\OperatorTok{=}\NormalTok{ sample}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{lt}\NormalTok{(}\StringTok{\textquotesingle{}random\textquotesingle{}}\OperatorTok{,} \FloatTok{0.6}\NormalTok{))}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ test }\OperatorTok{=}\NormalTok{ sample}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{gte}\NormalTok{(}\StringTok{\textquotesingle{}random\textquotesingle{}}\OperatorTok{,} \FloatTok{0.6}\NormalTok{))}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ numTrees }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{List}\OperatorTok{.}\FunctionTok{sequence}\NormalTok{(}\DecValTok{5}\OperatorTok{,} \DecValTok{50}\OperatorTok{,} \DecValTok{5}\NormalTok{)}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ accuracies }\OperatorTok{=}\NormalTok{ numTrees}\OperatorTok{.}\FunctionTok{map}\NormalTok{(}\KeywordTok{function}\NormalTok{(t) \{}
\KeywordTok{var}\NormalTok{ classifier }\OperatorTok{=}\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Classifier}\OperatorTok{.}\FunctionTok{smileRandomForest}\NormalTok{(t)}
                \OperatorTok{.}\FunctionTok{train}\NormalTok{(\{}
          \DataTypeTok{features}\OperatorTok{:}\NormalTok{ train}\OperatorTok{,}
          \DataTypeTok{classProperty}\OperatorTok{:} \StringTok{\textquotesingle{}class\textquotesingle{}}\OperatorTok{,}
          \DataTypeTok{inputProperties}\OperatorTok{:}\NormalTok{ predictionBands}
\NormalTok{  \})}\OperatorTok{;}
  \ControlFlowTok{return}\NormalTok{ test}\OperatorTok{.}\FunctionTok{classify}\NormalTok{(classifier)}
    \OperatorTok{.}\FunctionTok{errorMatrix}\NormalTok{(}\StringTok{\textquotesingle{}class\textquotesingle{}}\OperatorTok{,}  \StringTok{\textquotesingle{}classification\textquotesingle{}}\NormalTok{)}
    \OperatorTok{.}\FunctionTok{accuracy}\NormalTok{()}\OperatorTok{;}
\NormalTok{\})}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(ui}\OperatorTok{.}\AttributeTok{Chart}\OperatorTok{.}\AttributeTok{array}\OperatorTok{.}\FunctionTok{values}\NormalTok{(\{}
  \DataTypeTok{array}\OperatorTok{:}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Array}\NormalTok{(accuracies)}\OperatorTok{,}
  \DataTypeTok{axis}\OperatorTok{:} \DecValTok{0}\OperatorTok{,}
  \DataTypeTok{xLabels}\OperatorTok{:}\NormalTok{ numTrees}
\NormalTok{\}))}\OperatorTok{;}  
\end{Highlighting}
\end{Shaded}

You should see something like the following chart, in which the number of trees is on the x-axis and estimated accuracy is on the y-axis:

\begin{figure}
\centering
\includegraphics{./im/im_05_01.png}
\caption{Chart, scatter chart Description automatically generated}
\end{figure}

First, note that we always get very good accuracy in this simple example. Second, note that 10 is not the optimal number of trees, but after adding more (up to about 20 or 30), we don't get much more accuracy for the increased computational burden. So 20 trees is probably a good number to use in the context of this example.

\hypertarget{assignment}{%
\subsection{Assignment}\label{assignment}}

Design a four-class classification for your area of interest. Decide on suitable input data and manually collect training points (or polygons) if necessary. Tune a random forest classifier. In your code, have a variable called trees that sets the optimal number of trees according to your hyper-parameter tuning. Have a variable called \texttt{maxAccuracy} that stores the estimated accuracy for the optimal number of trees.

\hypertarget{where-to-submit-3}{%
\subsection*{Where to submit}\label{where-to-submit-3}}
\addcontentsline{toc}{subsection}{Where to submit}

Submit your responses to these questions on \href{https://www.gradescope.com/courses/293173/assignments/1446622/submissions}{Gradescope} by 10am on Wednesday, September 30. If needed, the access code for our course is \texttt{6PEW3W}.

\hypertarget{lab5}{%
\section{Time Series Modeling}\label{lab5}}

\hypertarget{overview-5}{%
\subsection*{Overview}\label{overview-5}}
\addcontentsline{toc}{subsection}{Overview}

The purpose of this lab is to establish a foundation for time series analysis on remotely sensed data. You will be introduced to the fundamentals of time series modeling, including decomposition, autocorrelation and modeling historical changes. At the completion of this lab, you will be able to build an explanatory model for temporal data which can be used in many different avenues of research.

\hypertarget{background}{%
\subsection{Background}\label{background}}

One of the paradigm-changing features of Earth Engine is the ability to access decades of imagery without the previous limitation of needing to download, organize, store and process this information. For instance, within the Landsat image collection we can access imagery back to 1972, allowing us to look at an area to visualize and quantify how much it's changed over time. With Earth Engine, Google maintains the data and offers it's compute power for processing - users can access tens or hundreds of time-sequenced images and quantify change across decades.

To explain the concepts of time series modeling, let's begin with a dataset that illustrates what we are trying to do. The line chart below references electricity production over thirty years, with one distinct data point per month. What can we observe?

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Production tends to increase each year - In this case, it appears to level out after 2010, but there is a general trend upwards.
\item
  Within each yearly cycle, we see that there is a sharp peak in June and July, and a trough in October and December. An annual, 12-month cycle is specifically referred to as `seasonality', although there can be other cyclical time periods (ex., a housing market in a specific area may see a recurring pattern in house prices that occurs roughtly every 7 years)
\item
  Finally, the magnitude of the difference between each yearly peak and trough increases over time as well.
\end{enumerate}

\hypertarget{im_06_07}{%
\subsubsection{\texorpdfstring{\protect\includegraphics{./im/im_06_01.png}}{im\_06\_07}}\label{im_06_07}}

With these observations, we can address each of the components individually and perhaps build an explanatory model. The time series decomposition below (generated in R) breaks up the data into separate components.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The `observed' line chart is the data in original form.
\item
  The next chart is a trendline built using a window function (each data point is plotted as the average of the previous 12 data points). You can see the general trend of the data and determine whether a linear fit is appropriate.
\item
  The seasonal chart seeks to identify cyclical patterns in the data - in this case, patterns that repeat every 12 months. It subtracts the trend from the observed points and averages the data for each time period (month).\\
\item
  Finally, the `random' line chart is the residual amount remaining when you remove the trend and seasonality from the data.
\end{enumerate}

\begin{figure}
\centering
\includegraphics{./im/im_06_02.png}
\caption{im\_06\_06}
\end{figure}

\hypertarget{limitations-in-remote-sensing-time-series}{%
\subsubsection{Limitations in Remote Sensing Time Series}\label{limitations-in-remote-sensing-time-series}}

Time Series modeling aims to build an an explanatory model of the data without overfitting the problem set - to use as simple a model as possible while accounting for as much of the data as possible. The previous example was used to illustrate the concepts of breaking down time series data into component parts, but remote sensing data has additional limitations that make this more challenging. Note that in the previous example used there was a well-formed data point for every single month - nothing was missing or obviously erroneous. It is almost inevitable that you will not get this same level of precision from remote sensing data. For instance, Landsat has 16-day temporal resolution - but depending on the area, removing cloudy pixels will remove a significant portion. For instance, in a test area in the Galapagos Islands, over 85\% of the data was removed due to cloud masking or atmospheric conditions. Issues such as the Landsat 7 Scan Line Corrector malfunction might prevent a cohesive time series dataset depending on your time period of research. Also, while the time series example we used involved measured values on the same scale throughout the time series (ie, a gigawatt is the same unit of measurement throughout the entire time series), with remote sensing we often run into situations where the magnitude of measurement changes. If we are researching winter crop yield and an image is collected right after a heavy snowfall, how do we compare this value? Do we keep this data or remove it? Additionally, atmospheric conditions can skew the visual results, where the hue of the vegetation changes drastically from image to image due to atmospheric conditions (fog, ground moisture, cloud cover).

For your project, you have to understand the characteristics of both your data and what you are trying to measure. Building a time series model to understand cyclical changes in vegetation can provide useful information in understanding crop yield - but if you do not account for issues in the data, you can end up building a faulty time series model that leads to erroneous results. Many time series modeling tools, such as ARIMA modeling, are not directly applicable in certain settings due to missing data, non-standard collection periods and varying intensity of due to atmospheric conditions. In this lab, we will focus on understanding on linear trends and harmonic modeling.

\hypertarget{multi-temporal-data-in-earth-engine}{%
\subsubsection{Multi-Temporal Data in Earth Engine}\label{multi-temporal-data-in-earth-engine}}

Time series data in Earth Engine are represented as a series of images called `Image Collections'. As a result of the complicating factors in remote sensing discussed earlier, analyzing time series in Earth Engine is unlike time series modeling in traditional methods. From a programming sense, we will join data together to define temporal relationships between collection items and build functions to reduce this tim.

First, some very basic mathematical notation for time series. A time series is an array of the value being measured, sorted chronologically: \{ \(\textbf{p}_{t} = t_{0} + t_{1}... t_{N}\) \}, where each \emph{t} is the given value in the series.

\hypertarget{data-preparation-and-preprocessing}{%
\subsubsection{Data Preparation and Preprocessing}\label{data-preparation-and-preprocessing}}

The first step in analysis of time series data is to import data of interest and plot the data at an interesting location. In this case, the region of interest is in a deciduous forest near Blacksburg, VA.

We begin by loading in the Landsat 8 Collection and provide a point at the region of interest. Additionally, we will create a time field.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ landsat\_8\_sr }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"LANDSAT/LC08/C01/T1\_SR"}\NormalTok{)}
\KeywordTok{var}\NormalTok{ roi }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{([}\OperatorTok{{-}}\FloatTok{80.49882800809357}\OperatorTok{,} \FloatTok{37.2544486695189}\NormalTok{])}\OperatorTok{;}
\CommentTok{// This field contains UNIX time in milliseconds.}
\KeywordTok{var}\NormalTok{ timeField }\OperatorTok{=} \StringTok{\textquotesingle{}system:time\_start\textquotesingle{}}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

The function \texttt{maskL8sr} is a cloud masking function that uses the Quality Assurance attribute of Landsat 8 to mask out any pixels that that are obscured by cloud. Note that this function is Landsat 8 specific, using other platforms will require a different setup.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Function to cloud mask from the pixel\_qa band of Landsat 8 SR data.}
\KeywordTok{function} \FunctionTok{maskL8sr}\NormalTok{(image) \{}
  \CommentTok{// Bits 3 and 5 are cloud shadow and cloud, respectively.}
  \KeywordTok{var}\NormalTok{ cloudShadowBitMask }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}} \DecValTok{3}\OperatorTok{;}
  \KeywordTok{var}\NormalTok{ cloudsBitMask }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}} \DecValTok{5}\OperatorTok{;}
  \CommentTok{// Get the pixel QA band.}
  \KeywordTok{var}\NormalTok{ qa }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}pixel\_qa\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
  \CommentTok{// Both flags should be set to zero, indicating clear conditions.}
  \KeywordTok{var}\NormalTok{ mask }\OperatorTok{=}\NormalTok{ qa}\OperatorTok{.}\FunctionTok{bitwiseAnd}\NormalTok{(cloudShadowBitMask)}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\DecValTok{0}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{and}\NormalTok{(qa}\OperatorTok{.}\FunctionTok{bitwiseAnd}\NormalTok{(cloudsBitMask)}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\DecValTok{0}\NormalTok{))}\OperatorTok{;}
  \CommentTok{// Return the masked image, scaled to reflectance, without the QA bands.}
  \ControlFlowTok{return}\NormalTok{ image}\OperatorTok{.}\FunctionTok{updateMask}\NormalTok{(mask)}\OperatorTok{.}\FunctionTok{divide}\NormalTok{(}\DecValTok{10000}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B[0{-}9]*\textquotesingle{}}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{copyProperties}\NormalTok{(image}\OperatorTok{,}\NormalTok{ [timeField])}\OperatorTok{;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We can use one of the indices that we built in an earlier lab to measure vegetation health. Normalized Difference Vegetation Index (NDVI) is a well-known metric for quantifying vegetation health - for this region of interest, we expect there to be a strong seasonality, and perhaps a gradual linear trend over time. In the code block below, we create a function called \texttt{addVariables} that extracts the date of each image, calculates NDVI and adds it to an array. We can then use \texttt{.map()} to apply the two functions we built to build a time series model of our data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Use this function to add variables for NDVI, time and a constant}
\CommentTok{// to Landsat 8 imagery.}
\KeywordTok{var}\NormalTok{ addVariables }\OperatorTok{=} \KeywordTok{function}\NormalTok{(image) \{}
  \CommentTok{// Compute time in fractional years since the epoch.}
  \KeywordTok{var}\NormalTok{ date }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Date}\NormalTok{(image}\OperatorTok{.}\FunctionTok{get}\NormalTok{(timeField))}\OperatorTok{;}
  \KeywordTok{var}\NormalTok{ years }\OperatorTok{=}\NormalTok{ date}\OperatorTok{.}\FunctionTok{difference}\NormalTok{(ee}\OperatorTok{.}\FunctionTok{Date}\NormalTok{(}\StringTok{\textquotesingle{}1970{-}01{-}01\textquotesingle{}}\NormalTok{)}\OperatorTok{,} \StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
  \CommentTok{// Return the image with the added bands.}
  \ControlFlowTok{return}\NormalTok{ image}
  \CommentTok{// Add an NDVI band.}
  \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(image}\OperatorTok{.}\FunctionTok{normalizedDifference}\NormalTok{([}\StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\NormalTok{])}\OperatorTok{.}\FunctionTok{rename}\NormalTok{(}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{))}
  \CommentTok{// Add a time band.}
  \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(years)}\OperatorTok{.}\FunctionTok{rename}\NormalTok{(}\StringTok{\textquotesingle{}t\textquotesingle{}}\NormalTok{))}
  \OperatorTok{.}\FunctionTok{float}\NormalTok{()}
  \CommentTok{// Add a constant band.}
  \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Image}\OperatorTok{.}\FunctionTok{constant}\NormalTok{(}\DecValTok{1}\NormalTok{))}\OperatorTok{;}
\NormalTok{\}}\OperatorTok{;}
\CommentTok{// Remove clouds, add variables and filter to the area of interest.}
\KeywordTok{var}\NormalTok{ filteredLandsat }\OperatorTok{=}\NormalTok{ landsat\_8\_sr}
\OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(roi)}
\OperatorTok{.}\FunctionTok{map}\NormalTok{(maskL8sr)}
\OperatorTok{.}\FunctionTok{map}\NormalTok{(addVariables)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

To visualize the data, we will export a chart at the location of interest. We will add a linear trend line for reference.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Plot a time series of NDVI at a single location.}
\KeywordTok{var}\NormalTok{ l8Chart }\OperatorTok{=}\NormalTok{ ui}\OperatorTok{.}\AttributeTok{Chart}\OperatorTok{.}\AttributeTok{image}\OperatorTok{.}\FunctionTok{series}\NormalTok{(filteredLandsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{)}\OperatorTok{,}\NormalTok{ roi)}
  \OperatorTok{.}\FunctionTok{setChartType}\NormalTok{(}\StringTok{\textquotesingle{}ScatterChart\textquotesingle{}}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{setOptions}\NormalTok{(\{}
   \DataTypeTok{title}\OperatorTok{:} \StringTok{\textquotesingle{}Landsat 8 NDVI Time Series at ROI\textquotesingle{}}\OperatorTok{,}
   \DataTypeTok{trendlines}\OperatorTok{:}\NormalTok{ \{}\DecValTok{0}\OperatorTok{:}\NormalTok{ \{}
                \DataTypeTok{color}\OperatorTok{:} \StringTok{\textquotesingle{}CC0000\textquotesingle{}}
\NormalTok{   \}\}}\OperatorTok{,}
   \DataTypeTok{lineWidth}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}
   \DataTypeTok{pointSize}\OperatorTok{:} \DecValTok{3}\OperatorTok{,}
\NormalTok{  \})}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(l8Chart)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

You can click on the `export' button next to the chart to view an iteractive chart. Scroll over some of the data points and look at the relationships between the data. A line connecting two dots means that they are sequential data points, and note that there are relatively few of them. We can see that there are relatively large jumps in the data, with an upward climb somewhere between March and late April, and a descent in late August. Each year is slightly different, but we can surmise that this is due to seasonal rains in the spring and leaves dying off in the fall. Finally, the general trend is downward, although the February 2021 datapoint might have significant leverage on the trend.

\begin{figure}
\centering
\includegraphics{./im/im_06_03.png}
\caption{im\_06\_03}
\end{figure}

\hypertarget{linear-modeling-of-time}{%
\subsubsection{Linear Modeling of Time}\label{linear-modeling-of-time}}

Lots of interesting analyses can be done to time series by harnessing the \texttt{linearRegression()} \href{https://developers.google.com/earth-engine/api_docs\#eereducerlinearregression}{reducer}. To estimate linear trends over time, consider the following linear model, where \(\epsilon_t\) is a random error:

\[ y = \beta_0 + \beta_1X_1 + ... + \beta_nX_n + \epsilon_t \]

This is the model behind the trendline added to the chart you just created. We can use this model to detrend our data (explain the upward or downward movement of the data by subtracting observed values from the fitted model values). For now, the goal is to discover the values of the beta coefficients.

To fit this trend model to the Landsat-based NDVI series using Ordinary Least Squares (\href{https://statisticsbyjim.com/glossary/ordinary-least-squares/}{OLS}), use the \texttt{linearRegression()} reducer:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// List of the independent variable names}
\KeywordTok{var}\NormalTok{ independents }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{List}\NormalTok{([}\StringTok{\textquotesingle{}constant\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}t\textquotesingle{}}\NormalTok{])}\OperatorTok{;}
\CommentTok{// Name of the dependent variable.}
\KeywordTok{var}\NormalTok{ dependent }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{String}\NormalTok{(}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\CommentTok{// Compute a linear trend. This will have two bands: \textquotesingle{}residuals\textquotesingle{} and }
\CommentTok{// a 2x1 band called coefficients (columns are for dependent variables).}
\KeywordTok{var}\NormalTok{ trend }\OperatorTok{=}\NormalTok{ filteredLandsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(independents}\OperatorTok{.}\FunctionTok{add}\NormalTok{(dependent))}
        \OperatorTok{.}\FunctionTok{reduce}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{linearRegression}\NormalTok{(independents}\OperatorTok{.}\FunctionTok{length}\NormalTok{()}\OperatorTok{,} \DecValTok{1}\NormalTok{))}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(trend}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}Trend Array Image\textquotesingle{}}\NormalTok{)}
\CommentTok{// Flatten the coefficients into a 2{-}band image}
\KeywordTok{var}\NormalTok{ coefficients }\OperatorTok{=}\NormalTok{ trend}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}coefficients\textquotesingle{}}\NormalTok{)}
    \OperatorTok{.}\FunctionTok{arrayProject}\NormalTok{([}\DecValTok{0}\NormalTok{])}
    \OperatorTok{.}\FunctionTok{arrayFlatten}\NormalTok{([independents])}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

The image added to the map is a two band image in which each pixel contains values for \(\beta_0\) and \(\beta_1\). Click around the map with inspector, and look at some of the values. We can see that most pixels around our region of interest have a negative trend - although darker values indicate a shallow negative trend, while bright red pixels indicate a steeper descent.

Use the model to ``detrend'' the original NDVI time series. By detrend, we mean account for the slope of the chart and remove it from the original data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Compute a de{-}trended series.}
\KeywordTok{var}\NormalTok{ detrended }\OperatorTok{=}\NormalTok{ filteredLandsat}\OperatorTok{.}\FunctionTok{map}\NormalTok{(}\KeywordTok{function}\NormalTok{(image) \{}
\ControlFlowTok{return}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(dependent)}\OperatorTok{.}\FunctionTok{subtract}\NormalTok{(}
\NormalTok{       image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(independents)}\OperatorTok{.}\FunctionTok{multiply}\NormalTok{(coefficients)}\OperatorTok{.}\FunctionTok{reduce}\NormalTok{(}\StringTok{\textquotesingle{}sum\textquotesingle{}}\NormalTok{))}
       \OperatorTok{.}\FunctionTok{rename}\NormalTok{(dependent)}
       \OperatorTok{.}\FunctionTok{copyProperties}\NormalTok{(image}\OperatorTok{,}\NormalTok{ [timeField])}\OperatorTok{;}
\NormalTok{       \})}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Plot the detrended results

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ detrendedChart }\OperatorTok{=}\NormalTok{ ui}\OperatorTok{.}\AttributeTok{Chart}\OperatorTok{.}\AttributeTok{image}\OperatorTok{.}\FunctionTok{series}\NormalTok{(detrended}\OperatorTok{,}\NormalTok{ roi}\OperatorTok{,} \KeywordTok{null}\OperatorTok{,} \DecValTok{30}\NormalTok{)}
\OperatorTok{.}\FunctionTok{setOptions}\NormalTok{(\{}
  \DataTypeTok{title}\OperatorTok{:} \StringTok{\textquotesingle{}Detrended Landsat Time Series at ROI\textquotesingle{}}\OperatorTok{,}
  \DataTypeTok{lineWidth}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}
  \DataTypeTok{pointSize}\OperatorTok{:} \DecValTok{3}\OperatorTok{,}
\NormalTok{\})}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(detrendedChart)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Compared to our earlier graph, the data looks similar - but now, the slight downward slope is accounted for with our linear model. Each fitted data point (data point on the linear model) is subtracted from each of the observed data points. Additionally, the Y-axis is now centered at 0, and the scale ranges from 0 to +/- 0.45 This allows us to focus on cyclical patterns in the data with long-term trends in the data removed.

\begin{figure}
\centering
\includegraphics{./im/im_06_04.png}
\caption{im\_06\_09}
\end{figure}

\hypertarget{estimate-seasonality-with-a-harmonic-model}{%
\subsection{Estimate Seasonality with a Harmonic Model}\label{estimate-seasonality-with-a-harmonic-model}}

Consider the following linear model, where \(e_t\) is random error, \(A\) is amplitude, \(\omega\) is frequency, and \(\phi\) is phase:

\[
p_t = \beta_0 + \beta_1t + Acos(2\pi\omega t - \phi) + e_t
\]

We can decompose our function into separate cosine and sine elements.

\[
p_t = \beta_0 + \beta_1t + \beta_2cos(2\pi\omega t) + \beta_3sin(2\pi\omega t) + e_t
\]

Note that \(\beta_2 = Acos(\phi)\) and \(\beta_3 = Asin(\phi)\), implying \(A = (\beta_2^2 + \beta_3^2)^½\) and \(\phi = atan(\frac{\beta_3}{\beta_2})\)).

If the math here does not make sense, basically we are breaking up more complex curves into a set of simplified cosine waves and an additive term. Mark Jakubauskas has an informative paper that breaks down the process in this \href{https://www.isprs.org/proceedings/xxxiii/congress/part4/384_xxxiii-part4.pdf}{paper}, and there are many papers which elaborate more on the math behind harmonic models. Building a harmonic model is used in remote sensing applications because of its flexibility in accounting for cyclicality with simple, reproducible shapes. If there is a seasonal trend in the data, the ordered nature of a cosine curve can likely approximate it.

To fit this model to the time series, set \(\omega\)=1 (one cycle per unit time) and use ordinary least squares regression as the metric of error reduction.

First, add the harmonic variables (the third and fourth terms of equation 2) to the image collection.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Use these independent variables in the harmonic regression.}
\KeywordTok{var}\NormalTok{ harmonicIndependents }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{List}\NormalTok{([}\StringTok{\textquotesingle{}constant\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}t\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}cos\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}sin\textquotesingle{}}\NormalTok{])}\OperatorTok{;}
\CommentTok{// Add harmonic terms as new image bands.}
\KeywordTok{var}\NormalTok{ harmonicLandsat }\OperatorTok{=}\NormalTok{ filteredLandsat}\OperatorTok{.}\FunctionTok{map}\NormalTok{(}\KeywordTok{function}\NormalTok{(image) \{}
  \KeywordTok{var}\NormalTok{ timeRadians }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}t\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{multiply}\NormalTok{(}\DecValTok{2} \OperatorTok{*} \BuiltInTok{Math}\OperatorTok{.}\ConstantTok{PI}\NormalTok{)}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ image}
      \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(timeRadians}\OperatorTok{.}\FunctionTok{cos}\NormalTok{()}\OperatorTok{.}\FunctionTok{rename}\NormalTok{(}\StringTok{\textquotesingle{}cos\textquotesingle{}}\NormalTok{))}
      \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(timeRadians}\OperatorTok{.}\FunctionTok{sin}\NormalTok{()}\OperatorTok{.}\FunctionTok{rename}\NormalTok{(}\StringTok{\textquotesingle{}sin\textquotesingle{}}\NormalTok{))}\OperatorTok{;}
\NormalTok{  \})}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Fit the model with a linear trend, using the \texttt{linearRegression()} reducer:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ harmonicTrend }\OperatorTok{=}\NormalTok{ harmonicLandsat}
  \OperatorTok{.}\FunctionTok{select}\NormalTok{(harmonicIndependents}\OperatorTok{.}\FunctionTok{add}\NormalTok{(dependent))}
  \CommentTok{// The output of this reducer is a 4x1 array image.}
  \OperatorTok{.}\FunctionTok{reduce}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{linearRegression}\NormalTok{(\{}
  \DataTypeTok{numX}\OperatorTok{:}\NormalTok{ harmonicIndependents}\OperatorTok{.}\FunctionTok{length}\NormalTok{()}\OperatorTok{,} 
  \DataTypeTok{numY}\OperatorTok{:} \DecValTok{1}
\NormalTok{  \}))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Plug the coefficients in to equation 2 in order to get a time series of fitted values:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Turn the array image into a multi{-}band image of coefficients.}
\KeywordTok{var}\NormalTok{ harmonicTrendCoefficients }\OperatorTok{=}\NormalTok{ harmonicTrend}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}coefficients\textquotesingle{}}\NormalTok{) }
        \OperatorTok{.}\FunctionTok{arrayProject}\NormalTok{([}\DecValTok{0}\NormalTok{])              }
        \OperatorTok{.}\FunctionTok{arrayFlatten}\NormalTok{([harmonicIndependents])}\OperatorTok{;}
\CommentTok{// Compute fitted values.}
\KeywordTok{var}\NormalTok{ fittedHarmonic }\OperatorTok{=}\NormalTok{ harmonicLandsat}\OperatorTok{.}\FunctionTok{map}\NormalTok{(}\KeywordTok{function}\NormalTok{(image) \{ }
  \ControlFlowTok{return}\NormalTok{ image}\OperatorTok{.}\FunctionTok{addBands}\NormalTok{(  }
\NormalTok{  image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(harmonicIndependents)   }
  \OperatorTok{.}\FunctionTok{multiply}\NormalTok{(harmonicTrendCoefficients)   }
  \OperatorTok{.}\FunctionTok{reduce}\NormalTok{(}\StringTok{\textquotesingle{}sum\textquotesingle{}}\NormalTok{)   }
  \OperatorTok{.}\FunctionTok{rename}\NormalTok{(}\StringTok{\textquotesingle{}fitted\textquotesingle{}}\NormalTok{))}\OperatorTok{;}
\NormalTok{\})}\OperatorTok{;}
\CommentTok{// Plot the fitted model and the original data at the ROI.}
\FunctionTok{print}\NormalTok{(ui}\OperatorTok{.}\AttributeTok{Chart}\OperatorTok{.}\AttributeTok{image}\OperatorTok{.}\FunctionTok{series}\NormalTok{(fittedHarmonic}\OperatorTok{.}\FunctionTok{select}\NormalTok{([}\StringTok{\textquotesingle{}fitted\textquotesingle{}}\OperatorTok{,}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{])}\OperatorTok{,}\NormalTok{ roi}\OperatorTok{,}
\NormalTok{                  ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{mean}\NormalTok{()}\OperatorTok{,} \DecValTok{30}\NormalTok{)  }
  \OperatorTok{.}\FunctionTok{setSeriesNames}\NormalTok{([}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}fitted\textquotesingle{}}\NormalTok{])  }
  \OperatorTok{.}\FunctionTok{setOptions}\NormalTok{(\{   }
  \DataTypeTok{title}\OperatorTok{:} \StringTok{\textquotesingle{}Harmonic Model: Original and Fitted Values\textquotesingle{}}\OperatorTok{,}   
  \DataTypeTok{lineWidth}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}   
  \DataTypeTok{pointSize}\OperatorTok{:} \DecValTok{3}\OperatorTok{,}\NormalTok{\}))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

The harmonic overlay (red data points) does an adequate job of modeling the data - There is a datapoint in Feb 2021 that is significantly less, but this appears to be an outlier. Additionally, the model misses a significant dip in July 2015, although this might be due to the climate conditions that were irregular - other years did not have the same dip.

\begin{figure}
\centering
\includegraphics{./im/im_06_05.png}
\caption{im\_06\_10}
\end{figure}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Upload the resulting graphic and interpret it. }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Although any coefficients can be mapped directly, it is often useful and interesting to map the phase and amplitude of the estimated harmonic model. First, compute phase and amplitude from the coefficients, then incorporate this information into each pixel. Use inspector to look at the pixels and note their phase and amplitude.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Compute phase and amplitude.}
\KeywordTok{var}\NormalTok{ phase }\OperatorTok{=}\NormalTok{ harmonicTrendCoefficients}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}sin\textquotesingle{}}\NormalTok{)}
        \OperatorTok{.}\FunctionTok{atan2}\NormalTok{(harmonicTrendCoefficients}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}cos\textquotesingle{}}\NormalTok{))  }
        \CommentTok{// Scale to [0, 1] from radians.  }
  \OperatorTok{.}\FunctionTok{unitScale}\NormalTok{(}\OperatorTok{{-}}\BuiltInTok{Math}\OperatorTok{.}\ConstantTok{PI}\OperatorTok{,} \BuiltInTok{Math}\OperatorTok{.}\ConstantTok{PI}\NormalTok{)}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ amplitude }\OperatorTok{=}\NormalTok{ harmonicTrendCoefficients}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}sin\textquotesingle{}}\NormalTok{)}
        \OperatorTok{.}\FunctionTok{hypot}\NormalTok{(harmonicTrendCoefficients}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}cos\textquotesingle{}}\NormalTok{))  }
        \CommentTok{// Add a scale factor for visualization.  }
  \OperatorTok{.}\FunctionTok{multiply}\NormalTok{(}\DecValTok{5}\NormalTok{)}\OperatorTok{;}
\CommentTok{// Compute the mean NDVI.}
\KeywordTok{var}\NormalTok{ meanNdvi }\OperatorTok{=}\NormalTok{ filteredLandsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{mean}\NormalTok{()}\OperatorTok{;}
\CommentTok{// Use the HSV to RGB transformation to display phase and amplitude.}
\KeywordTok{var}\NormalTok{ rgb }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Image}\OperatorTok{.}\FunctionTok{cat}\NormalTok{([}
\NormalTok{                        phase}\OperatorTok{,}
\NormalTok{                        amplitude}\OperatorTok{,} 
\NormalTok{                        meanNdvi}
\NormalTok{        ])}\OperatorTok{.}\FunctionTok{hsvToRgb}\NormalTok{()}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(rgb}\OperatorTok{,}\NormalTok{ \{\}}\OperatorTok{,} \StringTok{\textquotesingle{}phase (hue), amplitude (sat), ndvi (val)\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Upload the resulting map layer and describe its salient features.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{complex-time-series-modeling}{%
\subsubsection{Complex Time Series Modeling}\label{complex-time-series-modeling}}

A time series can be decomposed as the sum of sinusoids at different frequencies. The harmonic model presented here can be extended by adding bands that represent higher frequencies and the corresponding \texttt{sin()} band for a harmonic component to account for two cycles per year.

You can look at this GEE \href{https://code.earthengine.google.com/2669122497313113fc4bb81bc8352828}{example} of using multiple sinusoids to build a more complex harmonic model. Note that each year there is a high peak in June and a secondary peak in January - this harmonic model consisting of two sinusoids with separate frequencies and amplitudes is able to account for that. However, the error values in this model are high and the fit is quite inexact. We can see extreme drops in the NDVI value that the model misses, and several peaks each year that do not fit.

\begin{figure}
\centering
\includegraphics{./im/im_06_06.png}
\caption{im\_06\_11}
\end{figure}

More complex harmonic models might not be appropriate due to overfitting - in other words, this model might provide a false sense of comfort in it's explanatory ability. Time Series modelling of remote sensing data is more difficult than many business or scientific contexts due to masked data, missing data, irregular atmospheric conditions and natural variability.

\hypertarget{exporting-data}{%
\subsubsection{Exporting Data}\label{exporting-data}}

Many of you might be more familiar with building statistical models in other languages or tools, such as Python, R or JMP. After all, JavaScript was not built as a natural statistics tool, and being able to work with the data In that case, you'll likely want to export the data for your own analysis. There are several ways to do it, but the simplest method is to click the `expand into new tab' button next to the chart that contains the data you want to work with (likely the raw NDVI data) - in the new tab, you can click `Download .csv', which is a datatable that you can use with whichever software you prefer.

\begin{figure}
\centering
\includegraphics{./im/im_06_07.png}
\caption{im\_06\_07}
\end{figure}

\hypertarget{time-series-thresholding}{%
\subsection{Time Series Thresholding}\label{time-series-thresholding}}

Urban change detection is a burgeoning field in remote sensing that identifies historical urban development and works to predict where future urban development will occur. Remote sensing is a vital partner in this field, as it can provide an unbiased, quantitative assessment of change over time. For instance, \href{https://www.spiegel.de/international/europe/finding-swimming-pools-with-google-earth-greek-government-hauls-in-billions-in-back-taxes-a-709703.html}{Greece} is using Google Earth Pro to scour the countryside for signs of tax evaders (ex., a luxury pool built without a permit may indicate sheltered money). Other countries are using classification models in Google Earth Engine to characterize urban development.

In this example, we will go over a simple, but very effective method of identifying urban development, based on real-world experience. In nearby Roanoke (located about 45 minutes east of Virginia Tech), like any other city, there has been significant construction in the past few years. About three years ago, a patch of land was converted from trees and pasture and construction began an assisted living facility. Let's test to see if we can identify this construction. We will use the Landsat 8 image collection (as we used earlier), and import our test point as \texttt{var\ roi}. The process of building the chart is the same as earlier, and we will use NDVI as our change metric, as we can hypothesize that new construction will greatly reduce NDVI.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Test area {-} lat/long acquired from Google Maps}
\KeywordTok{var}\NormalTok{ roi }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{([}\OperatorTok{{-}}\FloatTok{79.98413}\OperatorTok{,} \FloatTok{37.2368}\NormalTok{])}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ landsat\_8\_sr }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"LANDSAT/LC08/C01/T1\_SR"}\NormalTok{)}

\CommentTok{// This field contains UNIX time in milliseconds.}
\KeywordTok{var}\NormalTok{ timeField }\OperatorTok{=} \StringTok{\textquotesingle{}system:time\_start\textquotesingle{}}\OperatorTok{;}

\CommentTok{// Function to cloud mask from the pixel\_qa band of Landsat 8 SR data.}
\KeywordTok{function} \FunctionTok{maskL8sr}\NormalTok{(image) \{}
  \CommentTok{// Bits 3 and 5 are cloud shadow and cloud, respectively.}
  \KeywordTok{var}\NormalTok{ cloudShadowBitMask }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}} \DecValTok{3}\OperatorTok{;}
  \KeywordTok{var}\NormalTok{ cloudsBitMask }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}} \DecValTok{5}\OperatorTok{;}
  \CommentTok{// Get the pixel QA band.}
  \KeywordTok{var}\NormalTok{ qa }\OperatorTok{=}\NormalTok{ image}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}pixel\_qa\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
  \CommentTok{// Both flags should be set to zero, indicating clear conditions.}
  \KeywordTok{var}\NormalTok{ mask }\OperatorTok{=}\NormalTok{ qa}\OperatorTok{.}\FunctionTok{bitwiseAnd}\NormalTok{(cloudShadowBitMask)}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\DecValTok{0}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{and}\NormalTok{(qa}\OperatorTok{.}\FunctionTok{bitwiseAnd}\NormalTok{(cloudsBitMask)}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\DecValTok{0}\NormalTok{))}\OperatorTok{;}
  \CommentTok{// Return the masked image, scaled to reflectance, without the QA bands.}
  \ControlFlowTok{return}\NormalTok{ image}\OperatorTok{.}\FunctionTok{updateMask}\NormalTok{(mask)}\OperatorTok{.}\FunctionTok{divide}\NormalTok{(}\DecValTok{10000}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}B[0{-}9]*\textquotesingle{}}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{copyProperties}\NormalTok{(image}\OperatorTok{,}\NormalTok{ [timeField])}\OperatorTok{;}
\NormalTok{\}}
\CommentTok{// Use this function to add variables for NDVI, time and a constant}
\CommentTok{// to Landsat 8 imagery.}
\KeywordTok{var}\NormalTok{ addVariables }\OperatorTok{=} \KeywordTok{function}\NormalTok{(image) \{}
  \CommentTok{// Compute time in fractional years since the epoch.}
  \KeywordTok{var}\NormalTok{ date }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Date}\NormalTok{(image}\OperatorTok{.}\FunctionTok{get}\NormalTok{(timeField))}\OperatorTok{;}
  \KeywordTok{var}\NormalTok{ years }\OperatorTok{=}\NormalTok{ date}\OperatorTok{.}\FunctionTok{difference}\NormalTok{(ee}\OperatorTok{.}\FunctionTok{Date}\NormalTok{(}\StringTok{\textquotesingle{}1970{-}01{-}01\textquotesingle{}}\NormalTok{)}\OperatorTok{,} \StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
  \CommentTok{// Return the image with the added bands.}
  \ControlFlowTok{return}\NormalTok{ image}
  \CommentTok{// Add an NDVI band.}
  \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(image}\OperatorTok{.}\FunctionTok{normalizedDifference}\NormalTok{([}\StringTok{\textquotesingle{}B5\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}B4\textquotesingle{}}\NormalTok{])}\OperatorTok{.}\FunctionTok{rename}\NormalTok{(}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{))}
  \CommentTok{// Add a time band.}
  \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(years)}\OperatorTok{.}\FunctionTok{rename}\NormalTok{(}\StringTok{\textquotesingle{}t\textquotesingle{}}\NormalTok{))}
  \OperatorTok{.}\FunctionTok{float}\NormalTok{()}
  \CommentTok{// Add a constant band.}
  \OperatorTok{.}\FunctionTok{addBands}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Image}\OperatorTok{.}\FunctionTok{constant}\NormalTok{(}\DecValTok{1}\NormalTok{))}\OperatorTok{;}
\NormalTok{\}}\OperatorTok{;}
\CommentTok{// Remove clouds, add variables and filter to the area of interest.}
\KeywordTok{var}\NormalTok{ filteredLandsat }\OperatorTok{=}\NormalTok{ landsat\_8\_sr}
\OperatorTok{.}\FunctionTok{filterBounds}\NormalTok{(roi)}
\OperatorTok{.}\FunctionTok{map}\NormalTok{(maskL8sr)}
\OperatorTok{.}\FunctionTok{map}\NormalTok{(addVariables)}\OperatorTok{;}
\CommentTok{// Plot a time series of NDVI at a single location.}
\KeywordTok{var}\NormalTok{ l8Chart }\OperatorTok{=}\NormalTok{ ui}\OperatorTok{.}\AttributeTok{Chart}\OperatorTok{.}\AttributeTok{image}\OperatorTok{.}\FunctionTok{series}\NormalTok{(filteredLandsat}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}NDVI\textquotesingle{}}\NormalTok{)}\OperatorTok{,}\NormalTok{ roi)}
  \OperatorTok{.}\FunctionTok{setChartType}\NormalTok{(}\StringTok{\textquotesingle{}ScatterChart\textquotesingle{}}\NormalTok{)}
  \OperatorTok{.}\FunctionTok{setOptions}\NormalTok{(\{}
   \DataTypeTok{title}\OperatorTok{:} \StringTok{\textquotesingle{}Landsat 8 NDVI Time Series at ROI\textquotesingle{}}\OperatorTok{,}
   \DataTypeTok{trendlines}\OperatorTok{:}\NormalTok{ \{}\DecValTok{0}\OperatorTok{:}\NormalTok{ \{}
                \DataTypeTok{color}\OperatorTok{:} \StringTok{\textquotesingle{}CC0000\textquotesingle{}}
\NormalTok{   \}\}}\OperatorTok{,}
   \DataTypeTok{lineWidth}\OperatorTok{:} \DecValTok{1}\OperatorTok{,}
   \DataTypeTok{pointSize}\OperatorTok{:} \DecValTok{3}\OperatorTok{,}
\NormalTok{  \})}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(l8Chart)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Below is the resulting chart, exactly as expected. NDVI has a max of 0.9 in the summer and a min of 0.4 in the winter, but between March 2018 to April 2018 the NDVI drops from 0.313 to 0.18, and largely stays below this value. In addition, the cyclicality is gone after 2018, and while there are some elevated values in late 2020, that is likely due to atmospheric conditions or sensor calibration. The linear trend is an indication of construction, and perhaps a window function to average out the variability can help identify large drops in the overall average NDVI for this test point.

\begin{figure}
\centering
\includegraphics{./im/im_06_08.png}
\caption{im\_06\_08}
\end{figure}

There are some interesting ways you can expand this general idea - for instance, you might be able to build a system that automatically identifies urban development that occurs when it occurs in your test zone. Global Forest watch is using a similar tactic to automatically detect when there is a large drop in NDVI, and by using MODIS data, they can obtain very high temporal resolution to identify exactly when and where this activity is occuring. Note that different image collections have different time-lines (for instance, Landsat 8 would not be able to detect urban change before 2013), and you may have to set up this system differently.

\hypertarget{additional-exercises-3}{%
\subsection{Additional Exercises}\label{additional-exercises-3}}

\textbf{Test three different points using Landsat 7, Landsat 8 and MODIS to identify urban development in an area of interest. Do the charts and data provide enough data to determine that urban change occurred?}

\textbf{Look in google scholar to identify 2-3 publications that have used a harmonic regression in a time series analysis of remotely sensed data in particular. Provide citations for the articles, and then describe for what purposes was the technique used and what was the justification provided for its use.}

\hypertarget{where-to-submit-4}{%
\subsection*{Where to submit}\label{where-to-submit-4}}
\addcontentsline{toc}{subsection}{Where to submit}

Submit your responses to these questions on \href{https://www.gradescope.com/courses/293173/assignments/1446622/submissions}{Gradescope} by 10am on Wednesday, October 06. If needed, the access code for our course is \texttt{6PEW3W}.

\hypertarget{lab6}{%
\section{Night Time Lights Appendix}\label{lab6}}

\hypertarget{overview-6}{%
\subsection*{Overview}\label{overview-6}}
\addcontentsline{toc}{subsection}{Overview}

Capturing and visualizing low-light emittance from around the earth has been utilized in various applications since the mid-1960's. By consistently quantifying light emittance over long time periods, it is possible to use this as a proxy for economic development, especially in areas where there is not high-quality data and metrics to work with. Google Earth Engine has consolidated this data into an operational archive dating back to 1992, which is an excellent way to find meaningful insights using this data set.

This tutorial is a supplement to the excellent \emph{Open Nighttime Lights} \href{https://worldbank.github.io/OpenNightLights/welcome.html}{tutorial} that the World Bank developed. The World Bank tutorial consists of six modules, including a background on the history of the data, working with the tools, extracting imagery, data analysis and image classification. It also contains an archive in which you can archive the raw data directly from Amazon Web Services and an applications section that attempts to estimate electricity usage using the nighttime data set. Each segment is well-written, and there is extensive documentation throughout.

The caveat here is that up until this point in the course, we have worked with the Google Earth Engine JavaScript code editor - Because the World Bank tutorial covers topics such as working with data frames, statistics and classification, it utilizes the Google Earth Engine Python API in a Jupyter Notebook. Python is a more natural fit and contains more capabilities for data analysis and Machine Learning than JavaScript, and while the GEE code editor is excellent at working with objects and methods, many of you might prefer working with Python. Based on your background and what you want to get out of this course, here is our general suggestion on how to proceed.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If you are comfortable working with Python, Jupyter Notebooks and setting up your own environment (pip, Conda, Brew), than follow along with the tutorial as it is. Module 2-2 in the World Bank tutorial explains how to get an environment up and running.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    If this is the case, spend some time reading about the functionality in the \href{https://geemap.org}{geemap} package - it consolidates much of the mapping features in Earth Engine in an intuitive way, as well as functionality to integrate your results with Folium and custom basemaps.
  \end{enumerate}
\item
  If you want to learn to use Python but have never worked with virtual environments, then consider going through the tutorial in a Google Colab - it requires no setup of infrastructure, and you can get running immediately while learning Python. Once you are comfortable with this, you can always learn how to set up your own environment. Explanations on getting started can be located \href{https://worldbank.github.io/OpenNightLights/tutorials/mod2_3_introduction_to_Jupyter_notebooks.html}{here}. Note that there are several components of the tutorial, primarily in visualization using leaflet, that will not work.
\item
  If you want to stick with working with JavaScript, then the section below will provide you with some capabilities of doing the core functions in the code editor, mainly the segment in Module 3. After that, we suggest exporting the data for further analysis.
\end{enumerate}

Again, this lab is more of a supplement for students that wish to keep using JavaScript and the GEE code editor. It is not designed to fully replace the World Bank tutorial, and while will get you started, there will be things that you will have to figure out on your own.

\hypertarget{basic-operations}{%
\subsection{Basic Operations}\label{basic-operations}}

Module 1 is an essential introduction to the NightTime Lights dataset, while Module 2 introduces you to the data and the setting up your environment. In this section, we will covering the essential components of obtaining the data that you need in the correct context, some basic processing, building a composite and exporting the data in JavaScript, with enough code to show you how to get started and how to follow along with the tutorial.

We will follow along with module exactly as it is set up, so that you can refer to the Module and section numbers.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Obtaining the Data}

  The code chunk below should be a good starting point on ingesting the data, looking at the range of data, and visualizing the average value across the image collection. Follow along with the same concepts in the tutorial, test using a specific image (instead of an image collection) and visualize your results. You can modify the opacity manually using the slider on the \texttt{layers} tab, and then build it into your \href{https://developers.google.com/earth-engine/guides/image_visualization?hl=en\#code-editor-javascript}{visualization}.

  Note: JavaScript uses Lon / Lat, while Python uses lat / long while building points or setting map areas.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Read in Nighttime Lights}
\KeywordTok{var}\NormalTok{ dmsp }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"NOAA/DMSP{-}OLS/NIGHTTIME\_LIGHTS"}\NormalTok{)}\OperatorTok{;}
\CommentTok{// Print size of the image collection}
\FunctionTok{print}\NormalTok{(dmsp}\OperatorTok{.}\FunctionTok{size}\NormalTok{())}\OperatorTok{;}
\CommentTok{// Print out the dates of image collection}
\KeywordTok{var}\NormalTok{ imgrange }\OperatorTok{=}\NormalTok{ dmsp}\OperatorTok{.}\FunctionTok{reduceColumns}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{minMax}\NormalTok{()}\OperatorTok{,}\NormalTok{ [}\StringTok{"system:time\_start"}\NormalTok{])}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ start }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Date}\NormalTok{(imgrange}\OperatorTok{.}\FunctionTok{get}\NormalTok{(}\StringTok{\textquotesingle{}min\textquotesingle{}}\NormalTok{))}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ end }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Date}\NormalTok{(imgrange}\OperatorTok{.}\FunctionTok{get}\NormalTok{(}\StringTok{\textquotesingle{}max\textquotesingle{}}\NormalTok{))}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Date range: \textquotesingle{}}\OperatorTok{,}\NormalTok{ start}\OperatorTok{,}\NormalTok{ end)}\OperatorTok{;}
\CommentTok{// Take average visibility }
\KeywordTok{var}\NormalTok{ nighttimeLights }\OperatorTok{=}\NormalTok{ dmsp}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}avg\_vis\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \FloatTok{3.0}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \FloatTok{60.0}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lat }\OperatorTok{=} \FloatTok{38.9072}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lon }\OperatorTok{=} \OperatorTok{{-}}\FloatTok{77.0369}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ zoomlevel}\OperatorTok{=}\DecValTok{7}\OperatorTok{;}
\CommentTok{// }
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(center\_lon}\OperatorTok{,}\NormalTok{ center\_lat}\OperatorTok{,}\NormalTok{ zoomlevel)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(nighttimeLights}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}Nighttime Lights\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{Image Clipping}

  This section follows along with some of our earlier work in clipping our image to a certain area. Whether you need to bring in your own shapefiles. The code below clips a single around a 200km buffer around Los Angeles.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get December image {-} "avg\_rad" band}
\KeywordTok{var}\NormalTok{ viirs2019\_12 }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"NOAA/VIIRS/DNB/MONTHLY\_V1/VCMSLCFG"}\NormalTok{)}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}
  \StringTok{"2019{-}12{-}01"}\OperatorTok{,}\StringTok{"2019{-}12{-}31"}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{median}\NormalTok{()}
\CommentTok{// Set visibility parameters}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \FloatTok{3.0}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \FloatTok{60.0}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lat }\OperatorTok{=} \FloatTok{34.05}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lon }\OperatorTok{=} \OperatorTok{{-}}\FloatTok{118.25}\OperatorTok{;}
\CommentTok{// Build a 200km buffer around a point}
\CommentTok{// Clip image to boundary of buffer}
\KeywordTok{var}\NormalTok{ aoi }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{([center\_lon}\OperatorTok{,}\NormalTok{ center\_lat])}\OperatorTok{.}\FunctionTok{buffer}\NormalTok{(}\DecValTok{200000}\NormalTok{)}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ viirs2019\_12\_clipped }\OperatorTok{=}\NormalTok{ viirs2019\_12}\OperatorTok{.}\FunctionTok{clip}\NormalTok{(aoi)}
\KeywordTok{var}\NormalTok{ zoomlevel}\OperatorTok{=}\DecValTok{7}\OperatorTok{;}
\CommentTok{// map set center }
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(center\_lon}\OperatorTok{,}\NormalTok{ center\_lat}\OperatorTok{,}\NormalTok{ zoomlevel)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(viirs2019\_12\_clipped}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}Clipped to Buffer\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_01.png}
\caption{im\_07\_01}
\end{figure}

You can do the same thing with either your own polygon vector files (import shapefile, kml), or use one of the vector files that GEE maintains - we can test use the TIGER state boundary file and clip the image to California.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Get December image {-} "avg\_rad" band}
\KeywordTok{var}\NormalTok{ viirs2019\_12 }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"NOAA/VIIRS/DNB/MONTHLY\_V1/VCMSLCFG"}\NormalTok{)}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}
  \StringTok{"2019{-}12{-}01"}\OperatorTok{,}\StringTok{"2019{-}12{-}31"}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{median}\NormalTok{()}
\CommentTok{// Set visibility parameters}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \FloatTok{3.0}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \FloatTok{60.0}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lat }\OperatorTok{=} \DecValTok{37}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lon }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{120}\OperatorTok{;}
\CommentTok{// Boundary of states}
\CommentTok{// Filter to California }
\KeywordTok{var}\NormalTok{ aoi\_CA }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{FeatureCollection}\NormalTok{(}\StringTok{\textquotesingle{}TIGER/2016/States\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(}
\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\StringTok{\textquotesingle{}NAME\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}California\textquotesingle{}}\NormalTok{))}
\KeywordTok{var}\NormalTok{ viirs2019\_12\_clipped }\OperatorTok{=}\NormalTok{ viirs2019\_12}\OperatorTok{.}\FunctionTok{clip}\NormalTok{(aoi\_CA)}
\KeywordTok{var}\NormalTok{ zoomlevel}\OperatorTok{=}\DecValTok{6}\OperatorTok{;}
\CommentTok{// map set center }
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(center\_lon}\OperatorTok{,}\NormalTok{ center\_lat}\OperatorTok{,}\NormalTok{ zoomlevel)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(viirs2019\_12\_clipped}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}California NightTime Lights\textquotesingle{}}\NormalTok{)}\OperatorTok{;} 
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_02.png}
\caption{im\_07\_02}
\end{figure}

The previous two examples showed the process of clipping individual images - to clip an entire image collection and extract a composite image, we can follow the same general approach, but use the \texttt{map} function to clip each image of the collection to our boundary. However, note that depending on the use case and the size of the image collection, this might take time to run and still leave you with a large amount of data. Before exporting all the data, perhaps reduce the image collection by extracting mean / median values, or use the reduce function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ viirsDNB }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"NOAA/VIIRS/DNB/MONTHLY\_V1/VCMSLCFG"}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{)}
\CommentTok{// Define our clipping function}
\CommentTok{// Built specifically for the purposes of clipping to California}
\KeywordTok{function} \FunctionTok{clip\_func}\NormalTok{(im\_col) \{}
    \ControlFlowTok{return}\NormalTok{ im\_col}\OperatorTok{.}\FunctionTok{clip}\NormalTok{(aoi\_CA)}\OperatorTok{;}
\NormalTok{\}}
\CommentTok{// Set visibility parameters}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \FloatTok{3.0}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \FloatTok{60.0}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lat }\OperatorTok{=} \DecValTok{37}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ center\_lon }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{120}\OperatorTok{;}
\KeywordTok{var}\NormalTok{ zoomlevel}\OperatorTok{=}\DecValTok{6}\OperatorTok{;}
\CommentTok{// Boundary of States}
\CommentTok{// Filter to California }
\KeywordTok{var}\NormalTok{ aoi\_CA }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{FeatureCollection}\NormalTok{(}\StringTok{\textquotesingle{}TIGER/2016/States\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(}
\NormalTok{  ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}\StringTok{\textquotesingle{}NAME\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}California\textquotesingle{}}\NormalTok{))}
\CommentTok{// use \textasciigrave{}map\textasciigrave{} {-} which applied our function to each image in the image collection}
\KeywordTok{var}\NormalTok{ viirs\_dmb\_clipped }\OperatorTok{=}\NormalTok{ viirsDNB}\OperatorTok{.}\FunctionTok{map}\NormalTok{(clip\_func)}
\CommentTok{// map set center }
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(center\_lon}\OperatorTok{,}\NormalTok{ center\_lat}\OperatorTok{,}\NormalTok{ zoomlevel)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(viirs\_dmb\_clipped}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}California NightTime Lights\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Conditional Operations}
\end{enumerate}

In this section, we will go over how to mask individual pixels based on conditional statements. This is one section that we will cover in JavaScript, but is probably easier to conduct in Python using `Pythonic' methods and libraries such as NumPy. The charting is easer to work with in Python, but in the code chunk below, you can go through how to build a histogram smoothed with a Gaussian filter to identify where a value to might be appropriate. Then, build a binary mask using GEE's built in conditionals:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// get December image, we\textquotesingle{}re using the "avg\_rad" band}
\KeywordTok{var}\NormalTok{ viirs2019\_12 }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"NOAA/VIIRS/DNB/MONTHLY\_V1/VCMSLCFG"}\NormalTok{)}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}
  \StringTok{"2019{-}12{-}01"}\OperatorTok{,}\StringTok{"2019{-}12{-}31"}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{median}\NormalTok{()}
\CommentTok{// center on Catalonia}
\KeywordTok{var}\NormalTok{ lat }\OperatorTok{=} \FloatTok{41.83}
\KeywordTok{var}\NormalTok{ lon }\OperatorTok{=} \FloatTok{1.67}
\CommentTok{// create a 200 km buffer around the center of Catalonia}
\KeywordTok{var}\NormalTok{ aoi }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Geometry}\OperatorTok{.}\FunctionTok{Point}\NormalTok{(lon}\OperatorTok{,}\NormalTok{ lat)}\OperatorTok{.}\FunctionTok{buffer}\NormalTok{(}\DecValTok{200000}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\textbf{Build the Histogram}

This histogram is quite tough to read, but there are values that range from 0 to over 1000 - note that the vast majority fall within the range of 0 and 4. This is used to get a basic understanding of our data.

--------\textgreater{} Need to improve

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// }
\KeywordTok{var}\NormalTok{ hist }\OperatorTok{=}\NormalTok{ viirs2019\_12}\OperatorTok{.}\FunctionTok{reduceRegion}\NormalTok{(\{}
  \DataTypeTok{reducer}\OperatorTok{:}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{autoHistogram}\NormalTok{()}\OperatorTok{,}
  \DataTypeTok{geometry}\OperatorTok{:}\NormalTok{ aoi}\OperatorTok{,}
  \DataTypeTok{scale}\OperatorTok{:} \DecValTok{100}\OperatorTok{,}
  \DataTypeTok{bestEffort}\OperatorTok{:} \KeywordTok{true}
\NormalTok{\})}\OperatorTok{;}
\CommentTok{// The result of the region reduction by \textasciigrave{}autoHistogram\textasciigrave{} is an array. Get the}
\CommentTok{// array and cast it as such for good measure.}
\KeywordTok{var}\NormalTok{ histArray }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Array}\NormalTok{(hist}\OperatorTok{.}\FunctionTok{get}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{)) }\OperatorTok{;}
\FunctionTok{print}\NormalTok{(histArray)}
\CommentTok{// Subset the values that represent the bottom of the bins and project to}
\CommentTok{// a single dimension. Result is a 1{-}D array.}
\KeywordTok{var}\NormalTok{ binBottom }\OperatorTok{=}\NormalTok{ histArray}\OperatorTok{.}\FunctionTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{0}\OperatorTok{,} \DecValTok{1}\NormalTok{)}\OperatorTok{.}\FunctionTok{project}\NormalTok{([}\DecValTok{0}\NormalTok{])}\OperatorTok{;}
\CommentTok{// Subset the values that represent the number of pixels per bin and project to}
\CommentTok{// a single dimension. Result is a 1{-}D array.}
\KeywordTok{var}\NormalTok{ nPixels }\OperatorTok{=}\NormalTok{ histArray}\OperatorTok{.}\FunctionTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{1}\OperatorTok{,} \KeywordTok{null}\NormalTok{)}\OperatorTok{.}\FunctionTok{project}\NormalTok{([}\DecValTok{0}\NormalTok{])}\OperatorTok{;}
\CommentTok{// Chart the two arrays using the \textasciigrave{}ui.Chart.array.values\textasciigrave{} function.}
\KeywordTok{var}\NormalTok{ histColumnFromArray }\OperatorTok{=}\NormalTok{ ui}\OperatorTok{.}\AttributeTok{Chart}\OperatorTok{.}\AttributeTok{array}\OperatorTok{.}\FunctionTok{values}\NormalTok{(\{}
  \DataTypeTok{array}\OperatorTok{:}\NormalTok{nPixels}\OperatorTok{,}
  \DataTypeTok{axis}\OperatorTok{:} \DecValTok{0}\OperatorTok{,}
  \DataTypeTok{xLabels}\OperatorTok{:}\NormalTok{ binBottom\})}
  \OperatorTok{.}\FunctionTok{setChartType}\NormalTok{(}\StringTok{\textquotesingle{}ColumnChart\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\FunctionTok{print}\NormalTok{(histColumnFromArray)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\textbf{Mask values}

The histogram shows us that a massive number of values fall near zero - if we build a mask using GEE's built in conditionals to keep only pixels that have a value above 4, the output allows us to focus in on areas that have meaningful values. Additionally, this will improve compute time and analysis.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Output is a binary mask (0{-}1)}
\KeywordTok{var}\NormalTok{ mask\_value }\OperatorTok{=} \DecValTok{4}
\KeywordTok{var}\NormalTok{ viirs2019\_12\_mask }\OperatorTok{=}\NormalTok{ viirs2019\_12}\OperatorTok{.}\FunctionTok{gte}\NormalTok{(mask\_value)}
\CommentTok{// Initialize our map}
\KeywordTok{var}\NormalTok{ nighttimeVis }\OperatorTok{=}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \FloatTok{0.0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{120.0}\NormalTok{\}}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(lon}\OperatorTok{,}\NormalTok{ lat}\OperatorTok{,} \DecValTok{8}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(viirs2019\_12}\OperatorTok{.}\FunctionTok{mask}\NormalTok{(viirs2019\_12\_mask)}\OperatorTok{,}\NormalTok{ nighttimeVis}\OperatorTok{,}  \StringTok{\textquotesingle{}Nighttime\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_03.png}
\caption{im\_07\_03}
\end{figure}

Note that just like in the lab, you can chain together conditionals to make a layered mask, and build a customized pallette.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ zones }\OperatorTok{=}\NormalTok{ viirs2019\_12}\OperatorTok{.}\FunctionTok{gt}\NormalTok{(}\FloatTok{1.5}\NormalTok{)}\OperatorTok{.}\FunctionTok{add}\NormalTok{(viirs2019\_12}\OperatorTok{.}\FunctionTok{gt}\NormalTok{(}\DecValTok{2}\NormalTok{))}\OperatorTok{.}\FunctionTok{add}\NormalTok{(viirs2019\_12}\OperatorTok{.}\FunctionTok{gt}\NormalTok{(}\DecValTok{5}\NormalTok{))}
\CommentTok{// Initialize our map}
\KeywordTok{var}\NormalTok{ nighttimeVis }\OperatorTok{=}\NormalTok{ \{}\DataTypeTok{min}\OperatorTok{:} \FloatTok{0.0}\OperatorTok{,} \DataTypeTok{max}\OperatorTok{:} \FloatTok{120.0}\NormalTok{\}}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(lon}\OperatorTok{,}\NormalTok{ lat}\OperatorTok{,} \DecValTok{8}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(zones}\OperatorTok{.}\FunctionTok{mask}\NormalTok{(zones)}\OperatorTok{,}\NormalTok{ \{}\StringTok{\textquotesingle{}palette\textquotesingle{}}\OperatorTok{:}\NormalTok{[}\StringTok{\textquotesingle{}\#cc0909\textquotesingle{}}\OperatorTok{,}\StringTok{\textquotesingle{}\#e67525\textquotesingle{}}\OperatorTok{,}\StringTok{\textquotesingle{}\#fff825\textquotesingle{}}\NormalTok{]\}}\OperatorTok{,} \StringTok{\textquotesingle{}zones\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_04.png}
\caption{im\_07\_04}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Cell Statistics and Band Math}
\end{enumerate}

It is worthwhile to read through this section thoroughly on the World Bank tutorial, as the techniques you learn here will be very useful in later sections. We will go over scaling an image to center each pixel at zero. We are working in the region of East Timor - the general process is to read in the December 2017 Nighttime Lights average, clip it to the East Timor Feature Collection, and then calculate the mean and standard deviation using the \texttt{reduceRegion} function. Now that we have those values, we can standardize the scaling. Compare the before and after images - in the first, it is very difficult to get any meaningful values, because the range of values is so narrow. Once scaled, we can more easily differentiate between urban areas and rural areas. You will also note that by doing this, the noise increases as well, as you can tell from the reduced `sharpness' of the image. This can be an issue in many cases, and will be addressed in other components of the module.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// get December image, we\textquotesingle{}re using the "avg\_rad" band}
\KeywordTok{var}\NormalTok{ viirs2017\_12 }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}
  \StringTok{"NOAA/VIIRS/DNB/MONTHLY\_V1/VCMSLCFG"}\NormalTok{)}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}
  \StringTok{"2017{-}12{-}01"}\OperatorTok{,}\StringTok{"2017{-}12{-}31"}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{)}\OperatorTok{.}\FunctionTok{first}\NormalTok{()}
\CommentTok{// get the geometry for Timor{-}Leste from GEE\textquotesingle{}s tagged datasets}
\KeywordTok{var}\NormalTok{ tls }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Feature}\NormalTok{(ee}\OperatorTok{.}\FunctionTok{FeatureCollection}\NormalTok{(}
  \StringTok{"FAO/GAUL/2015/level0"}\NormalTok{)}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{eq}\NormalTok{(}
  \StringTok{\textquotesingle{}ADM0\_NAME\textquotesingle{}}\OperatorTok{,} \StringTok{\textquotesingle{}Timor{-}Leste\textquotesingle{}}\NormalTok{))}\OperatorTok{.}\FunctionTok{first}\NormalTok{())}\OperatorTok{.}\FunctionTok{geometry}\NormalTok{()}
\CommentTok{// clip our VIIRS image to Timor{-}Leste}
\KeywordTok{var}\NormalTok{ ntl\_tls }\OperatorTok{=}\NormalTok{ viirs2017\_12}\OperatorTok{.}\FunctionTok{clip}\NormalTok{(tls)}
\CommentTok{// Set visibility parameters}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \FloatTok{3.0}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \FloatTok{60.0}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(}\FloatTok{126.25}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{8.5}\OperatorTok{,} \DecValTok{9}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(ntl\_tls}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}"VIIRS{-}DNB Dec 2017"\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_05.png}
\caption{im\_07\_05}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Reduce image to find the mean and standard deviation}
\KeywordTok{var}\NormalTok{ mu }\OperatorTok{=}\NormalTok{ ntl\_tls}\OperatorTok{.}\FunctionTok{reduceRegion}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{mean}\NormalTok{())}
\KeywordTok{var}\NormalTok{ std }\OperatorTok{=}\NormalTok{ ntl\_tls}\OperatorTok{.}\FunctionTok{reduceRegion}\NormalTok{(ee}\OperatorTok{.}\AttributeTok{Reducer}\OperatorTok{.}\FunctionTok{stdDev}\NormalTok{())}
\CommentTok{// Convert these to Numbers using the ee.Number constructor}
\KeywordTok{var}\NormalTok{ mu }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Number}\NormalTok{(mu}\OperatorTok{.}\FunctionTok{get}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{))}
\KeywordTok{var}\NormalTok{ std }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Number}\NormalTok{(std}\OperatorTok{.}\FunctionTok{get}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{))}
\CommentTok{// Print Output to ensure values look correct}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Mean Avg Radiance\textquotesingle{}}\OperatorTok{,}\NormalTok{ mu}\OperatorTok{.}\FunctionTok{getInfo}\NormalTok{())}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}StdDev\textquotesingle{}}\OperatorTok{,}\NormalTok{ std}\OperatorTok{.}\FunctionTok{getInfo}\NormalTok{())}
\CommentTok{// Subtract mean and divide by standard deviation}
\KeywordTok{var}\NormalTok{ ntl\_tls\_std }\OperatorTok{=}\NormalTok{ ntl\_tls}\OperatorTok{.}\FunctionTok{subtract}\NormalTok{(mu)}\OperatorTok{.}\FunctionTok{divide}\NormalTok{(std)}
\CommentTok{// Set visibility parameters}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \OperatorTok{{-}}\DecValTok{4}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \DecValTok{4}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(}\FloatTok{126.25}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{8.5}\OperatorTok{,} \DecValTok{9}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(ntl\_tls\_std}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}Scaled Image\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_06.png}
\caption{im\_07\_06}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  \textbf{Expressions}
\end{enumerate}

In this module, we will work with the \texttt{.expression()} methods built-into images. This allows us to work with customized functions and complete more advanced band math than pre-built functionality. This is a very short module, but the key point here is that being able to manipulate and find unique relationships in imagery. Once you understand how to build an expression, opportunities are limitless. In the images below, we invert the pixel values by multiplying each pixel by -1 and adding 63 (max value).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// get 1996 composite, apply mask, and add as layer}
\KeywordTok{var}\NormalTok{ dmsp1996 }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{Image}\NormalTok{(}\StringTok{"NOAA/DMSP{-}OLS/NIGHTTIME\_LIGHTS/F121996"}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}stable\_lights\textquotesingle{}}\NormalTok{)}
\KeywordTok{var}\NormalTok{ lat }\OperatorTok{=} \FloatTok{19.43}
\KeywordTok{var}\NormalTok{ lon }\OperatorTok{=} \OperatorTok{{-}}\FloatTok{99.13}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \FloatTok{0.0}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \FloatTok{63.0}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(lon}\OperatorTok{,}\NormalTok{ lat}\OperatorTok{,} \DecValTok{7}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(dmsp1996}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}1996 Composite\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_07.png}
\caption{im\_07\_07}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Use Expression to invert the pixels}
\KeywordTok{var}\NormalTok{ dmsp1996\_inv }\OperatorTok{=}\NormalTok{ dmsp1996}\OperatorTok{.}\FunctionTok{multiply}\NormalTok{(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\OperatorTok{.}\FunctionTok{add}\NormalTok{(}\DecValTok{63}\NormalTok{)}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(dmsp1996\_inv}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}1996 Composite Inverse\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_08.png}
\caption{im\_07\_08}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  \textbf{Expression (Continued)}
\end{enumerate}

In the previous example we built an expression using some of the GEE built-in operations, such as \texttt{.multiplication()} and \texttt{.add()}. This works well for that specific use case, but is limiting when you need to use operations that are not specifically provided within GEE. Another methodology is to build our expression with a string and then provide the input as a key-value pair. See the code chunk below for the methodology. Additionally, for calculations that involve massive amounts of data, there are some speed advantages in doing it this way. Follow along with the World Bank tutorial using this methodology, and try to build some of your own functions to see the result. Using `Inspector' would be helpful to test whether your function acted as expected.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{ inv\_formula }\OperatorTok{=} \StringTok{"(X*{-}1) + 63"}
\CommentTok{// We plug this formula in, identify our variable "X" and set it to our 1996 DMSP{-}OLS "stable\_lights" band}
\KeywordTok{var}\NormalTok{ dmsp1996\_inv2 }\OperatorTok{=}\NormalTok{ dmsp1996}\OperatorTok{.}\FunctionTok{expression}\NormalTok{(inv\_formula}\OperatorTok{,}\NormalTok{ \{}\StringTok{\textquotesingle{}X\textquotesingle{}}\OperatorTok{:}\NormalTok{dmsp1996\})}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(dmsp1996\_inv2}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}1996 Composite Inverse\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  \textbf{Make a Composite}
\end{enumerate}

Building a temporal composite is an important part of analysis and modeling. We went through these concepts in earlier labs, although this tutorial extends some of the functionality.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 2015 image collection {-} "avg\_rad" band}
\KeywordTok{var}\NormalTok{ viirs2015 }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(}\StringTok{"NOAA/VIIRS/DNB/MONTHLY\_V1/VCMSLCFG"}\NormalTok{)}\OperatorTok{.}\FunctionTok{filterDate}\NormalTok{(}
  \StringTok{"2015{-}01{-}01"}\OperatorTok{,}\StringTok{"2015{-}12{-}31"}\NormalTok{)}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}\StringTok{\textquotesingle{}avg\_rad\textquotesingle{}}\NormalTok{)}
\CommentTok{// Confirm that there are 12 images in this collection }
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Images:\textquotesingle{}}\OperatorTok{,}\NormalTok{ viirs2015}\OperatorTok{.}\FunctionTok{size}\NormalTok{()}\OperatorTok{.}\FunctionTok{getInfo}\NormalTok{())}
\KeywordTok{var}\NormalTok{ viirs2015med }\OperatorTok{=}\NormalTok{ viirs2015}\OperatorTok{.}\FunctionTok{median}\NormalTok{()}
\CommentTok{// iniatialize map on Sao Paulo}
\KeywordTok{var}\NormalTok{ lat }\OperatorTok{=} \OperatorTok{{-}}\FloatTok{23.54}
\KeywordTok{var}\NormalTok{ lon }\OperatorTok{=} \OperatorTok{{-}}\FloatTok{46.63}
\KeywordTok{var}\NormalTok{ nighttimeLightsVis }\OperatorTok{=}\NormalTok{ \{}
  \DataTypeTok{min}\OperatorTok{:} \FloatTok{0.0}\OperatorTok{,}
  \DataTypeTok{max}\OperatorTok{:} \FloatTok{63.0}\OperatorTok{,}
\NormalTok{\}}\OperatorTok{;}
\CommentTok{// Initialize the map}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{setCenter}\NormalTok{(lon}\OperatorTok{,}\NormalTok{ lat}\OperatorTok{,} \DecValTok{7}\NormalTok{)}\OperatorTok{;}
\BuiltInTok{Map}\OperatorTok{.}\FunctionTok{addLayer}\NormalTok{(viirs2015med}\OperatorTok{.}\FunctionTok{mask}\NormalTok{(viirs2015med)}\OperatorTok{,}\NormalTok{ nighttimeLightsVis}\OperatorTok{,} \StringTok{\textquotesingle{}2015 Monthly Median\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{./im/im_07_09.png}
\caption{im\_07\_09}
\end{figure}

------\textgreater{} Research alternative to loop - convert function in 7.4.3 to \texttt{.map}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Define start and end years}
\KeywordTok{var}\NormalTok{ start }\OperatorTok{=} \DecValTok{2015}
\KeywordTok{var}\NormalTok{ end }\OperatorTok{=} \DecValTok{2019}
\KeywordTok{var}\NormalTok{ years }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{List}\OperatorTok{.}\FunctionTok{sequence}\NormalTok{(start}\OperatorTok{,}\NormalTok{ end)}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Number of years: \textquotesingle{}}\OperatorTok{,}\NormalTok{ years}\OperatorTok{.}\FunctionTok{size}\NormalTok{()}\OperatorTok{.}\FunctionTok{getInfo}\NormalTok{())}
\KeywordTok{var}\NormalTok{ colID }\OperatorTok{=} \StringTok{"NOAA/VIIRS/DNB/MONTHLY\_V1/VCMSLCFG"}
\KeywordTok{function} \FunctionTok{viirs\_annual\_median\_reduce}\NormalTok{(year) \{}
    \ControlFlowTok{return}\NormalTok{ ee}\OperatorTok{.}\FunctionTok{ImageCollection}\NormalTok{(colID)}\OperatorTok{.}\FunctionTok{filter}\NormalTok{(            ee}\OperatorTok{.}\AttributeTok{Filter}\OperatorTok{.}\FunctionTok{calendarRange}\NormalTok{(year}\OperatorTok{,}\NormalTok{year}\OperatorTok{,}\StringTok{"year"}\NormalTok{))}\OperatorTok{.}\FunctionTok{select}\NormalTok{(}
      \StringTok{"avg\_rad"}\NormalTok{)}\OperatorTok{.}\FunctionTok{median}\NormalTok{()}\OperatorTok{.}\FunctionTok{set}\NormalTok{(}\StringTok{\textquotesingle{}year\textquotesingle{}}\OperatorTok{,}\NormalTok{year)}
\NormalTok{\}}
\CommentTok{// Map function to each year in our list}
\KeywordTok{var}\NormalTok{ yearComps }\OperatorTok{=}\NormalTok{ ee}\OperatorTok{.}\AttributeTok{ImageCollection}\OperatorTok{.}\FunctionTok{fromImages}\NormalTok{(years}\OperatorTok{.}\FunctionTok{map}\NormalTok{(viirs\_annual\_median\_reduce))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  \textbf{Importing and Exporting Data}
\end{enumerate}

Using the GEE code editor is relatively straightforward for importing spatial files, such as Shapefiles. Follow the \href{https://developers.google.com/earth-engine/guides/table_upload?hl=en}{documentation} and you should be able to import the data that you need.

While the \href{https://developers.google.com/earth-engine/guides/exporting?hl=en}{documentation} on exporting data is also relatively straightforward, it is important to understand exactly what you are exporting.

Refer to lab 01 for more information and some examples of importing and exporting data.

\hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

As noted earlier, this lab is more of a JavaScript supplement to the excellent World Bank tutorial. There are many data and remote sensing libraries in Python that can help you take your work to the next stage.

\end{document}
